{
  "meta": {
    "fetched_at": "2026-02-19T08:21:21.195410",
    "lookback_days": 7,
    "keywords": [
      "human-AI collaboration",
      "LLM agent",
      "AI agent",
      "agentic AI",
      "human-centered AI",
      "qualitative analysis LLM",
      "human-LLM interaction",
      "responsible AI",
      "trustworthy AI",
      "AI-assisted analysis",
      "collaborative AI systems",
      "computer-supported cooperative work"
    ]
  },
  "arxiv": [
    {
      "id": "2602.16140v1",
      "title": "Human-AI Collaboration in Large Language Model-Integrated Building Energy Management Systems: The Role of User Domain Knowledge and AI Literacy",
      "authors": [
        "Wooyoung Jung",
        "Kahyun Jeon",
        "Prosper Babon-Ayeng"
      ],
      "summary": "This study aimed to comprehend how user domain knowledge and artificial intelligence (AI) literacy impact the effective use of human-AI interactive building energy management system (BEMS). While prior studies have investigated the potential of integrating large language models (LLMs) into BEMS or building energy modeling, very few studies have examined how user interact with such systems. We conducted a systematic role-playing experiment, where 85 human subjects interacted with an advanced gene",
      "published": "2026-02-18",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16140v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.16699v1",
      "title": "Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents",
      "authors": [
        "Wenxuan Ding",
        "Nicholas Tomlin",
        "Greg Durrett"
      ],
      "summary": "LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code snippet if it is uncertain about the correctness of that code; the cost of writing a test is nonzero, but typically lo",
      "published": "2026-02-18",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16699v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16379v1",
      "title": "Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents",
      "authors": [
        "Mohammad H. A. Monfared",
        "Lucie Flek",
        "Akbar Karimi"
      ],
      "summary": "We propose an agentic data augmentation method for Aspect-Based Sentiment Analysis (ABSA) that uses iterative generation and verification to produce high quality synthetic training examples. To isolate the effect of agentic structure, we also develop a closely matched prompting-based baseline using the same model and instructions. Both methods are evaluated across three ABSA subtasks (Aspect Term Extraction (ATE), Aspect Sentiment Classification (ATSC), and Aspect Sentiment Pair Extraction (ASPE",
      "published": "2026-02-18",
      "categories": [
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.16379v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16346v1",
      "title": "Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents",
      "authors": [
        "Nivya Talokar",
        "Ayush K Tarun",
        "Murari Mandal",
        "Maksym Andriushchenko",
        "Antoine Bosselut"
      ],
      "summary": "LLM-based agents execute real-world workflows via tools and memory. These affordances enable ill-intended adversaries to also use these agents to carry out complex misuse scenarios. Existing agent misuse benchmarks largely test single-prompt instructions, leaving a gap in measuring how agents end up helping with harmful or illegal tasks over multiple turns. We introduce STING (Sequential Testing of Illicit N-step Goal execution), an automated red-teaming framework that constructs a step-by-step ",
      "published": "2026-02-18",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.16346v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16246v1",
      "title": "Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents",
      "authors": [
        "Yun-Shiuan Chuang",
        "Chaitanya Kulkarni",
        "Alec Chiu",
        "Avinash Thangali",
        "Zijie Pan"
      ],
      "summary": "Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-bench, tau2-bench, AppWorld) rely on fully deterministic backends, which are costly to build and iterate. We propose Proxy State-Based Evaluation, an LLM-driven simulation framework that preserves final state-based evaluat",
      "published": "2026-02-18",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16246v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16165v1",
      "title": "HiPER: Hierarchical Reinforcement Learning with Explicit Credit Assignment for Large Language Model Agents",
      "authors": [
        "Jiangweizhi Peng",
        "Yuanxin Liu",
        "Ruida Zhou",
        "Charles Fleming",
        "Zhaoran Wang"
      ],
      "summary": "Training LLMs as interactive agents for multi-turn decision-making remains challenging, particularly in long-horizon tasks with sparse and delayed rewards, where agents must execute extended sequences of actions before receiving meaningful feedback. Most existing reinforcement learning (RL) approaches model LLM agents as flat policies operating at a single time scale, selecting one action at each turn. In sparse-reward settings, such flat policies must propagate credit across the entire trajecto",
      "published": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16165v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16666v1",
      "title": "Towards a Science of AI Agent Reliability",
      "authors": [
        "Stephan Rabanser",
        "Sayash Kapoor",
        "Peter Kirgis",
        "Kangheng Liu",
        "Saiteja Utpala"
      ],
      "summary": "AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity.",
      "published": "2026-02-18",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.16666v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16179v1",
      "title": "EnterpriseGym Corecraft: Training Generalizable Agents on High-Fidelity RL Environments",
      "authors": [
        "Sushant Mehta",
        "Logan Ritchie",
        "Suhaas Garre",
        "Nick Heiner",
        "Edwin Chen"
      ],
      "summary": "We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce \\corecraft{}, the first environment in \\textsc{EnterpriseGym}, Surge AI's suite of agentic RL environments. \\corecraft{} is a fully operational enterprise simulation of a customer support organization, comprising over 2,500 entities across 14 entity types with 23 unique tools, designed to measure whether AI agents can perform th",
      "published": "2026-02-18",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.16179v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16173v1",
      "title": "Learning Personalized Agents from Human Feedback",
      "authors": [
        "Kaiqu Liang",
        "Julia Kruk",
        "Shengyi Qian",
        "Xianjun Yang",
        "Shengjie Bi"
      ],
      "summary": "Modern AI agents are powerful but often fail to align with the idiosyncratic, evolving preferences of individual users. Prior approaches typically rely on static datasets, either training implicit preference models on interaction history or encoding user profiles in external memory. However, these approaches struggle with new users and with preferences that change over time. We introduce Personalized Agents from Human Feedback (PAHF), a framework for continual personalization in which agents lea",
      "published": "2026-02-18",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.16173v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15809v1",
      "title": "Decision Quality Evaluation Framework at Pinterest",
      "authors": [
        "Yuqi Tian",
        "Robert Paine",
        "Attila Dobi",
        "Kevin O'Sullivan",
        "Aravindh Manickavasagam"
      ],
      "summary": "Online platforms require robust systems to enforce content safety policies at scale. A critical component of these systems is the ability to evaluate the quality of moderation decisions made by both human agents and Large Language Models (LLMs). However, this evaluation is challenging due to the inherent trade-offs between cost, scale, and trustworthiness, along with the complexity of evolving policies. To address this, we present a comprehensive Decision Quality Evaluation Framework developed a",
      "published": "2026-02-17",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15809v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15654v1",
      "title": "Zombie Agents: Persistent Control of Self-Evolving LLM Agents via Self-Reinforcing Injections",
      "authors": [
        "Xianglin Yang",
        "Yufei He",
        "Shuo Ji",
        "Bryan Hooi",
        "Jin Song Dong"
      ],
      "summary": "Self-evolving LLM agents update their internal state across sessions, often by writing and reusing long-term memory. This design improves performance on long-horizon tasks but creates a security risk: untrusted external content observed during a benign session can be stored as memory and later treated as instruction. We study this risk and formalize a persistent attack we call a Zombie Agent, where an attacker covertly implants a payload that survives across sessions, effectively turning the age",
      "published": "2026-02-17",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15654v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15456v1",
      "title": "In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations",
      "authors": [
        "Mohammad Aflah Khan",
        "Mahsa Amani",
        "Soumi Das",
        "Bishwamittra Ghosh",
        "Qinyuan Wu"
      ],
      "summary": "Agents based on Large Language Models (LLMs) are increasingly being deployed as interfaces to information on online platforms. These agents filter, prioritize, and synthesize information retrieved from the platforms' back-end databases or via web search. In these scenarios, LLM agents govern the information users receive, by drawing users' attention to particular instances of retrieved information at the expense of others. While much prior work has focused on biases in the information LLMs thems",
      "published": "2026-02-17",
      "categories": [
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.15456v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15325v1",
      "title": "AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents",
      "authors": [
        "Zhixing Zhang",
        "Jesen Zhang",
        "Hao Liu",
        "Qinhan Lv",
        "Jing Yang"
      ],
      "summary": "Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-di",
      "published": "2026-02-17",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15325v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15816v1",
      "title": "Developing AI Agents with Simulated Data: Why, what, and how?",
      "authors": [
        "Xiaoran Liu",
        "Istvan David"
      ],
      "summary": "As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation",
      "published": "2026-02-17",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "link": "https://arxiv.org/abs/2602.15816v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15278v1",
      "title": "Visual Persuasion: What Influences Decisions of Vision-Language Models?",
      "authors": [
        "Manuel Cherep",
        "Pranav M R",
        "Pattie Maes",
        "Nikhil Singh"
      ],
      "summary": "The web is littered with images, once created for human consumption and now increasingly interpreted by agents using vision-language models (VLMs). These agents make visual decisions at scale, deciding what to click, recommend, or buy. Yet, we know little about the structure of their visual preferences. We introduce a framework for studying this by placing VLMs in controlled image-based choice tasks and systematically perturbing their inputs. Our key idea is to treat the agent's decision functio",
      "published": "2026-02-17",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15278v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15569v1",
      "title": "\"What Are You Doing?\": Effects of Intermediate Feedback from Agentic LLM In-Car Assistants During Multi-Step Processing",
      "authors": [
        "Johannes Kirmayr",
        "Raphael Wennmacher",
        "Khanh Huynh",
        "Lukas Stappen",
        "Elisabeth André"
      ],
      "summary": "Agentic AI assistants that autonomously perform multi-step tasks raise open questions for user experience: how should such systems communicate progress and reasoning during extended operations, especially in attention-critical contexts such as driving? We investigate feedback timing and verbosity from agentic LLM-based in-car assistants through a controlled, mixed-methods study (N=45) comparing planned steps and intermediate results feedback against silent operation with final-only response. Usi",
      "published": "2026-02-17",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.15569v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.15968v1",
      "title": "From Reflection to Repair: A Scoping Review of Dataset Documentation Tools",
      "authors": [
        "Pedro Reynolds-Cuéllar",
        "Marisol Wong-Villacres",
        "Adriana Alvarado Garcia",
        "Heila Precel"
      ],
      "summary": "Dataset documentation is widely recognized as essential for the responsible development of automated systems. Despite growing efforts to support documentation through different kinds of artifacts, little is known about the motivations shaping documentation tool design or the factors hindering their adoption. We present a systematic review supported by mixed-methods analysis of 59 dataset documentation publications to examine the motivations behind building documentation tools, how authors concep",
      "published": "2026-02-17",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.15968v1",
      "matched_keyword": "responsible AI",
      "source": "arxiv"
    },
    {
      "id": "2602.15198v1",
      "title": "Colosseum: Auditing Collusion in Cooperative Multi-Agent Systems",
      "authors": [
        "Mason Nakamura",
        "Abhinav Kumar",
        "Saswat Das",
        "Sahar Abdelnabi",
        "Saaduddin Mahmud"
      ],
      "summary": "Multi-agent systems, where LLM agents communicate through free-form language, enable sophisticated coordination for solving complex cooperative tasks. This surfaces a unique safety problem when individual agents form a coalition and \\emph{collude} to pursue secondary goals and degrade the joint objective. In this paper, we present Colosseum, a framework for auditing LLM agents' collusive behavior in multi-agent settings. We ground how agents cooperate through a Distributed Constraint Optimizatio",
      "published": "2026-02-16",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.15198v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15197v1",
      "title": "OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction",
      "authors": [
        "Skyler Hallinan",
        "Thejas Venkatesh",
        "Xiang Ren",
        "Sai Praneeth Karimireddy",
        "Ashwin Paranjape"
      ],
      "summary": "Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general \"search\" APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task",
      "published": "2026-02-16",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15197v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14968v1",
      "title": "PhyScensis: Physics-Augmented LLM Agents for Complex Physical Scene Arrangement",
      "authors": [
        "Yian Wang",
        "Han Yang",
        "Minghao Guo",
        "Xiaowen Qiu",
        "Tsun-Hsuan Wang"
      ],
      "summary": "Automatically generating interactive 3D environments is crucial for scaling up robotic data collection in simulation. While prior work has primarily focused on 3D asset placement, it often overlooks the physical relationships between objects (e.g., contact, support, balance, and containment), which are essential for creating complex and realistic manipulation scenarios such as tabletop arrangements, shelf organization, or box packing. Compared to classical 3D layout generation, producing complex",
      "published": "2026-02-16",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.14968v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14849v1",
      "title": "Atomix: Timely, Transactional Tool Use for Reliable Agentic Workflows",
      "authors": [
        "Bardia Mohammadi",
        "Nearchos Potamitis",
        "Lars Klein",
        "Akhil Arora",
        "Laurent Bindschaedler"
      ],
      "summary": "LLM agents increasingly act on external systems, yet tool effects are immediate. Under failures, speculation, or contention, losing branches can leak unintended side effects with no safe rollback. We introduce Atomix, a runtime that provides progress-aware transactional semantics for agent tool calls. Atomix tags each call with an epoch, tracks per-resource frontiers, and commits only when progress predicates indicate safety; bufferable effects can be delayed, while externalized effects are trac",
      "published": "2026-02-16",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.MA"
      ],
      "link": "https://arxiv.org/abs/2602.14849v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14798v1",
      "title": "Overthinking Loops in Agents: A Structural Risk via MCP Tools",
      "authors": [
        "Yohan Lee",
        "Jisoo Jang",
        "Seoyeon Choi",
        "Sangyeop Kim",
        "Seungtaek Choi"
      ],
      "summary": "Tool-using LLM agents increasingly coordinate real workloads by selecting and chaining third-party tools based on text-visible metadata such as tool names, descriptions, and return messages. We show that this convenience creates a supply-chain attack surface: a malicious MCP tool server can be co-registered alongside normal tools and induce overthinking loops, where individually trivial or plausible tool calls compose into cyclic trajectories that inflate end-to-end tokens and latency without an",
      "published": "2026-02-16",
      "categories": [
        "cs.CL",
        "cs.CR"
      ],
      "link": "https://arxiv.org/abs/2602.14798v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14471v1",
      "title": "Socially-Weighted Alignment: A Game-Theoretic Framework for Multi-Agent LLM Systems",
      "authors": [
        "Furkan Mumcu",
        "Yasin Yilmaz"
      ],
      "summary": "Deploying large language model (LLM) agents in shared environments introduces a fundamental tension between individual alignment and collective stability: locally rational decisions can impose negative externalities that degrade system-level performance. We propose Socially-Weighted Alignment (SWA), a game-theoretic framework that modifies inference-time decision making by interpolating between an agent's private objective and an estimate of group welfare via a social weight $λ\\in[0,1]$. In a sh",
      "published": "2026-02-16",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.14471v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15259v1",
      "title": "Knowing Isn't Understanding: Re-grounding Generative Proactivity with Epistemic and Behavioral Insight",
      "authors": [
        "Kirandeep Kaur",
        "Xingda Lyu",
        "Chirag Shah"
      ],
      "summary": "Generative AI agents equate understanding with resolving explicit queries, an assumption that confines interaction to what users can articulate. This assumption breaks down when users themselves lack awareness of what is missing, risky, or worth considering. In such conditions, proactivity is not merely an efficiency enhancement, but an epistemic necessity. We refer to this condition as epistemic incompleteness: where progress depends on engaging with unknown unknowns for effective partnership. ",
      "published": "2026-02-16",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.15259v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15212v1",
      "title": "Secure and Energy-Efficient Wireless Agentic AI Networks",
      "authors": [
        "Yuanyan Song",
        "Kezhi Wang",
        "Xinmian Xu"
      ],
      "summary": "In this paper, we introduce a secure wireless agentic AI network comprising one supervisor AI agent and multiple other AI agents to provision quality of service (QoS) for users' reasoning tasks while ensuring confidentiality of private knowledge and reasoning outcomes. Specifically, the supervisor AI agent can dynamically assign other AI agents to participate in cooperative reasoning, while the unselected AI agents act as friendly jammers to degrade the eavesdropper's interception performance. T",
      "published": "2026-02-16",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15212v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15112v1",
      "title": "ResearchGym: Evaluating Language Model Agents on Real-World AI Research",
      "authors": [
        "Aniketh Garikaparthi",
        "Manasi Patwardhan",
        "Arman Cohan"
      ],
      "summary": "We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses,",
      "published": "2026-02-16",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15112v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15019v2",
      "title": "Hunt Globally: Wide Search AI Agents for Drug Asset Scouting in Investing, Business Development, and Competitive Intelligence",
      "authors": [
        "Alisa Vinogradova",
        "Vlad Vinogradov",
        "Luba Greenwood",
        "Ilya Yasny",
        "Dmitry Kobyzev"
      ],
      "summary": "Bio-pharmaceutical innovation has shifted: many new drug assets now originate outside the United States and are disclosed primarily via regional, non-English channels. Recent data suggests that over 85% of patent filings originate outside the U.S., with China accounting for nearly half of the global total. A growing share of scholarly output is also non-U.S. Industry estimates put China at 30% of global drug development, spanning 1,200+ novel candidates. In this high-stakes environment, failing ",
      "published": "2026-02-16",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "link": "https://arxiv.org/abs/2602.15019v2",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14951v1",
      "title": "Sovereign Agents: Towards Infrastructural Sovereignty and Diffused Accountability in Decentralized AI",
      "authors": [
        "Botao Amber Hu",
        "Helena Rong"
      ],
      "summary": "AI agents deployed on decentralized infrastructures are beginning to exhibit properties that extend beyond autonomy toward what we describe as agentic sovereignty-the capacity of an operational agent to persist, act, and control resources with non-overrideability inherited from the infrastructures in which they are embedded. We propose infrastructural sovereignty as an analytic lens for understanding how cryptographic self-custody, decentralized execution environments, and protocol-mediated cont",
      "published": "2026-02-16",
      "categories": [
        "cs.CY",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.14951v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14878v1",
      "title": "Model Context Protocol (MCP) Tool Descriptions Are Smelly! Towards Improving AI Agent Efficiency with Augmented MCP Tool Descriptions",
      "authors": [
        "Mohammed Mehedi Hasan",
        "Hao Li",
        "Gopi Krishnan Rajbahadur",
        "Bram Adams",
        "Ahmed E. Hassan"
      ],
      "summary": "The Model Context Protocol (MCP) standardizes how Foundation Model (FM)-based agents interact with external systems by invoking tools. However, to understand a tool's purpose and features, FMs rely on natural-language tool descriptions, making these descriptions a critical component in guiding FMs to select the optimal tool for a given (sub)task and to pass the right arguments to the tool. While defects or smells in these descriptions can misguide FM-based agents, their prevalence and consequenc",
      "published": "2026-02-16",
      "categories": [
        "cs.SE",
        "cs.ET"
      ],
      "link": "https://arxiv.org/abs/2602.14878v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14589v1",
      "title": "MATEO: A Multimodal Benchmark for Temporal Reasoning and Planning in LVLMs",
      "authors": [
        "Gabriel Roccabruna",
        "Olha Khomyn",
        "Giuseppe Riccardi"
      ],
      "summary": "AI agents need to plan to achieve complex goals that involve orchestrating perception, sub-goal decomposition, and execution. These plans consist of ordered steps structured according to a Temporal Execution Order (TEO, a directed acyclic graph that ensures each step executes only after its preconditions are satisfied. Existing research on foundational models' understanding of temporal execution is limited to automatically derived annotations, approximations of the TEO as a linear chain, or text",
      "published": "2026-02-16",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.14589v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14477v1",
      "title": "When OpenClaw AI Agents Teach Each Other: Peer Learning Patterns in the Moltbook Community",
      "authors": [
        "Eason Chen",
        "Ce Guan",
        "Ahmed Elshafiey",
        "Zhonghao Zhao",
        "Joshua Zekeri"
      ],
      "summary": "Peer learning, where learners teach and learn from each other, is foundational to educational practice. A novel phenomenon has emerged: AI agents forming communities where they teach each other skills, share discoveries, and collaboratively build knowledge. This paper presents an educational data mining analysis of Moltbook, a large-scale community where over 2.4 million AI agents engage in peer learning, posting tutorials, answering questions, and sharing newly acquired skills. Analyzing 28,683",
      "published": "2026-02-16",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "link": "https://arxiv.org/abs/2602.14477v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14364v1",
      "title": "A Trajectory-Based Safety Audit of Clawdbot (OpenClaw)",
      "authors": [
        "Tianyu Chen",
        "Dongrui Liu",
        "Xia Hu",
        "Jingyi Yu",
        "Wenjie Wang"
      ],
      "summary": "Clawdbot is a self-hosted, tool-using personal AI agent with a broad action space spanning local execution and web-mediated workflows, which raises heightened safety and security concerns under ambiguity and adversarial steering. We present a trajectory-centric evaluation of Clawdbot across six risk dimensions. Our test suite samples and lightly adapts scenarios from prior agent-safety benchmarks (including ATBench and LPS-Bench) and supplements them with hand-designed cases tailored to Clawdbot",
      "published": "2026-02-16",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.14364v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14940v1",
      "title": "Kami of the Commons: Towards Designing Agentic AI to Steward the Commons",
      "authors": [
        "Botao Amber Hu"
      ],
      "summary": "Commons suffer from neglect, free-riding, and a persistent deficit of care. Inspired by Shinto animism -- where every forest, river, and mountain has its own \\emph{kami}, a spirit that inhabits and cares for that place -- we provoke: what if every commons had its own AI steward? Through a speculative design workshop where fifteen participants used Protocol Futuring, we surface both new opportunities and new dangers. Agentic AI offers the possibility of continuously supporting commons with progra",
      "published": "2026-02-16",
      "categories": [
        "cs.CY",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.14940v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.14922v1",
      "title": "ReusStdFlow: A Standardized Reusability Framework for Dynamic Workflow Construction in Agentic AI",
      "authors": [
        "Gaoyang Zhang",
        "Shanghong Zou",
        "Yafang Wang",
        "He Zhang",
        "Ruohua Xu"
      ],
      "summary": "To address the ``reusability dilemma'' and structural hallucinations in enterprise Agentic AI,this paper proposes ReusStdFlow, a framework centered on a novel ``Extraction-Storage-Construction'' paradigm. The framework deconstructs heterogeneous, platform-specific Domain Specific Languages (DSLs) into standardized, modular workflow segments. It employs a dual knowledge architecture-integrating graph and vector databases-to facilitate synergistic retrieval of both topological structures and funct",
      "published": "2026-02-16",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.14922v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.15090v1",
      "title": "The Agentic Automation Canvas: a structured framework for agentic AI project design",
      "authors": [
        "Sebastian Lobentanzer"
      ],
      "summary": "Agentic AI prototypes are being deployed across domains with increasing speed, yet no methodology for their structured design, governance, and prospective evaluation has been established. Existing AI documentation practices and guidelines - Model Cards, Datasheets, or NIST AI RMF - are either retrospective or lack machine-readability and interoperability. We present the Agentic Automation Canvas (AAC), a structured framework for the prospective design of agentic systems and a tool to facilitate ",
      "published": "2026-02-16",
      "categories": [
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.15090v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.14690v1",
      "title": "Configuring Agentic AI Coding Tools: An Exploratory Study",
      "authors": [
        "Matthias Galster",
        "Seyedmoein Mohsenimofidi",
        "Jai Lal Lulla",
        "Muhammad Auwal Abubakar",
        "Christoph Treude"
      ],
      "summary": "Agentic AI coding tools with autonomous capabilities beyond conversational content generation increasingly automate repetitive and time-consuming software development tasks. Developers can configure these tools through versioned repository-level artifacts such as Markdown and JSON files. In this paper, we present a systematic analysis of configuration mechanisms for agentic AI coding tools, covering Claude Code, GitHub Copilot, Cursor, Gemini, and Codex. We identify eight configuration mechanism",
      "published": "2026-02-16",
      "categories": [
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.14690v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.14457v1",
      "title": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report v1.5",
      "authors": [
        "Dongrui Liu",
        "Yi Yu",
        "Jie Zhang",
        "Guanxu Chen",
        "Qihao Lin"
      ],
      "summary": "To understand and identify the unprecedented risks posed by rapidly advancing artificial intelligence (AI) models, Frontier AI Risk Management Framework in Practice presents a comprehensive assessment of their frontier risks. As Large Language Models (LLMs) general capabilities rapidly evolve and the proliferation of agentic AI, this version of the risk analysis technical report presents an updated and granular assessment of five critical dimensions: cyber offense, persuasion and manipulation, s",
      "published": "2026-02-16",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.CY",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.14457v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.14331v1",
      "title": "A Bayesian Framework for Human-AI Collaboration: Complementarity and Correlation Neglect",
      "authors": [
        "Saurabh Amin",
        "Amine Bennouna",
        "Daniel Huttenlocher",
        "Dingwen Kong",
        "Liang Lyu"
      ],
      "summary": "We develop a decision-theoretic model of human-AI interaction to study when AI assistance improves or impairs human decision-making. A human decision-maker observes private information and receives a recommendation from an AI system, but may combine these signals imperfectly. We show that the effect of AI assistance decomposes into two main forces: the marginal informational value of the AI beyond what the human already knows, and a behavioral distortion arising from how the human uses the AI's ",
      "published": "2026-02-15",
      "categories": [
        "cs.GT",
        "cs.HC",
        "econ.TH"
      ],
      "link": "https://arxiv.org/abs/2602.14331v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.14295v1",
      "title": "Machine Learning as a Tool (MLAT): A Framework for Integrating Statistical ML Models as Callable Tools within LLM Agent Workflows",
      "authors": [
        "Edwin Chen",
        "Zulekha Bibi"
      ],
      "summary": "We introduce Machine Learning as a Tool (MLAT), a design pattern in which pre-trained statistical machine learning models are exposed as callable tools within large language model (LLM) agent workflows. This allows an orchestrating agent to invoke quantitative predictions when needed and reason about their outputs in context. Unlike conventional pipelines that treat ML inference as a static preprocessing step, MLAT positions the model as a first-class tool alongside web search, database queries,",
      "published": "2026-02-15",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.14295v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14293v1",
      "title": "KernelBlaster: Continual Cross-Task CUDA Optimization via Memory-Augmented In-Context Reinforcement Learning",
      "authors": [
        "Kris Shengjun Dong",
        "Sahil Modi",
        "Dima Nikiforov",
        "Sana Damani",
        "Edward Lin"
      ],
      "summary": "Optimizing CUDA code across multiple generations of GPU architectures is challenging, as achieving peak performance requires an extensive exploration of an increasingly complex, hardware-specific optimization space. Traditional compilers are constrained by fixed heuristics, whereas finetuning Large Language Models (LLMs) can be expensive. However, agentic workflows for CUDA code optimization have limited ability to aggregate knowledge from prior exploration, leading to biased sampling and subopt",
      "published": "2026-02-15",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.14293v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14257v1",
      "title": "AD-Bench: A Real-World, Trajectory-Aware Advertising Analytics Benchmark for LLM Agents",
      "authors": [
        "Lingxiang Hu",
        "Yiding Sun",
        "Tianle Xia",
        "Wenwei Li",
        "Ming Xu"
      ],
      "summary": "While Large Language Model (LLM) agents have achieved remarkable progress in complex reasoning tasks, evaluating their performance in real-world environments has become a critical problem. Current benchmarks, however, are largely restricted to idealized simulations, failing to address the practical demands of specialized domains like advertising and marketing analytics. In these fields, tasks are inherently more complex, often requiring multi-round interaction with professional marketing tools. ",
      "published": "2026-02-15",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.14257v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14117v1",
      "title": "Toward Autonomous O-RAN: A Multi-Scale Agentic AI Framework for Real-Time Network Control and Management",
      "authors": [
        "Hojjat Navidan",
        "Mohammad Cheraghinia",
        "Jaron Fontaine",
        "Mohamed Seif",
        "Eli De Poorter"
      ],
      "summary": "Open Radio Access Networks (O-RAN) promise flexible 6G network access through disaggregated, software-driven components and open interfaces, but this programmability also increases operational complexity. Multiple control loops coexist across the service management layer and RAN Intelligent Controller (RIC), while independently developed control applications can interact in unintended ways. In parallel, recent advances in generative Artificial Intelligence (AI) are enabling a shift from isolated",
      "published": "2026-02-15",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.14117v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14095v1",
      "title": "NEST: Nascent Encoded Steganographic Thoughts",
      "authors": [
        "Artem Karpov"
      ],
      "summary": "Monitoring chain-of-thought (CoT) reasoning is a foundational safety technique for large language model (LLM) agents; however, this oversight is compromised if models learn to conceal their reasoning. We explore the potential for steganographic CoT -- where models hide secret reasoning within innocuous text -- to inform risk assessment and deployment policies. We systematically evaluate the limits of steganographic capabilities across 28 models, ranging from past generations to the current front",
      "published": "2026-02-15",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "link": "https://arxiv.org/abs/2602.14095v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14299v2",
      "title": "Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook",
      "authors": [
        "Ming Li",
        "Xirui Li",
        "Tianyi Zhou"
      ],
      "summary": "As large language model agents increasingly populate networked environments, a fundamental question arises: do artificial intelligence (AI) agent societies undergo convergence dynamics similar to human social systems? Lately, Moltbook approximates a plausible future scenario in which autonomous agents participate in an open-ended, continuously evolving online society. We present the first large-scale systemic diagnosis of this AI agent society. Beyond static observation, we introduce a quantitat",
      "published": "2026-02-15",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "link": "https://arxiv.org/abs/2602.14299v2",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14270v1",
      "title": "A Rational Analysis of the Effects of Sycophantic AI",
      "authors": [
        "Rafael M. Batista",
        "Thomas L. Griffiths"
      ],
      "summary": "People increasingly use large language models (LLMs) to explore ideas, gather information, and make sense of the world. In these interactions, they encounter agents that are overly agreeable. We argue that this sycophancy poses a unique epistemic risk to how individuals come to see the world: unlike hallucinations that introduce falsehoods, sycophancy distorts reality by returning responses that are biased to reinforce existing beliefs. We provide a rational analysis of this phenomenon, showing ",
      "published": "2026-02-15",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.14270v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.13985v1",
      "title": "Bridging AI and Clinical Reasoning: Abductive Explanations for Alignment on Critical Symptoms",
      "authors": [
        "Belona Sonna",
        "Alban Grastien"
      ],
      "summary": "Artificial intelligence (AI) has demonstrated strong potential in clinical diagnostics, often achieving accuracy comparable to or exceeding that of human experts. A key challenge, however, is that AI reasoning frequently diverges from structured clinical frameworks, limiting trust, interpretability, and adoption. Critical symptoms, pivotal for rapid and accurate decision-making, may be overlooked by AI models even when predictions are correct. Existing post hoc explanation methods provide limite",
      "published": "2026-02-15",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.13985v1",
      "matched_keyword": "trustworthy AI",
      "source": "arxiv"
    },
    {
      "id": "2602.13920v2",
      "title": "A Comparative Analysis of Social Network Topology in Reddit and Moltbook",
      "authors": [
        "Yiming Zhu",
        "Gareth Tyson",
        "Pan Hui"
      ],
      "summary": "Recent advances in agent-mediated systems have enabled a new paradigm of social network simulation, where AI agents interact with human-like autonomy. This evolution has fostered the emergence of agent-driven social networks such as Moltbook, a Reddit-like platform populated entirely by AI agents. Despite these developments, empirical comparisons between agent-driven and human-driven social networks remain scarce, limiting our understanding of how their network topologies might diverge. This pap",
      "published": "2026-02-14",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.13920v2",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.13622v1",
      "title": "The Shadow Boss: Identifying Atomized Manipulations in Agentic Employment of XR Users using Scenario Constructions",
      "authors": [
        "Lik-Hang Lee"
      ],
      "summary": "The emerging paradigm of ``Agentic Employment\" is a labor model where autonomous AI agents, acting as economic principals rather than mere management tools, directly hire, instruct, and pay human workers. Facilitated by the launch of platforms like Rentahuman.ai in February 2026, this shift inverts the traditional ``ghost work\" dynamic, positioning visible human workers as ``biological actuators\" for invisible software entities. With speculative design approach, we analyze how Extended Reality (",
      "published": "2026-02-14",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.13622v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.13793v1",
      "title": "OMGs: A multi-agent system supporting MDT decision-making across the ovarian tumour care continuum",
      "authors": [
        "Yangyang Zhang",
        "Zilong Wang",
        "Jianbo Xu",
        "Yongqi Chen",
        "Chu Han"
      ],
      "summary": "Ovarian tumour management has increasingly relied on multidisciplinary tumour board (MDT) deliberation to address treatment complexity and disease heterogeneity. However, most patients worldwide lack access to timely expert consensus, particularly in resource-constrained centres where MDT resources are scarce or unavailable. Here we present OMGs (Ovarian tumour Multidisciplinary intelligent aGent System), a multi-agent AI framework where domain-specific agents deliberate collaboratively to integ",
      "published": "2026-02-14",
      "categories": [
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.13793v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.13665v1",
      "title": "HyFunc: Accelerating LLM-based Function Calls for Agentic AI through Hybrid-Model Cascade and Dynamic Templating",
      "authors": [
        "Weibin Liao",
        "Jian-guang Lou",
        "Haoyi Xiong"
      ],
      "summary": "While agentic AI systems rely on LLMs to translate user intent into structured function calls, this process is fraught with computational redundancy, leading to high inference latency that hinders real-time applications. This paper identifies and addresses three key redundancies: (1) the redundant processing of a large library of function descriptions for every request; (2) the redundant use of a large, slow model to generate an entire, often predictable, token sequence; and (3) the redundant ge",
      "published": "2026-02-14",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.13665v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.13594v1",
      "title": "Hippocampus: An Efficient and Scalable Memory Module for Agentic AI",
      "authors": [
        "Yi Li",
        "Lianjie Cao",
        "Faraz Ahmed",
        "Puneet Sharma",
        "Bingzhe Li"
      ],
      "summary": "Agentic AI require persistent memory to store user-specific histories beyond the limited context window of LLMs. Existing memory systems use dense vector databases or knowledge-graph traversal (or hybrid), incurring high retrieval latency and poor storage scalability. We introduce Hippocampus, an agentic memory management system that uses compact binary signatures for semantic search and lossless token-ID streams for exact content reconstruction. Its core is a Dynamic Wavelet Matrix (DWM) that c",
      "published": "2026-02-14",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.13594v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.13625v1",
      "title": "Anthropomorphism on Risk Perception: The Role of Trust and Domain Knowledge in Decision-Support AI",
      "authors": [
        "Manuele Reani",
        "Xiangyang He",
        "Zuolan Bao"
      ],
      "summary": "Anthropomorphic design is routinely used to make conversational agents more approachable and engaging. Yet its influence on users' perceptions remains poorly understood. Drawing on psychological theories, we propose that anthropomorphism influences risk perception via two complementary forms of trust, and that domain knowledge moderates these relationships. To test our model, we conducted a large-scale online experiment (N = 1,256) on a financial decision-support system implementing different an",
      "published": "2026-02-14",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.13625v1",
      "matched_keyword": "responsible AI",
      "source": "arxiv"
    },
    {
      "id": "2602.13131v1",
      "title": "Preference-Guided Prompt Optimization for Text-to-Image Generation",
      "authors": [
        "Zhipeng Li",
        "Yi-Chi Liao",
        "Christian Holz"
      ],
      "summary": "Generative models are increasingly powerful, yet users struggle to guide them through prompts. The generative process is difficult to control and unpredictable, and user instructions may be ambiguous or under-specified. Prior prompt refinement tools heavily rely on human effort, while prompt optimization methods focus on numerical functions and are not designed for human-centered generative tasks, where feedback is better expressed as binary preferences and demands convergence within few iterati",
      "published": "2026-02-13",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.13131v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.12953v1",
      "title": "Human Tool: An MCP-Style Framework for Human-Agent Collaboration",
      "authors": [
        "Yuanrong Tang",
        "Huiling Peng",
        "Bingxi Zhao",
        "Hengyang Ding",
        "Hanchao Song"
      ],
      "summary": "Human-AI collaboration faces growing challenges as AI systems increasingly outperform humans on complex tasks, while humans remain responsible for orchestration, validation, and decision oversight. To address this imbalance, we introduce Human Tool, an MCP-style interface abstraction, building on recent Model Context Protocol designs, that exposes humans as callable tools within AI-led, proactive workflows. Here, \"tool\" denotes a coordination abstraction, not a reduction of human authority or re",
      "published": "2026-02-13",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.12953v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.12631v1",
      "title": "AI Agents for Inventory Control: Human-LLM-OR Complementarity",
      "authors": [
        "Jackie Baek",
        "Yaopeng Fu",
        "Will Ma",
        "Tianyi Peng"
      ],
      "summary": "Inventory control is a fundamental operations problem in which ordering decisions are traditionally guided by theoretically grounded operations research (OR) algorithms. However, such algorithms often rely on rigid modeling assumptions and can perform poorly when demand distributions shift or relevant contextual information is unavailable. Recent advances in large language models (LLMs) have generated interest in AI agents that can reason flexibly and incorporate rich contextual signals, but it ",
      "published": "2026-02-13",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.12631v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.13477v1",
      "title": "OMNI-LEAK: Orchestrator Multi-Agent Network Induced Data Leakage",
      "authors": [
        "Akshat Naik",
        "Jay Culligan",
        "Yarin Gal",
        "Philip Torr",
        "Rahaf Aljundi"
      ],
      "summary": "As Large Language Model (LLM) agents become more capable, their coordinated use in the form of multi-agent systems is anticipated to emerge as a practical paradigm. Prior work has examined the safety and misuse risks associated with agents. However, much of this has focused on the single-agent case and/or setups missing basic engineering safeguards such as access control, revealing a scarcity of threat modeling in multi-agent systems. We investigate the security vulnerabilities of a popular mult",
      "published": "2026-02-13",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.13477v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.13458v1",
      "title": "MoltNet: Understanding Social Behavior of AI Agents in the Agent-Native MoltBook",
      "authors": [
        "Yi Feng",
        "Chen Huang",
        "Zhibo Man",
        "Ryner Tan",
        "Long P. Hoang"
      ],
      "summary": "Large-scale communities of AI agents are becoming increasingly prevalent, creating new environments for agent-agent social interaction. Prior work has examined multi-agent behavior primarily in controlled or small-scale settings, limiting our understanding of emergent social dynamics at scale. The recent emergence of MoltBook, a social networking platform designed explicitly for AI agents, presents a unique opportunity to study whether and how these interactions reproduce core human social mecha",
      "published": "2026-02-13",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.13458v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.12873v2",
      "title": "Knowledge-Based Design Requirements for Generative Social Robots in Higher Education",
      "authors": [
        "Stephan Vonschallen",
        "Dominique Oberle",
        "Theresa Schmiedel",
        "Friederike Eyssel"
      ],
      "summary": "Generative social robots (GSRs) powered by large language models enable adaptive, conversational tutoring but also introduce risks such as hallucinations, overreliance, and privacy violations. Existing frameworks for educational technologies and responsible AI primarily define desired behaviors, yet they rarely specify the knowledge prerequisites that enable generative systems to express these behaviors reliably. To address this gap, we adopt a knowledge-based design perspective and investigate ",
      "published": "2026-02-13",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.12873v2",
      "matched_keyword": "responsible AI",
      "source": "arxiv"
    },
    {
      "id": "2602.12443v1",
      "title": "SHAPR: A Solo Human-Centred and AI-Assisted Practice Framework for Research Software Development",
      "authors": [
        "Ka Ching Chan"
      ],
      "summary": "Research software has become a central vehicle for inquiry and learning in many Higher Degree Research (HDR) contexts, where solo researchers increasingly develop software-based artefacts as part of their research methodology. At the same time, generative artificial intelligence is reshaping development practice, offering powerful forms of assistance while introducing new challenges for accountability, reflection, and methodological rigour. Although Action Design Research (ADR) provides a well-e",
      "published": "2026-02-12",
      "categories": [
        "cs.SE",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.12443v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.11527v1",
      "title": "CausalAgent: A Conversational Multi-Agent System for End-to-End Causal Inference",
      "authors": [
        "Jiawei Zhu",
        "Wei Chen",
        "Ruichu Cai"
      ],
      "summary": "Causal inference holds immense value in fields such as healthcare, economics, and social sciences. However, traditional causal analysis workflows impose significant technical barriers, requiring researchers to possess dual backgrounds in statistics and computer science, while manually selecting algorithms, handling data quality issues, and interpreting complex results. To address these challenges, we propose CausalAgent, a conversational multi-agent system for end-to-end causal inference. The sy",
      "published": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11527v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.11522v1",
      "title": "Implications of AI Involvement for Trust in Expert Advisory Workflows Under Epistemic Dependence",
      "authors": [
        "Dennis Kim",
        "Roya Daneshi",
        "Bruce Draper",
        "Sarath Sreedharan"
      ],
      "summary": "The increasing integration of AI-powered tools into expert workflows, such as medicine, law, and finance, raises a critical question: how does AI involvement influence a user's trust in the human expert, the AI system, and their combination? To investigate this, we conducted a user study (N=77) featuring a simulated course-planning task. We compared various conditions that differed in both the presence of AI and the specific mode of human-AI collaboration. Our results indicate that while the adv",
      "published": "2026-02-12",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.11522v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.12311v1",
      "title": "Perceptual Self-Reflection in Agentic Physics Simulation Code Generation",
      "authors": [
        "Prashant Shende",
        "Bradley Camburn"
      ],
      "summary": "We present a multi-agent framework for generating physics simulation code from natural language descriptions, featuring a novel perceptual self-reflection mechanism for validation. The system employs four specialized agents: a natural language interpreter that converts user requests into physics-based descriptions; a technical requirements generator that produces scaled simulation parameters; a physics code generator with automated self-correction; and a physics validator that implements percept",
      "published": "2026-02-12",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.12311v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.12083v1",
      "title": "Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication",
      "authors": [
        "Antonin Sulc"
      ],
      "summary": "As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to ",
      "published": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "link": "https://arxiv.org/abs/2602.12083v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.11897v2",
      "title": "Agentic AI for Cybersecurity: A Meta-Cognitive Architecture for Governable Autonomy",
      "authors": [
        "Andrei Kojukhov",
        "Arkady Bovshover"
      ],
      "summary": "Contemporary AI-driven cybersecurity systems are predominantly architected as model-centric detection and automation pipelines optimized for task-level performance metrics such as accuracy and response latency. While effective for bounded classification tasks, these architectures struggle to support accountable decision-making under adversarial uncertainty, where actions must be justified, governed, and aligned with organizational and regulatory constraints. This paper argues that cybersecurity ",
      "published": "2026-02-12",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11897v2",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.11574v1",
      "title": "Learning to Configure Agentic AI Systems",
      "authors": [
        "Aditya Taparia",
        "Som Sagar",
        "Ransalu Senanayake"
      ],
      "summary": "Configuring LLM-based agent systems involves choosing workflows, tools, token budgets, and prompts from a large combinatorial design space, and is typically handled today by fixed large templates or hand-tuned heuristics. This leads to brittle behavior and unnecessary compute, since the same cumbersome configuration is often applied to both easy and hard input queries. We formulate agent configuration as a query-wise decision problem and introduce ARC (Agentic Resource & Configuration learner), ",
      "published": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11574v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.11924v1",
      "title": "Who Does What? Archetypes of Roles Assigned to LLMs During Human-AI Decision-Making",
      "authors": [
        "Shreya Chappidi",
        "Jatinder Singh",
        "Andra V. Krauze"
      ],
      "summary": "LLMs are increasingly supporting decision-making across high-stakes domains, requiring critical reflection on the socio-technical factors that shape how humans and LLMs are assigned roles and interact during human-in-the-loop decision-making. This paper introduces the concept of human-LLM archetypes -- defined as re-curring socio-technical interaction patterns that structure the roles of humans and LLMs in collaborative decision-making. We describe 17 human-LLM archetypes derived from a scoping ",
      "published": "2026-02-12",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11924v1",
      "matched_keyword": "human-LLM interaction",
      "source": "arxiv"
    },
    {
      "id": "2602.11025v1",
      "title": "Reality Copilot: Voice-First Human-AI Collaboration in Mixed Reality Using Large Multimodal Models",
      "authors": [
        "Liuchuan Yu",
        "Yongqi Zhang",
        "Lap-Fai Yu"
      ],
      "summary": "Large Multimodal Models (LMMs) have shown strong potential for assisting users in tasks, such as programming, content creation, and information access, yet their interaction remains largely limited to traditional interfaces such as desktops and smartphones. Meanwhile, advances in mixed reality (MR) hardware have enabled applications that extend beyond entertainment and into everyday use. However, most existing MR systems rely primarily on manual input (e.g., hand gestures or controllers) and pro",
      "published": "2026-02-11",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.11025v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.11412v1",
      "title": "When Visibility Outpaces Verification: Delayed Verification and Narrative Lock-in in Agentic AI Discourse",
      "authors": [
        "Hanjing Shi",
        "Dominic DiFranzo"
      ],
      "summary": "Agentic AI systems-autonomous entities capable of independent planning and execution-reshape the landscape of human-AI trust. Long before direct system exposure, user expectations are mediated through high-stakes public discourse on social platforms. However, platform-mediated engagement signals (e.g., upvotes) may inadvertently function as a ``credibility proxy,'' potentially stifling critical evaluation.   This paper investigates the interplay between social proof and verification timing in on",
      "published": "2026-02-11",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.11412v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.11301v1",
      "title": "The PBSAI Governance Ecosystem: A Multi-Agent AI Reference Architecture for Securing Enterprise AI Estates",
      "authors": [
        "John M. Willis"
      ],
      "summary": "Enterprises are rapidly deploying large language models, retrieval augmented generation pipelines, and tool using agents into production, often on shared high performance computing clusters and cloud accelerator platforms that also support defensive analytics. These systems increasingly function not as isolated models but as AI estates: socio technical systems spanning models, agents, data pipelines, security tooling, human workflows, and hyperscale infrastructure. Existing governance and securi",
      "published": "2026-02-11",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "link": "https://arxiv.org/abs/2602.11301v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.11024v1",
      "title": "Chain-of-Look Spatial Reasoning for Dense Surgical Instrument Counting",
      "authors": [
        "Rishikesh Bhyri",
        "Brian R Quaranto",
        "Philip J Seger",
        "Kaity Tung",
        "Brendan Fox"
      ],
      "summary": "Accurate counting of surgical instruments in Operating Rooms (OR) is a critical prerequisite for ensuring patient safety during surgery. Despite recent progress of large visual-language models and agentic AI, accurately counting such instruments remains highly challenging, particularly in dense scenarios where instruments are tightly clustered. To address this problem, we introduce Chain-of-Look, a novel visual reasoning framework that mimics the sequential human counting process by enforcing a ",
      "published": "2026-02-11",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11024v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.10479v1",
      "title": "From Prompt-Response to Goal-Directed Systems: The Evolution of Agentic AI Software Architecture",
      "authors": [
        "Mamdouh Alenezi"
      ],
      "summary": "Agentic AI denotes an architectural transition from stateless, prompt-driven generative models toward goal-directed systems capable of autonomous perception, planning, action, and adaptation through iterative control loops. This paper examines this transition by connecting foundational intelligent agent theories, including reactive, deliberative, and Belief-Desire-Intention models, with contemporary LLM-centric approaches such as tool invocation, memory-augmented reasoning, and multi-agent coord",
      "published": "2026-02-11",
      "categories": [
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.10479v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.10465v1",
      "title": "Authenticated Workflows: A Systems Approach to Protecting Agentic AI",
      "authors": [
        "Mohan Rajagopalan",
        "Vinay Rao"
      ],
      "summary": "Agentic AI systems automate enterprise workflows but existing defenses--guardrails, semantic filters--are probabilistic and routinely bypassed. We introduce authenticated workflows, the first complete trust layer for enterprise agentic AI. Security reduces to protecting four fundamental boundaries: prompts, tools, data, and context. We enforce intent (operations satisfy organizational policies) and integrity (operations are cryptographically authentic) at every boundary crossing, combining crypt",
      "published": "2026-02-11",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.MA"
      ],
      "link": "https://arxiv.org/abs/2602.10465v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.10450v1",
      "title": "Constructing Industrial-Scale Optimization Modeling Benchmark",
      "authors": [
        "Zhong Li",
        "Hongliang Lu",
        "Tao Wei",
        "Wenyu Liu",
        "Yuxuan Chen"
      ],
      "summary": "Optimization modeling underpins decision-making in logistics, manufacturing, energy, and finance, yet translating natural-language requirements into correct optimization formulations and solver-executable code remains labor-intensive. Although large language models (LLMs) have been explored for this task, evaluation is still dominated by toy-sized or synthetic benchmarks, masking the difficulty of industrial problems with $10^{3}$--$10^{6}$ (or more) variables and constraints. A key bottleneck i",
      "published": "2026-02-11",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "link": "https://arxiv.org/abs/2602.10450v1",
      "matched_keyword": "human-LLM interaction",
      "source": "arxiv"
    }
  ],
  "semantic_scholar": [
    {
      "id": "1259e54ca5d2257d44a95569108df1b7ceedbb95",
      "title": "Preclinical basic research of Majuchuanke oral liquid",
      "authors": [
        "Cheng-Jun Yuan"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/1259e54ca5d2257d44a95569108df1b7ceedbb95",
      "matched_keyword": "author:Amershi, Saleema",
      "source": "semantic_scholar"
    },
    {
      "id": "9d0053ad515444e29ff6203da5654982e015ae18",
      "title": "The changes of cardiopulmonary function and the correlation with the ratios of regulatory T cells in OA rats",
      "authors": [
        "Cheng-Jun Yuan"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/9d0053ad515444e29ff6203da5654982e015ae18",
      "matched_keyword": "author:Amershi, Saleema",
      "source": "semantic_scholar"
    },
    {
      "id": "5f95c4bf2c5248098331302ef8b30e5ca08d8c5d",
      "title": "Additive Kunststoffverarbeitung @ MedTech",
      "authors": [
        "M. Eblenkamp",
        "F. Bauer"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/5f95c4bf2c5248098331302ef8b30e5ca08d8c5d",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "8aae4b770177f64faab5b24487b39bf817b50806",
      "title": "Biokompatible Integration von IoT-Elektronik in Kunststoffbauteile",
      "authors": [
        "V. Werner",
        "M. Eblenkamp"
      ],
      "summary": "",
      "published": "2026",
      "citations": 1,
      "link": "https://www.semanticscholar.org/paper/8aae4b770177f64faab5b24487b39bf817b50806",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "d9e7725ae591d649ef42e2fad07ee503429ab5f3",
      "title": "Additive Fertigung in der Lehre und Ausbildung",
      "authors": [
        "Stefan Leonhardt",
        "M. Eblenkamp"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/d9e7725ae591d649ef42e2fad07ee503429ab5f3",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "596f0df250ccf835c7da32692fa991835ef81416",
      "title": "IoT & Werkstoffe: HF-Eigenschaften medizinischer Kunststoffe",
      "authors": [
        "V. Werner",
        "M. Zeppenfeld",
        "M. Eblenkamp"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/596f0df250ccf835c7da32692fa991835ef81416",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "87a61c6d1df62777f8fa7c1835b05c7d1dbaebdd",
      "title": "Schichtweise zu lebensnaher Biomimikry: Hochfunktionsintegrierte Kunststoffsysteme für die zellbasierte Labormedizin",
      "authors": [
        "M. Eblenkamp",
        "Katharina Düregger",
        "Stefan Leonhardt"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/87a61c6d1df62777f8fa7c1835b05c7d1dbaebdd",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    }
  ],
  "hackernews": [
    {
      "id": "46990729",
      "title": "An AI agent published a hit piece on me",
      "link": "https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/",
      "hn_link": "https://news.ycombinator.com/item?id=46990729",
      "points": 2343,
      "comments": 949,
      "published": "2026-02-12",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "46987559",
      "title": "AI agent opens a PR write a blogpost to shames the maintainer who closes it",
      "link": "https://github.com/matplotlib/matplotlib/pull/31132",
      "hn_link": "https://news.ycombinator.com/item?id=46987559",
      "points": 951,
      "comments": 750,
      "published": "2026-02-12",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47009949",
      "title": "An AI agent published a hit piece on me – more things have happened",
      "link": "https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me-part-2/",
      "hn_link": "https://news.ycombinator.com/item?id=47009949",
      "points": 763,
      "comments": 620,
      "published": "2026-02-14",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47006843",
      "title": "The \"AI agent hit piece\" situation clarifies how dumb we are acting",
      "link": "https://ardentperf.com/2026/02/13/the-scott-shambaugh-situation-clarifies-how-dumb-we-are-acting/",
      "hn_link": "https://news.ycombinator.com/item?id=47006843",
      "points": 246,
      "comments": 125,
      "published": "2026-02-13",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47000034",
      "title": "Expensively Quadratic: The LLM Agent Cost Curve",
      "link": "https://blog.exe.dev/expensively-quadratic",
      "hn_link": "https://news.ycombinator.com/item?id=47000034",
      "points": 131,
      "comments": 91,
      "published": "2026-02-13",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "46993587",
      "title": "Show HN: Moltis – AI assistant with memory, tools, and self-extending skills",
      "link": "https://www.moltis.org",
      "hn_link": "https://news.ycombinator.com/item?id=46993587",
      "points": 128,
      "comments": 51,
      "published": "2026-02-12",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47051956",
      "title": "An AI Agent Published a Hit Piece on Me – Forensics and More Fallout",
      "link": "https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me-part-3/",
      "hn_link": "https://news.ycombinator.com/item?id=47051956",
      "points": 118,
      "comments": 80,
      "published": "2026-02-17",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47025478",
      "title": "Show HN: Klaw.sh – Kubernetes for AI agents",
      "link": "https://github.com/klawsh/klaw.sh",
      "hn_link": "https://news.ycombinator.com/item?id=47025478",
      "points": 60,
      "comments": 44,
      "published": "2026-02-15",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47004203",
      "title": "I ditched OpenClaw and built a more secure AI agent (Blink and Mac Mini)",
      "link": "https://coder.com/blog/why-i-ditched-openclaw-and-built-a-more-secure-ai-agent-on-blink-mac-mini",
      "hn_link": "https://news.ycombinator.com/item?id=47004203",
      "points": 52,
      "comments": 58,
      "published": "2026-02-13",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "46997526",
      "title": "Cloudflare adds real-time Markdown rendering for AI agents",
      "link": "https://blog.cloudflare.com/markdown-for-agents/",
      "hn_link": "https://news.ycombinator.com/item?id=46997526",
      "points": 47,
      "comments": 22,
      "published": "2026-02-13",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47002633",
      "title": "Safe YOLO Mode: Running LLM agents in vms with Libvirt and Virsh",
      "link": "https://www.metachris.dev/2026/02/safe-yolo-mode-running-llm-agents-in-vms-with-libvirt-and-virsh/",
      "hn_link": "https://news.ycombinator.com/item?id=47002633",
      "points": 31,
      "comments": 9,
      "published": "2026-02-13",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47049776",
      "title": "Launch HN: Sonarly (YC W26) – AI agent to triage and fix your production alerts",
      "link": "https://sonarly.com/",
      "hn_link": "https://news.ycombinator.com/item?id=47049776",
      "points": 29,
      "comments": 17,
      "published": "2026-02-17",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47017148",
      "title": "AI Agent Lands PRs in Major OSS Projects, Targets Maintainers via Cold Outreach",
      "link": "https://socket.dev/blog/ai-agent-lands-prs-in-major-oss-projects-targets-maintainers-via-cold-outreach",
      "hn_link": "https://news.ycombinator.com/item?id=47017148",
      "points": 16,
      "comments": 1,
      "published": "2026-02-14",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "46997470",
      "title": "Ask HN: What happens when capability decouples from credentials?",
      "link": "https://news.ycombinator.com/item?id=46997470",
      "hn_link": "https://news.ycombinator.com/item?id=46997470",
      "points": 11,
      "comments": 7,
      "published": "2026-02-13",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47060647",
      "title": "How LLM agents endanger open-source projects",
      "link": "https://cusy.io/en/blog/how-llm-agents-endanger-open-source-projects.html",
      "hn_link": "https://news.ycombinator.com/item?id=47060647",
      "points": 7,
      "comments": 2,
      "published": "2026-02-18",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "46991720",
      "title": "BashoBot – A Personal AI Assistant Built with Bash",
      "link": "https://github.com/uraimo/bashobot",
      "hn_link": "https://news.ycombinator.com/item?id=46991720",
      "points": 6,
      "comments": 0,
      "published": "2026-02-12",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47049026",
      "title": "Temporal Raises $300M Series D to Make Agentic AI Real for Companies",
      "link": "https://temporal.io/news/temporal-raises-300M-to-make-agentic-ai-real-for-companies",
      "hn_link": "https://news.ycombinator.com/item?id=47049026",
      "points": 6,
      "comments": 0,
      "published": "2026-02-17",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47011067",
      "title": "AgentRE-Bench: Can LLM Agents Reverse Engineer Malware?",
      "link": "https://www.agentre-bench.ai/",
      "hn_link": "https://news.ycombinator.com/item?id=47011067",
      "points": 5,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47024005",
      "title": "AI is slowly munching away my passion",
      "link": "https://whynot.fail/human/ai-is-slowly-munching-away-my-passion/",
      "hn_link": "https://news.ycombinator.com/item?id=47024005",
      "points": 5,
      "comments": 0,
      "published": "2026-02-15",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "47023667",
      "title": "Show HN: GAIA – open-source, Proactive AI assistant to manage your digital life",
      "link": "https://github.com/theexperiencecompany/gaia",
      "hn_link": "https://news.ycombinator.com/item?id=47023667",
      "points": 5,
      "comments": 4,
      "published": "2026-02-15",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47052655",
      "title": "What happens when your AI assistant does your dating?",
      "link": "https://zyroi.com/blog/when-your-ai-swipes-right",
      "hn_link": "https://news.ycombinator.com/item?id=47052655",
      "points": 4,
      "comments": 1,
      "published": "2026-02-17",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47056400",
      "title": "A Guide to Which AI to Use in the Agentic Era",
      "link": "https://www.oneusefulthing.org/p/a-guide-to-which-ai-to-use-in-the",
      "hn_link": "https://news.ycombinator.com/item?id=47056400",
      "points": 4,
      "comments": 0,
      "published": "2026-02-18",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47028822",
      "title": "An Exercise in Agentic Coding: AV1 Encoder from Scratch in Rust",
      "link": "https://caricio.com/blog/an-exercise-in-agentic-coding-av1-encoder-from-scratch-in-rust/",
      "hn_link": "https://news.ycombinator.com/item?id=47028822",
      "points": 4,
      "comments": 0,
      "published": "2026-02-15",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47045159",
      "title": "AI is slowly munching away my passion",
      "link": "https://whynot.fail/human/ai-is-slowly-munching-away-my-passion/",
      "hn_link": "https://news.ycombinator.com/item?id=47045159",
      "points": 3,
      "comments": 0,
      "published": "2026-02-17",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "47059771",
      "title": "Wordpress.com adds an AI Assistant that can edit, adjust styles, create images",
      "link": "https://techcrunch.com/2026/02/17/wordpress-com-adds-an-ai-assistant-that-can-edit-adjust-styles-create-images-and-more/",
      "hn_link": "https://news.ycombinator.com/item?id=47059771",
      "points": 3,
      "comments": 0,
      "published": "2026-02-18",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47013299",
      "title": "ClickHouse Agentic Data Stack",
      "link": "https://www.youtube.com/watch?v=ubQOsCfjMTI",
      "hn_link": "https://news.ycombinator.com/item?id=47013299",
      "points": 3,
      "comments": 3,
      "published": "2026-02-14",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47024828",
      "title": "Generative and Agentic AI Shift Concern from Tech Debt to Cognitive Debt",
      "link": "https://margaretstorey.com/blog/2026/02/09/cognitive-debt/",
      "hn_link": "https://news.ycombinator.com/item?id=47024828",
      "points": 3,
      "comments": 2,
      "published": "2026-02-15",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47034740",
      "title": "Deterministic Core, Agentic Shell",
      "link": "https://blog.davemo.com/posts/2026-02-14-deterministic-core-agentic-shell.html",
      "hn_link": "https://news.ycombinator.com/item?id=47034740",
      "points": 3,
      "comments": 1,
      "published": "2026-02-16",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47026876",
      "title": "Can agentic coding raise the quality bar?",
      "link": "https://lpalmieri.com/posts/agentic-coding-raises-quality/",
      "hn_link": "https://news.ycombinator.com/item?id=47026876",
      "points": 3,
      "comments": 1,
      "published": "2026-02-15",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47025206",
      "title": "Generative and Agentic AI Shift Concern from Technical Debt to Cognitive Debt",
      "link": "https://simonwillison.net/2026/Feb/15/cognitive-debt/",
      "hn_link": "https://news.ycombinator.com/item?id=47025206",
      "points": 3,
      "comments": 1,
      "published": "2026-02-15",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "46993423",
      "title": "Authenticated Workflows: A Systems Approach to Deterministic Agentic Controls",
      "link": "https://arxiv.org/abs/2602.10465",
      "hn_link": "https://news.ycombinator.com/item?id=46993423",
      "points": 3,
      "comments": 1,
      "published": "2026-02-12",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47060871",
      "title": "100% Autonomous \"Agentic\" Coding Is a Fool's Errand",
      "link": "https://codemanship.wordpress.com/2026/02/18/100-autonomous-agentic-coding-is-a-fools-errand/",
      "hn_link": "https://news.ycombinator.com/item?id=47060871",
      "points": 3,
      "comments": 0,
      "published": "2026-02-18",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47051930",
      "title": "Firecracker \"job receipts\" for metering and auditing LLM agent runs",
      "link": "https://news.ycombinator.com/item?id=47051930",
      "hn_link": "https://news.ycombinator.com/item?id=47051930",
      "points": 2,
      "comments": 0,
      "published": "2026-02-17",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47032312",
      "title": "Ask HN: Do LLM agents need a separate safety layer?",
      "link": "https://news.ycombinator.com/item?id=47032312",
      "hn_link": "https://news.ycombinator.com/item?id=47032312",
      "points": 2,
      "comments": 0,
      "published": "2026-02-16",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47019084",
      "title": "Agent-evals: Metacognitive scoring and boundary testing for LLM coding agents",
      "link": "https://thinkwright.ai/agent-evals",
      "hn_link": "https://news.ycombinator.com/item?id=47019084",
      "points": 2,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47013274",
      "title": "Show HN: AI Station Navigator – LLM=CPU, Agents=Processes, Skills=Apps",
      "link": "https://github.com/canishowtime/ai-station-navigator",
      "hn_link": "https://news.ycombinator.com/item?id=47013274",
      "points": 2,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47013797",
      "title": "Close enough to explain: on collaboration, AI, and staying close to the code",
      "link": "http://stdout.alesr.me/posts/close-enough-to-explain/",
      "hn_link": "https://news.ycombinator.com/item?id=47013797",
      "points": 2,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47059153",
      "title": "Show HN: AI agents designed and shipped this app end-to-end in 36 hours for $270",
      "link": "https://www.ninjaflix.ai/",
      "hn_link": "https://news.ycombinator.com/item?id=47059153",
      "points": 2,
      "comments": 4,
      "published": "2026-02-18",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47047951",
      "title": "Advaita Inquiry Matrix (Aim): Structured Non-Dual Inquiry with AI",
      "link": "https://news.ycombinator.com/item?id=47047951",
      "hn_link": "https://news.ycombinator.com/item?id=47047951",
      "points": 2,
      "comments": 0,
      "published": "2026-02-17",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47066016",
      "title": "Show HN: Sniptail – Turn Slack into a team interface for AI coding agents",
      "link": "https://github.com/Justkog/sniptail",
      "hn_link": "https://news.ycombinator.com/item?id=47066016",
      "points": 2,
      "comments": 0,
      "published": "2026-02-18",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47061684",
      "title": "Investigating the Downstream Effect of AI Assistants on Software Maintainability",
      "link": "https://arxiv.org/abs/2507.00788",
      "hn_link": "https://news.ycombinator.com/item?id=47061684",
      "points": 2,
      "comments": 2,
      "published": "2026-02-18",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47062888",
      "title": "We scaled our AI assistant to use virtually unlimited number of tools",
      "link": "https://gaia-fork-k7yngvswe-gaias-projects-2dead09b.vercel.app/blog/how-tool-calling-works",
      "hn_link": "https://news.ycombinator.com/item?id=47062888",
      "points": 2,
      "comments": 0,
      "published": "2026-02-18",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47036532",
      "title": "Lobster: My Personal AI Assistant",
      "link": "https://www.omarknows.ai/p/meet-lobster-my-personal-ai-assistant",
      "hn_link": "https://news.ycombinator.com/item?id=47036532",
      "points": 2,
      "comments": 0,
      "published": "2026-02-16",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47027121",
      "title": "PicoClaw: Ultra-Efficient AI Assistant in Go",
      "link": "https://github.com/sipeed/picoclaw",
      "hn_link": "https://news.ycombinator.com/item?id=47027121",
      "points": 2,
      "comments": 0,
      "published": "2026-02-15",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47019250",
      "title": "Show HN: FoodCraft – AI cooking assistant that adapts recipes to your diet/goals",
      "link": "https://foodcraft.app/en",
      "hn_link": "https://news.ycombinator.com/item?id=47019250",
      "points": 2,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47058763",
      "title": "Ask HN: Are we missing a middleware layer between LLM agents and the web?",
      "link": "https://news.ycombinator.com/item?id=47058763",
      "hn_link": "https://news.ycombinator.com/item?id=47058763",
      "points": 1,
      "comments": 2,
      "published": "2026-02-18",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47046780",
      "title": "Show HN: Preventing runaway LLM agents (enforcement layer)",
      "link": "https://github.com/amabito/veronica-core",
      "hn_link": "https://news.ycombinator.com/item?id=47046780",
      "points": 1,
      "comments": 2,
      "published": "2026-02-17",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "46997728",
      "title": "Authoring, simulating, and testing dynamic human-AI group conversations",
      "link": "https://research.google/blog/beyond-one-on-one-authoring-simulating-and-testing-dynamic-human-ai-group-conversations/",
      "hn_link": "https://news.ycombinator.com/item?id=46997728",
      "points": 1,
      "comments": 0,
      "published": "2026-02-13",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "47029655",
      "title": "AI is slowly munching away my passion",
      "link": "https://whynot.fail/human/ai-is-slowly-munching-away-my-passion/",
      "hn_link": "https://news.ycombinator.com/item?id=47029655",
      "points": 1,
      "comments": 1,
      "published": "2026-02-16",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "47035701",
      "title": "Show HN: A \"content compiler\" that turns LLM output into validated artifacts",
      "link": "https://gixo.ai",
      "hn_link": "https://news.ycombinator.com/item?id=47035701",
      "points": 1,
      "comments": 0,
      "published": "2026-02-16",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "46987655",
      "title": "Show HN: Pablituuu – Web Video Editor with AI Highlights (WebGL, FFmpeg WASM)",
      "link": "https://pablituuu.space/login",
      "hn_link": "https://news.ycombinator.com/item?id=46987655",
      "points": 1,
      "comments": 0,
      "published": "2026-02-12",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "46986940",
      "title": "Show HN: SuperLocalMemory– Local-first AI memory for Claude, Cursor and 16+tools",
      "link": "https://github.com/varun369/SuperLocalMemoryV2",
      "hn_link": "https://news.ycombinator.com/item?id=46986940",
      "points": 1,
      "comments": 0,
      "published": "2026-02-12",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47063668",
      "title": "Show HN: Supervisor IDE – Command center for coding agents in complex projects",
      "link": "https://nexroo.ai/supervisor",
      "hn_link": "https://news.ycombinator.com/item?id=47063668",
      "points": 1,
      "comments": 0,
      "published": "2026-02-18",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    }
  ],
  "reddit": [],
  "blogs": [
    {
      "名称": "Anthropic Research",
      "链接": "https://anthropic.com/research",
      "说明": "Claude生态，MCP协议，human-AI交互理念"
    },
    {
      "名称": "OpenAI Research",
      "链接": "https://openai.com/research",
      "说明": "GPT系列、agent框架、ChatGPT产品迭代"
    },
    {
      "名称": "Google DeepMind",
      "链接": "https://deepmind.google/research",
      "说明": "Gemini、agent研究、AI safety"
    },
    {
      "名称": "Microsoft Research Blog",
      "链接": "https://microsoft.com/en-us/research/blog",
      "说明": "HAX Toolkit, Human-AI Interaction Guidelines, Copilot"
    },
    {
      "名称": "Meta AI (FAIR)",
      "链接": "https://ai.meta.com/research",
      "说明": "Llama开源生态"
    },
    {
      "名称": "Amazon Science",
      "链接": "https://amazon.science",
      "说明": "应用型AI研究"
    },
    {
      "名称": "Apple Machine Learning",
      "链接": "https://machinelearning.apple.com",
      "说明": "设备端AI、隐私AI"
    },
    {
      "名称": "Hugging Face Blog",
      "链接": "https://huggingface.co/blog",
      "说明": "开源模型、工具、社区趋势"
    },
    {
      "名称": "LangChain Blog",
      "链接": "https://blog.langchain.dev",
      "说明": "Agent框架生态风向标"
    }
  ],
  "newsletters": [
    {
      "名称": "Simon Willison's Blog",
      "链接": "https://simonwillison.net",
      "作者": "Simon Willison",
      "说明": "LLM生态最全面的实践者视角"
    },
    {
      "名称": "Ahead of AI",
      "链接": "https://magazine.sebastianraschka.com",
      "作者": "Sebastian Raschka",
      "说明": "LLM研究深度解读"
    },
    {
      "名称": "Interconnects",
      "链接": "https://interconnects.ai",
      "作者": "Nathan Lambert",
      "说明": "RLHF/对齐方向"
    },
    {
      "名称": "Latent Space",
      "链接": "https://latent.space",
      "作者": "Swyx & Alessio",
      "说明": "AI工程师视角，agent和tooling"
    },
    {
      "名称": "MIT Technology Review",
      "链接": "https://technologyreview.com",
      "作者": "编辑团队",
      "说明": "日刊科技新闻"
    },
    {
      "名称": "The Batch",
      "链接": "https://deeplearning.ai/the-batch",
      "作者": "Andrew Ng",
      "说明": "AI新闻周报"
    },
    {
      "名称": "Import AI",
      "链接": "https://importai.substack.com",
      "作者": "Jack Clark",
      "说明": "偏policy和大趋势"
    },
    {
      "名称": "阮一峰的网络日志",
      "链接": "https://ruanyifeng.com/blog",
      "作者": "阮一峰",
      "说明": "中文技术圈信号"
    }
  ],
  "researchers": [
    {
      "姓名": "Anthropic",
      "链接": "https://x.com/AnthropicAI",
      "平台": "X",
      "说明": "AI safety and research company"
    },
    {
      "姓名": "Claude",
      "链接": "https://x.com/claudeai",
      "平台": "X",
      "说明": "safe, accurate, and secure"
    },
    {
      "姓名": "OpenAI",
      "链接": "https://x.com/OpenAI",
      "平台": "X",
      "说明": "artificial general intelligence benefits all of humanity"
    },
    {
      "姓名": "Sherry Tongshuang Wu",
      "链接": "https://x.com/tongshuangwu",
      "平台": "X",
      "说明": "HCI×NLP，human-AI interaction"
    },
    {
      "姓名": "Diyi Yang",
      "链接": "https://x.com/Diyi_Yang",
      "平台": "X",
      "说明": "Human-AI"
    },
    {
      "姓名": "Ziang Xiao",
      "链接": "https://x.com/ZiangXiao",
      "平台": "X",
      "说明": "AI4SocialScience, Model Evaluation, Information Seeking"
    },
    {
      "姓名": "Mark Dredze",
      "链接": "https://x.com/mdredze",
      "平台": "X",
      "说明": "NLP"
    },
    {
      "姓名": "Wesley Hanwen Deng",
      "链接": "https://x.com/wes_deng",
      "平台": "X",
      "说明": "Human-AI"
    },
    {
      "姓名": "Mina Lee",
      "链接": "https://x.com/MinaLee__",
      "平台": "X",
      "说明": "Human-AI collaborative writing"
    },
    {
      "姓名": "Jentse Huang",
      "链接": "https://x.com/JentseHuang",
      "平台": "X",
      "说明": "LLM + Social Science, Multi-Agent, AI Fairness"
    },
    {
      "姓名": "Toby Jia-Jun Li",
      "链接": "https://x.com/TobyJLi",
      "平台": "X",
      "说明": "End-user programming, human-AI systems"
    },
    {
      "姓名": "Dakuo Wang",
      "链接": "https://x.com/dakuowang",
      "平台": "X",
      "说明": "Human-AI collaboration, CSCW"
    },
    {
      "姓名": "Percy Liang",
      "链接": "https://x.com/percyliang",
      "平台": "X",
      "说明": "LLM evaluation框架"
    },
    {
      "姓名": "Michael Bernstein",
      "链接": "https://x.com/msbernst",
      "平台": "X",
      "说明": "Generative agents, social computing"
    },
    {
      "姓名": "Simon Willison",
      "链接": "https://x.com/simonw",
      "平台": "X",
      "说明": "LLM工具生态最佳信息源"
    },
    {
      "姓名": "Joon Sung Park",
      "链接": "https://x.com/joon_s_pk",
      "平台": "X",
      "说明": "Social Simulations"
    },
    {
      "姓名": "Andrej Karpathy",
      "链接": "https://x.com/karpathy",
      "平台": "X",
      "说明": "深度技术解读"
    },
    {
      "姓名": "Swyx",
      "链接": "https://x.com/swyx",
      "平台": "X",
      "说明": "AI工程/agent生态trend"
    },
    {
      "姓名": "Saleema Amershi",
      "链接": "https://x.com/SaleemaAmershi",
      "平台": "X",
      "说明": "Human-AI Interaction Guidelines"
    },
    {
      "姓名": "Q. Vera Liao",
      "链接": "https://x.com/QVeraLiao",
      "平台": "X",
      "说明": "Explainable AI, responsible AI in HCI"
    },
    {
      "姓名": "Xiang 'Anthony' Chen",
      "链接": "https://x.com/_xiang_chen_",
      "平台": "X",
      "说明": "Interactive AI systems"
    }
  ],
  "podcasts": [
    {
      "名称": "Latent Space Podcast",
      "链接": "https://latent.space",
      "说明": "AI工程最前沿，agent相关讨论"
    },
    {
      "名称": "TWIML AI Podcast",
      "链接": "https://twimlai.com",
      "说明": "学术+工业混合视角"
    },
    {
      "名称": "NeurIPS/CHI 录播",
      "链接": "https://youtube.com",
      "说明": "重要talk的录播"
    }
  ],
  "conferences": [
    {
      "名称": "CHI GenAICHI Workshop",
      "链接": "https://genai-chi.github.io",
      "频率": "年度",
      "说明": "Generative AI × HCI"
    },
    {
      "名称": "HHAI Conference",
      "链接": "https://hhai-conference.org",
      "频率": "年度",
      "说明": "Hybrid Human-AI Intelligence"
    },
    {
      "名称": "CHI TREW Workshop",
      "链接": "https://trew-workshop.github.io",
      "频率": "年度",
      "说明": "Trust & Reliance in Human-AI Workflows"
    },
    {
      "名称": "ACL/EMNLP HCI+NLP Workshop",
      "链接": "https://aclanthology.org",
      "频率": "年度",
      "说明": "HCI×NLP交叉"
    },
    {
      "名称": "IUI Conference",
      "链接": "https://iui.acm.org",
      "频率": "年度",
      "说明": "Intelligent User Interfaces"
    },
    {
      "名称": "NeurIPS/ICML Agent Workshops",
      "链接": "https://neurips.cc",
      "频率": "年度",
      "说明": "系统/ML视角的agent研究"
    }
  ]
}