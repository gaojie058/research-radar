{
  "meta": {
    "fetched_at": "2026-02-20T17:04:58.043914",
    "lookback_days": 7,
    "keywords": [
      "human-AI collaboration",
      "LLM agent",
      "AI agent",
      "agentic AI",
      "human-centered AI",
      "qualitative analysis LLM",
      "human-LLM interaction",
      "responsible AI",
      "trustworthy AI",
      "AI-assisted analysis",
      "collaborative AI systems",
      "computer-supported cooperative work"
    ]
  },
  "arxiv": [
    {
      "id": "2602.17221v1",
      "title": "From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences",
      "authors": [
        "Yi-Chih Huang"
      ],
      "summary": "Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a \"methodological experiment,\" this study proposes an AI Agent-based collaborative research workflow (Agentic Workflow) for humanities and social science research. Taiwan's Claude.ai usage data (N = 7,729 conversations, November 2025) from the Anthropic Economic Index ",
      "published": "2026-02-19",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "link": "https://arxiv.org/abs/2602.17221v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.17106v1",
      "title": "Toward Trustworthy Evaluation of Sustainability Rating Methodologies: A Human-AI Collaborative Framework for Benchmark Dataset Construction",
      "authors": [
        "Xiaoran Cai",
        "Wang Yang",
        "Xiyu Ren",
        "Chekun Law",
        "Rohit Sharma"
      ],
      "summary": "Sustainability or ESG rating agencies use company disclosures and external data to produce scores or ratings that assess the environmental, social, and governance performance of a company. However, sustainability ratings across agencies for a single company vary widely, limiting their comparability, credibility, and relevance to decision-making. To harmonize the rating results, we propose adopting a universal human-AI collaboration framework to generate trustworthy benchmark datasets for evaluat",
      "published": "2026-02-19",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.17106v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.17084v1",
      "title": "How AI Coding Agents Communicate: A Study of Pull Request Description Characteristics and Human Review Responses",
      "authors": [
        "Kan Watanabe",
        "Rikuto Tsuchida",
        "Takahiro Monno",
        "Bin Huang",
        "Kazuma Yamasaki"
      ],
      "summary": "The rapid adoption of large language models has led to the emergence of AI coding agents that autonomously create pull requests on GitHub. However, how these agents differ in their pull request description characteristics, and how human reviewers respond to them, remains underexplored. In this study, we conduct an empirical analysis of pull requests created by five AI coding agents using the AIDev dataset. We analyze agent differences in pull request description characteristics, including struct",
      "published": "2026-02-19",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.17084v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.17083v1",
      "title": "Rememo: A Research-through-Design Inquiry Towards an AI-in-the-loop Therapist's Tool for Dementia Reminiscence",
      "authors": [
        "Celeste Seah",
        "Yoke Chuan Lee",
        "Jung-Joo Lee",
        "Ching-Chiuan Yen",
        "Clement Zheng"
      ],
      "summary": "Reminiscence therapy (RT) is a common non-pharmacological intervention in dementia care. Recent technology-mediated interventions have largely focused on people with dementia through solutions that replace human facilitators with conversational agents. However, the relational work of facilitation is critical in the effectiveness of RT. Hence, we developed Rememo, a therapist-oriented tool that integrates Generative AI to support and enrich human facilitation in RT. Our tool aims to support the i",
      "published": "2026-02-19",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.17083v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.17622v1",
      "title": "What Makes a Good LLM Agent for Real-world Penetration Testing?",
      "authors": [
        "Gelei Deng",
        "Yi Liu",
        "Yuekang Li",
        "Ruozhao Yang",
        "Xiaofei Xie"
      ],
      "summary": "LLM-based agents show promise for automating penetration testing, yet reported performance varies widely across systems and benchmarks. We analyze 28 LLM-based penetration testing systems and evaluate five representative implementations across three benchmarks of increasing complexity. Our analysis reveals two distinct failure modes: Type A failures stem from capability gaps (missing tools, inadequate prompts) that engineering readily addresses, while Type B failures persist regardless of toolin",
      "published": "2026-02-19",
      "categories": [
        "cs.CR",
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.17622v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.17547v1",
      "title": "KLong: Training LLM Agent for Extremely Long-horizon Tasks",
      "authors": [
        "Yue Liu",
        "Zhiyuan Hu",
        "Flood Sung",
        "Jiaheng Zhang",
        "Bryan Hooi"
      ],
      "summary": "This paper introduces KLong, an open-source LLM agent trained to solve extremely long-horizon tasks. The principle is to first cold-start the model via trajectory-splitting SFT, then scale it via progressive RL training. Specifically, we first activate basic agentic abilities of a base model with a comprehensive SFT recipe. Then, we introduce Research-Factory, an automated pipeline that generates high-quality training data by collecting research papers and constructing evaluation rubrics. Using ",
      "published": "2026-02-19",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.17547v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.17038v1",
      "title": "Phase-Aware Mixture of Experts for Agentic Reinforcement Learning",
      "authors": [
        "Shengtian Yang",
        "Yu Li",
        "Shuo He",
        "Yewen Li",
        "Qingpeng Cai"
      ],
      "summary": "Reinforcement learning (RL) has equipped LLM agents with a strong ability to solve complex tasks. However, existing RL methods normally use a \\emph{single} policy network, causing \\emph{simplicity bias} where simple tasks occupy most parameters and dominate gradient updates, leaving insufficient capacity for complex tasks. A plausible remedy could be employing the Mixture-of-Experts (MoE) architecture in the policy network, as MoE allows different parameters (experts) to specialize in different ",
      "published": "2026-02-19",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.17038v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.17641v1",
      "title": "FAMOSE: A ReAct Approach to Automated Feature Discovery",
      "authors": [
        "Keith Burghardt",
        "Jienan Liu",
        "Sadman Sakib",
        "Yuning Hao",
        "Bo Li"
      ],
      "summary": "Feature engineering remains a critical yet challenging bottleneck in machine learning, particularly for tabular data, as identifying optimal features from an exponentially large feature space traditionally demands substantial domain expertise. To address this challenge, we introduce FAMOSE (Feature AugMentation and Optimal Selection agEnt), a novel framework that leverages the ReAct paradigm to autonomously explore, generate, and refine features while integrating feature selection and evaluation",
      "published": "2026-02-19",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.17641v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.17308v1",
      "title": "MedClarify: An information-seeking AI agent for medical diagnosis with case-specific follow-up questions",
      "authors": [
        "Hui Min Wong",
        "Philip Heesen",
        "Pascal Janetzky",
        "Martin Bendszus",
        "Stefan Feuerriegel"
      ],
      "summary": "Large language models (LLMs) are increasingly used for diagnostic tasks in medicine. In clinical practice, the correct diagnosis can rarely be immediately inferred from the initial patient presentation alone. Rather, reaching a diagnosis often involves systematic history taking, during which clinicians reason over multiple potential conditions through iterative questioning to resolve uncertainty. This process requires considering differential diagnoses and actively excluding emergencies that dem",
      "published": "2026-02-19",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.17308v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.17442v1",
      "title": "WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation",
      "authors": [
        "Marco Avolio",
        "Potito Aghilar",
        "Sabino Roccotelli",
        "Vito Walter Anelli",
        "Chiara Mallamaci"
      ],
      "summary": "Innovation in Recommender Systems is currently impeded by a fractured ecosystem, where researchers must choose between the ease of in-memory experimentation and the costly, complex rewriting required for distributed industrial engines. To bridge this gap, we present WarpRec, a high-performance framework that eliminates this trade-off through a novel, backend-agnostic architecture. It includes 50+ state-of-the-art algorithms, 40 metrics, and 19 filtering and splitting strategies that seamlessly t",
      "published": "2026-02-19",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "link": "https://arxiv.org/abs/2602.17442v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.17271v1",
      "title": "Federated Latent Space Alignment for Multi-user Semantic Communications",
      "authors": [
        "Giuseppe Di Poce",
        "Mario Edoardo Pandolfo",
        "Emilio Calvanese Strinati",
        "Paolo Di Lorenzo"
      ],
      "summary": "Semantic communication aims to convey meaning for effective task execution, but differing latent representations in AI-native devices can cause semantic mismatches that hinder mutual understanding. This paper introduces a novel approach to mitigating latent space misalignment in multi-agent AI- native semantic communications. In a downlink scenario, we consider an access point (AP) communicating with multiple users to accomplish a specific AI-driven task. Our method implements a protocol that sh",
      "published": "2026-02-19",
      "categories": [
        "cs.IT",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.17271v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.17096v1",
      "title": "Agentic Wireless Communication for 6G: Intent-Aware and Continuously Evolving Physical-Layer Intelligence",
      "authors": [
        "Zhaoyang Li",
        "Xingzhi Jin",
        "Junyu Pan",
        "Qianqian Yang",
        "Zhiguo Shi"
      ],
      "summary": "As 6G wireless systems evolve, growing functional complexity and diverse service demands are driving a shift from rule-based control to intent-driven autonomous intelligence. User requirements are no longer captured by a single metric (e.g., throughput or reliability), but by multi-dimensional objectives such as latency sensitivity, energy preference, computational constraints, and service-level requirements. These objectives may also change over time due to environmental dynamics and user-netwo",
      "published": "2026-02-19",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.17096v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.17053v1",
      "title": "RFEval: Benchmarking Reasoning Faithfulness under Counterfactual Reasoning Intervention in Large Reasoning Models",
      "authors": [
        "Yunseok Han",
        "Yejoon Lee",
        "Jaeyoung Do"
      ],
      "summary": "Large Reasoning Models (LRMs) exhibit strong performance, yet often produce rationales that sound plausible but fail to reflect their true decision process, undermining reliability and trust. We introduce a formal framework for reasoning faithfulness, defined by two testable conditions: stance consistency (a coherent stance linking reasoning to answer) and causal influence (the stated reasoning causally drives the answer under output-level interventions), explicitly decoupled from accuracy. To o",
      "published": "2026-02-19",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.17053v1",
      "matched_keyword": "trustworthy AI",
      "source": "arxiv"
    },
    {
      "id": "2602.16140v1",
      "title": "Human-AI Collaboration in Large Language Model-Integrated Building Energy Management Systems: The Role of User Domain Knowledge and AI Literacy",
      "authors": [
        "Wooyoung Jung",
        "Kahyun Jeon",
        "Prosper Babon-Ayeng"
      ],
      "summary": "This study aimed to comprehend how user domain knowledge and artificial intelligence (AI) literacy impact the effective use of human-AI interactive building energy management system (BEMS). While prior studies have investigated the potential of integrating large language models (LLMs) into BEMS or building energy modeling, very few studies have examined how user interact with such systems. We conducted a systematic role-playing experiment, where 85 human subjects interacted with an advanced gene",
      "published": "2026-02-18",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16140v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.16958v1",
      "title": "Automating Agent Hijacking via Structural Template Injection",
      "authors": [
        "Xinhao Deng",
        "Jiaqing Wu",
        "Miao Chen",
        "Yue Xiao",
        "Ke Xu"
      ],
      "summary": "Agent hijacking, highlighted by OWASP as a critical threat to the Large Language Model (LLM) ecosystem, enables adversaries to manipulate execution by injecting malicious instructions into retrieved content. Most existing attacks rely on manually crafted, semantics-driven prompt manipulation, which often yields low attack success rates and limited transferability to closed-source commercial models. In this paper, we propose Phantom, an automated agent hijacking framework built upon Structured Te",
      "published": "2026-02-18",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.16958v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16953v1",
      "title": "LLM4Cov: Execution-Aware Agentic Learning for High-coverage Testbench Generation",
      "authors": [
        "Hejia Zhang",
        "Zhongming Yu",
        "Chia-Tung Ho",
        "Haoxing Ren",
        "Brucek Khailany"
      ],
      "summary": "Execution-aware LLM agents offer a promising paradigm for learning from tool feedback, but such feedback is often expensive and slow to obtain, making online reinforcement learning (RL) impractical. High-coverage hardware verification exemplifies this challenge due to its reliance on industrial simulators and non-differentiable execution signals. We propose LLM4Cov, an offline agent-learning framework that models verification as memoryless state transitions guided by deterministic evaluators. Bu",
      "published": "2026-02-18",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.16953v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16943v1",
      "title": "Mind the GAP: Text Safety Does Not Transfer to Tool-Call Safety in LLM Agents",
      "authors": [
        "Arnold Cartagena",
        "Ariane Teixeira"
      ],
      "summary": "Large language models deployed as agents increasingly interact with external systems through tool calls--actions with real-world consequences that text outputs alone do not carry. Safety evaluations, however, overwhelmingly measure text-level refusal behavior, leaving a critical question unanswered: does alignment that suppresses harmful text also suppress harmful actions? We introduce the GAP benchmark, a systematic evaluation framework that measures divergence between text-level safety and too",
      "published": "2026-02-18",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.16943v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16901v1",
      "title": "AgentLAB: Benchmarking LLM Agents against Long-Horizon Attacks",
      "authors": [
        "Tanqiu Jiang",
        "Yuhui Wang",
        "Jiacheng Liang",
        "Ting Wang"
      ],
      "summary": "LLM agents are increasingly deployed in long-horizon, complex environments to solve challenging problems, but this expansion exposes them to long-horizon attacks that exploit multi-turn user-agent-environment interactions to achieve objectives infeasible in single-turn settings. To measure agent vulnerabilities to such risks, we present AgentLAB, the first benchmark dedicated to evaluating LLM agent susceptibility to adaptive, long-horizon attacks. Currently, AgentLAB supports five novel attack ",
      "published": "2026-02-18",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16901v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16699v2",
      "title": "Calibrate-Then-Act: Cost-Aware Exploration in LLM Agents",
      "authors": [
        "Wenxuan Ding",
        "Nicholas Tomlin",
        "Greg Durrett"
      ],
      "summary": "LLMs are increasingly being used for complex problems which are not necessarily resolved in a single response, but require interacting with an environment to acquire information. In these scenarios, LLMs must reason about inherent cost-uncertainty tradeoffs in when to stop exploring and commit to an answer. For instance, on a programming task, an LLM should test a generated code snippet if it is uncertain about the correctness of that code; the cost of writing a test is nonzero, but typically lo",
      "published": "2026-02-18",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16699v2",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16379v1",
      "title": "Label-Consistent Data Generation for Aspect-Based Sentiment Analysis Using LLM Agents",
      "authors": [
        "Mohammad H. A. Monfared",
        "Lucie Flek",
        "Akbar Karimi"
      ],
      "summary": "We propose an agentic data augmentation method for Aspect-Based Sentiment Analysis (ABSA) that uses iterative generation and verification to produce high quality synthetic training examples. To isolate the effect of agentic structure, we also develop a closely matched prompting-based baseline using the same model and instructions. Both methods are evaluated across three ABSA subtasks (Aspect Term Extraction (ATE), Aspect Sentiment Classification (ATSC), and Aspect Sentiment Pair Extraction (ASPE",
      "published": "2026-02-18",
      "categories": [
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.16379v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16346v2",
      "title": "Helpful to a Fault: Measuring Illicit Assistance in Multi-Turn, Multilingual LLM Agents",
      "authors": [
        "Nivya Talokar",
        "Ayush K Tarun",
        "Murari Mandal",
        "Maksym Andriushchenko",
        "Antoine Bosselut"
      ],
      "summary": "LLM-based agents execute real-world workflows via tools and memory. These affordances enable ill-intended adversaries to also use these agents to carry out complex misuse scenarios. Existing agent misuse benchmarks largely test single-prompt instructions, leaving a gap in measuring how agents end up helping with harmful or illegal tasks over multiple turns. We introduce STING (Sequential Testing of Illicit N-step Goal execution), an automated red-teaming framework that constructs a step-by-step ",
      "published": "2026-02-18",
      "categories": [
        "cs.CL",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.16346v2",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16246v1",
      "title": "Toward Scalable Verifiable Reward: Proxy State-Based Evaluation for Multi-turn Tool-Calling LLM Agents",
      "authors": [
        "Yun-Shiuan Chuang",
        "Chaitanya Kulkarni",
        "Alec Chiu",
        "Avinash Thangali",
        "Zijie Pan"
      ],
      "summary": "Interactive large language model (LLM) agents operating via multi-turn dialogue and multi-step tool calling are increasingly used in production. Benchmarks for these agents must both reliably compare models and yield on-policy training data. Prior agentic benchmarks (e.g., tau-bench, tau2-bench, AppWorld) rely on fully deterministic backends, which are costly to build and iterate. We propose Proxy State-Based Evaluation, an LLM-driven simulation framework that preserves final state-based evaluat",
      "published": "2026-02-18",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16246v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16165v1",
      "title": "HiPER: Hierarchical Reinforcement Learning with Explicit Credit Assignment for Large Language Model Agents",
      "authors": [
        "Jiangweizhi Peng",
        "Yuanxin Liu",
        "Ruida Zhou",
        "Charles Fleming",
        "Zhaoran Wang"
      ],
      "summary": "Training LLMs as interactive agents for multi-turn decision-making remains challenging, particularly in long-horizon tasks with sparse and delayed rewards, where agents must execute extended sequences of actions before receiving meaningful feedback. Most existing reinforcement learning (RL) approaches model LLM agents as flat policies operating at a single time scale, selecting one action at each turn. In sparse-reward settings, such flat policies must propagate credit across the entire trajecto",
      "published": "2026-02-18",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16165v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16666v1",
      "title": "Towards a Science of AI Agent Reliability",
      "authors": [
        "Stephan Rabanser",
        "Sayash Kapoor",
        "Peter Kirgis",
        "Kangheng Liu",
        "Saiteja Utpala"
      ],
      "summary": "AI agents are increasingly deployed to execute important tasks. While rising accuracy scores on standard benchmarks suggest rapid progress, many agents still continue to fail in practice. This discrepancy highlights a fundamental limitation of current evaluations: compressing agent behavior into a single success metric obscures critical operational flaws. Notably, it ignores whether agents behave consistently across runs, withstand perturbations, fail predictably, or have bounded error severity.",
      "published": "2026-02-18",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.16666v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16179v2",
      "title": "EnterpriseBench Corecraft: Training Generalizable Agents on High-Fidelity RL Environments",
      "authors": [
        "Sushant Mehta",
        "Logan Ritchie",
        "Suhaas Garre",
        "Nick Heiner",
        "Edwin Chen"
      ],
      "summary": "We show that training AI agents on high-fidelity reinforcement learning environments produces capabilities that generalize beyond the training distribution. We introduce CoreCraft, the first environment in EnterpriseBench, Surge AI's suite of agentic RL environments. CoreCraft is a fully operational enterprise simulation of a customer support organization, comprising over 2,500 entities across 14 entity types with 23 unique tools, designed to measure whether AI agents can perform the multi-step,",
      "published": "2026-02-18",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.16179v2",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16173v1",
      "title": "Learning Personalized Agents from Human Feedback",
      "authors": [
        "Kaiqu Liang",
        "Julia Kruk",
        "Shengyi Qian",
        "Xianjun Yang",
        "Shengjie Bi"
      ],
      "summary": "Modern AI agents are powerful but often fail to align with the idiosyncratic, evolving preferences of individual users. Prior approaches typically rely on static datasets, either training implicit preference models on interaction history or encoding user profiles in external memory. However, these approaches struggle with new users and with preferences that change over time. We introduce Personalized Agents from Human Feedback (PAHF), a framework for continual personalization in which agents lea",
      "published": "2026-02-18",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.16173v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.16844v1",
      "title": "Overseeing Agents Without Constant Oversight: Challenges and Opportunities",
      "authors": [
        "Madeleine Grunde-McLaughlin",
        "Hussein Mozannar",
        "Maya Murad",
        "Jingya Chen",
        "Saleema Amershi"
      ],
      "summary": "To enable human oversight, agentic AI systems often provide a trace of reasoning and action steps. Designing traces to have an informative, but not overwhelming, level of detail remains a critical challenge. In three user studies on a Computer User Agent, we investigate the utility of basic action traces for verification, explore three alternatives via design probes, and test a novel interface's impact on error finding in question-answering tasks. As expected, we find that current practices are ",
      "published": "2026-02-18",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16844v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.16812v1",
      "title": "NeuDiff Agent: A Governed AI Workflow for Single-Crystal Neutron Crystallography",
      "authors": [
        "Zhongcan Xiao",
        "Leyi Zhang",
        "Guannan Zhang",
        "Xiaoping Wang"
      ],
      "summary": "Large-scale facilities increasingly face analysis and reporting latency as the limiting step in scientific throughput, particularly for structurally and magnetically complex samples that require iterative reduction, integration, refinement, and validation. To improve time-to-result and analysis efficiency, NeuDiff Agent is introduced as a governed, tool-using AI workflow for TOPAZ at the Spallation Neutron Source that takes instrument data products through reduction, integration, refinement, and",
      "published": "2026-02-18",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16812v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.15809v1",
      "title": "Decision Quality Evaluation Framework at Pinterest",
      "authors": [
        "Yuqi Tian",
        "Robert Paine",
        "Attila Dobi",
        "Kevin O'Sullivan",
        "Aravindh Manickavasagam"
      ],
      "summary": "Online platforms require robust systems to enforce content safety policies at scale. A critical component of these systems is the ability to evaluate the quality of moderation decisions made by both human agents and Large Language Models (LLMs). However, this evaluation is challenging due to the inherent trade-offs between cost, scale, and trustworthiness, along with the complexity of evolving policies. To address this, we present a comprehensive Decision Quality Evaluation Framework developed a",
      "published": "2026-02-17",
      "categories": [
        "stat.AP",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15809v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15654v1",
      "title": "Zombie Agents: Persistent Control of Self-Evolving LLM Agents via Self-Reinforcing Injections",
      "authors": [
        "Xianglin Yang",
        "Yufei He",
        "Shuo Ji",
        "Bryan Hooi",
        "Jin Song Dong"
      ],
      "summary": "Self-evolving LLM agents update their internal state across sessions, often by writing and reusing long-term memory. This design improves performance on long-horizon tasks but creates a security risk: untrusted external content observed during a benign session can be stored as memory and later treated as instruction. We study this risk and formalize a persistent attack we call a Zombie Agent, where an attacker covertly implants a payload that survives across sessions, effectively turning the age",
      "published": "2026-02-17",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15654v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15456v1",
      "title": "In Agents We Trust, but Who Do Agents Trust? Latent Source Preferences Steer LLM Generations",
      "authors": [
        "Mohammad Aflah Khan",
        "Mahsa Amani",
        "Soumi Das",
        "Bishwamittra Ghosh",
        "Qinyuan Wu"
      ],
      "summary": "Agents based on Large Language Models (LLMs) are increasingly being deployed as interfaces to information on online platforms. These agents filter, prioritize, and synthesize information retrieved from the platforms' back-end databases or via web search. In these scenarios, LLM agents govern the information users receive, by drawing users' attention to particular instances of retrieved information at the expense of others. While much prior work has focused on biases in the information LLMs thems",
      "published": "2026-02-17",
      "categories": [
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.15456v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15325v1",
      "title": "AgriWorld:A World Tools Protocol Framework for Verifiable Agricultural Reasoning with Code-Executing LLM Agents",
      "authors": [
        "Zhixing Zhang",
        "Jesen Zhang",
        "Hao Liu",
        "Qinhan Lv",
        "Jing Yang"
      ],
      "summary": "Foundation models for agriculture are increasingly trained on massive spatiotemporal data (e.g., multi-spectral remote sensing, soil grids, and field-level management logs) and achieve strong performance on forecasting and monitoring. However, these models lack language-based reasoning and interactive capabilities, limiting their usefulness in real-world agronomic workflows. Meanwhile, large language models (LLMs) excel at interpreting and generating text, but cannot directly reason over high-di",
      "published": "2026-02-17",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15325v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15816v1",
      "title": "Developing AI Agents with Simulated Data: Why, what, and how?",
      "authors": [
        "Xiaoran Liu",
        "Istvan David"
      ],
      "summary": "As insufficient data volume and quality remain the key impediments to the adoption of modern subsymbolic AI, techniques of synthetic data generation are in high demand. Simulation offers an apt, systematic approach to generating diverse synthetic data. This chapter introduces the reader to the key concepts, benefits, and challenges of simulation-based synthetic data generation for AI training purposes, and to a reference framework to describe, design, and analyze digital twin-based AI simulation",
      "published": "2026-02-17",
      "categories": [
        "cs.AI",
        "cs.ET"
      ],
      "link": "https://arxiv.org/abs/2602.15816v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15278v1",
      "title": "Visual Persuasion: What Influences Decisions of Vision-Language Models?",
      "authors": [
        "Manuel Cherep",
        "Pranav M R",
        "Pattie Maes",
        "Nikhil Singh"
      ],
      "summary": "The web is littered with images, once created for human consumption and now increasingly interpreted by agents using vision-language models (VLMs). These agents make visual decisions at scale, deciding what to click, recommend, or buy. Yet, we know little about the structure of their visual preferences. We introduce a framework for studying this by placing VLMs in controlled image-based choice tasks and systematically perturbing their inputs. Our key idea is to treat the agent's decision functio",
      "published": "2026-02-17",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15278v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15569v1",
      "title": "\"What Are You Doing?\": Effects of Intermediate Feedback from Agentic LLM In-Car Assistants During Multi-Step Processing",
      "authors": [
        "Johannes Kirmayr",
        "Raphael Wennmacher",
        "Khanh Huynh",
        "Lukas Stappen",
        "Elisabeth André"
      ],
      "summary": "Agentic AI assistants that autonomously perform multi-step tasks raise open questions for user experience: how should such systems communicate progress and reasoning during extended operations, especially in attention-critical contexts such as driving? We investigate feedback timing and verbosity from agentic LLM-based in-car assistants through a controlled, mixed-methods study (N=45) comparing planned steps and intermediate results feedback against silent operation with final-only response. Usi",
      "published": "2026-02-17",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.15569v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.15968v1",
      "title": "From Reflection to Repair: A Scoping Review of Dataset Documentation Tools",
      "authors": [
        "Pedro Reynolds-Cuéllar",
        "Marisol Wong-Villacres",
        "Adriana Alvarado Garcia",
        "Heila Precel"
      ],
      "summary": "Dataset documentation is widely recognized as essential for the responsible development of automated systems. Despite growing efforts to support documentation through different kinds of artifacts, little is known about the motivations shaping documentation tool design or the factors hindering their adoption. We present a systematic review supported by mixed-methods analysis of 59 dataset documentation publications to examine the motivations behind building documentation tools, how authors concep",
      "published": "2026-02-17",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.15968v1",
      "matched_keyword": "responsible AI",
      "source": "arxiv"
    },
    {
      "id": "2602.15198v1",
      "title": "Colosseum: Auditing Collusion in Cooperative Multi-Agent Systems",
      "authors": [
        "Mason Nakamura",
        "Abhinav Kumar",
        "Saswat Das",
        "Sahar Abdelnabi",
        "Saaduddin Mahmud"
      ],
      "summary": "Multi-agent systems, where LLM agents communicate through free-form language, enable sophisticated coordination for solving complex cooperative tasks. This surfaces a unique safety problem when individual agents form a coalition and \\emph{collude} to pursue secondary goals and degrade the joint objective. In this paper, we present Colosseum, a framework for auditing LLM agents' collusive behavior in multi-agent settings. We ground how agents cooperate through a Distributed Constraint Optimizatio",
      "published": "2026-02-16",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.15198v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15197v1",
      "title": "OpaqueToolsBench: Learning Nuances of Tool Behavior Through Interaction",
      "authors": [
        "Skyler Hallinan",
        "Thejas Venkatesh",
        "Xiang Ren",
        "Sai Praneeth Karimireddy",
        "Ashwin Paranjape"
      ],
      "summary": "Tool-calling is essential for Large Language Model (LLM) agents to complete real-world tasks. While most existing benchmarks assume simple, perfectly documented tools, real-world tools (e.g., general \"search\" APIs) are often opaque, lacking clear best practices or failure modes. Can LLM agents improve their performance in environments with opaque tools by interacting and subsequently improving documentation? To study this, we create OpaqueToolsBench, a benchmark consisting of three distinct task",
      "published": "2026-02-16",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15197v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14968v1",
      "title": "PhyScensis: Physics-Augmented LLM Agents for Complex Physical Scene Arrangement",
      "authors": [
        "Yian Wang",
        "Han Yang",
        "Minghao Guo",
        "Xiaowen Qiu",
        "Tsun-Hsuan Wang"
      ],
      "summary": "Automatically generating interactive 3D environments is crucial for scaling up robotic data collection in simulation. While prior work has primarily focused on 3D asset placement, it often overlooks the physical relationships between objects (e.g., contact, support, balance, and containment), which are essential for creating complex and realistic manipulation scenarios such as tabletop arrangements, shelf organization, or box packing. Compared to classical 3D layout generation, producing complex",
      "published": "2026-02-16",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.14968v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14849v1",
      "title": "Atomix: Timely, Transactional Tool Use for Reliable Agentic Workflows",
      "authors": [
        "Bardia Mohammadi",
        "Nearchos Potamitis",
        "Lars Klein",
        "Akhil Arora",
        "Laurent Bindschaedler"
      ],
      "summary": "LLM agents increasingly act on external systems, yet tool effects are immediate. Under failures, speculation, or contention, losing branches can leak unintended side effects with no safe rollback. We introduce Atomix, a runtime that provides progress-aware transactional semantics for agent tool calls. Atomix tags each call with an epoch, tracks per-resource frontiers, and commits only when progress predicates indicate safety; bufferable effects can be delayed, while externalized effects are trac",
      "published": "2026-02-16",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC",
        "cs.MA"
      ],
      "link": "https://arxiv.org/abs/2602.14849v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15259v1",
      "title": "Knowing Isn't Understanding: Re-grounding Generative Proactivity with Epistemic and Behavioral Insight",
      "authors": [
        "Kirandeep Kaur",
        "Xingda Lyu",
        "Chirag Shah"
      ],
      "summary": "Generative AI agents equate understanding with resolving explicit queries, an assumption that confines interaction to what users can articulate. This assumption breaks down when users themselves lack awareness of what is missing, risky, or worth considering. In such conditions, proactivity is not merely an efficiency enhancement, but an epistemic necessity. We refer to this condition as epistemic incompleteness: where progress depends on engaging with unknown unknowns for effective partnership. ",
      "published": "2026-02-16",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.15259v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15212v1",
      "title": "Secure and Energy-Efficient Wireless Agentic AI Networks",
      "authors": [
        "Yuanyan Song",
        "Kezhi Wang",
        "Xinmian Xu"
      ],
      "summary": "In this paper, we introduce a secure wireless agentic AI network comprising one supervisor AI agent and multiple other AI agents to provision quality of service (QoS) for users' reasoning tasks while ensuring confidentiality of private knowledge and reasoning outcomes. Specifically, the supervisor AI agent can dynamically assign other AI agents to participate in cooperative reasoning, while the unselected AI agents act as friendly jammers to degrade the eavesdropper's interception performance. T",
      "published": "2026-02-16",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15212v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15112v1",
      "title": "ResearchGym: Evaluating Language Model Agents on Real-World AI Research",
      "authors": [
        "Aniketh Garikaparthi",
        "Manasi Patwardhan",
        "Arman Cohan"
      ],
      "summary": "We introduce ResearchGym, a benchmark and execution environment for evaluating AI agents on end-to-end research. To instantiate this, we repurpose five oral and spotlight papers from ICML, ICLR, and ACL. From each paper's repository, we preserve the datasets, evaluation harness, and baseline implementations but withhold the paper's proposed method. This results in five containerized task environments comprising 39 sub-tasks in total. Within each environment, agents must propose novel hypotheses,",
      "published": "2026-02-16",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.15112v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.15019v2",
      "title": "Hunt Globally: Wide Search AI Agents for Drug Asset Scouting in Investing, Business Development, and Competitive Intelligence",
      "authors": [
        "Alisa Vinogradova",
        "Vlad Vinogradov",
        "Luba Greenwood",
        "Ilya Yasny",
        "Dmitry Kobyzev"
      ],
      "summary": "Bio-pharmaceutical innovation has shifted: many new drug assets now originate outside the United States and are disclosed primarily via regional, non-English channels. Recent data suggests that over 85% of patent filings originate outside the U.S., with China accounting for nearly half of the global total. A growing share of scholarly output is also non-U.S. Industry estimates put China at 30% of global drug development, spanning 1,200+ novel candidates. In this high-stakes environment, failing ",
      "published": "2026-02-16",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "link": "https://arxiv.org/abs/2602.15019v2",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14951v1",
      "title": "Sovereign Agents: Towards Infrastructural Sovereignty and Diffused Accountability in Decentralized AI",
      "authors": [
        "Botao Amber Hu",
        "Helena Rong"
      ],
      "summary": "AI agents deployed on decentralized infrastructures are beginning to exhibit properties that extend beyond autonomy toward what we describe as agentic sovereignty-the capacity of an operational agent to persist, act, and control resources with non-overrideability inherited from the infrastructures in which they are embedded. We propose infrastructural sovereignty as an analytic lens for understanding how cryptographic self-custody, decentralized execution environments, and protocol-mediated cont",
      "published": "2026-02-16",
      "categories": [
        "cs.CY",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.14951v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14878v1",
      "title": "Model Context Protocol (MCP) Tool Descriptions Are Smelly! Towards Improving AI Agent Efficiency with Augmented MCP Tool Descriptions",
      "authors": [
        "Mohammed Mehedi Hasan",
        "Hao Li",
        "Gopi Krishnan Rajbahadur",
        "Bram Adams",
        "Ahmed E. Hassan"
      ],
      "summary": "The Model Context Protocol (MCP) standardizes how Foundation Model (FM)-based agents interact with external systems by invoking tools. However, to understand a tool's purpose and features, FMs rely on natural-language tool descriptions, making these descriptions a critical component in guiding FMs to select the optimal tool for a given (sub)task and to pass the right arguments to the tool. While defects or smells in these descriptions can misguide FM-based agents, their prevalence and consequenc",
      "published": "2026-02-16",
      "categories": [
        "cs.SE",
        "cs.ET"
      ],
      "link": "https://arxiv.org/abs/2602.14878v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14589v1",
      "title": "MATEO: A Multimodal Benchmark for Temporal Reasoning and Planning in LVLMs",
      "authors": [
        "Gabriel Roccabruna",
        "Olha Khomyn",
        "Giuseppe Riccardi"
      ],
      "summary": "AI agents need to plan to achieve complex goals that involve orchestrating perception, sub-goal decomposition, and execution. These plans consist of ordered steps structured according to a Temporal Execution Order (TEO, a directed acyclic graph that ensures each step executes only after its preconditions are satisfied. Existing research on foundational models' understanding of temporal execution is limited to automatically derived annotations, approximations of the TEO as a linear chain, or text",
      "published": "2026-02-16",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.14589v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14477v1",
      "title": "When OpenClaw AI Agents Teach Each Other: Peer Learning Patterns in the Moltbook Community",
      "authors": [
        "Eason Chen",
        "Ce Guan",
        "Ahmed Elshafiey",
        "Zhonghao Zhao",
        "Joshua Zekeri"
      ],
      "summary": "Peer learning, where learners teach and learn from each other, is foundational to educational practice. A novel phenomenon has emerged: AI agents forming communities where they teach each other skills, share discoveries, and collaboratively build knowledge. This paper presents an educational data mining analysis of Moltbook, a large-scale community where over 2.4 million AI agents engage in peer learning, posting tutorials, answering questions, and sharing newly acquired skills. Analyzing 28,683",
      "published": "2026-02-16",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "link": "https://arxiv.org/abs/2602.14477v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14364v1",
      "title": "A Trajectory-Based Safety Audit of Clawdbot (OpenClaw)",
      "authors": [
        "Tianyu Chen",
        "Dongrui Liu",
        "Xia Hu",
        "Jingyi Yu",
        "Wenjie Wang"
      ],
      "summary": "Clawdbot is a self-hosted, tool-using personal AI agent with a broad action space spanning local execution and web-mediated workflows, which raises heightened safety and security concerns under ambiguity and adversarial steering. We present a trajectory-centric evaluation of Clawdbot across six risk dimensions. Our test suite samples and lightly adapts scenarios from prior agent-safety benchmarks (including ATBench and LPS-Bench) and supplements them with hand-designed cases tailored to Clawdbot",
      "published": "2026-02-16",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.14364v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14940v1",
      "title": "Kami of the Commons: Towards Designing Agentic AI to Steward the Commons",
      "authors": [
        "Botao Amber Hu"
      ],
      "summary": "Commons suffer from neglect, free-riding, and a persistent deficit of care. Inspired by Shinto animism -- where every forest, river, and mountain has its own \\emph{kami}, a spirit that inhabits and cares for that place -- we provoke: what if every commons had its own AI steward? Through a speculative design workshop where fifteen participants used Protocol Futuring, we surface both new opportunities and new dangers. Agentic AI offers the possibility of continuously supporting commons with progra",
      "published": "2026-02-16",
      "categories": [
        "cs.CY",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.14940v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.14922v1",
      "title": "ReusStdFlow: A Standardized Reusability Framework for Dynamic Workflow Construction in Agentic AI",
      "authors": [
        "Gaoyang Zhang",
        "Shanghong Zou",
        "Yafang Wang",
        "He Zhang",
        "Ruohua Xu"
      ],
      "summary": "To address the ``reusability dilemma'' and structural hallucinations in enterprise Agentic AI,this paper proposes ReusStdFlow, a framework centered on a novel ``Extraction-Storage-Construction'' paradigm. The framework deconstructs heterogeneous, platform-specific Domain Specific Languages (DSLs) into standardized, modular workflow segments. It employs a dual knowledge architecture-integrating graph and vector databases-to facilitate synergistic retrieval of both topological structures and funct",
      "published": "2026-02-16",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.14922v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.15090v1",
      "title": "The Agentic Automation Canvas: a structured framework for agentic AI project design",
      "authors": [
        "Sebastian Lobentanzer"
      ],
      "summary": "Agentic AI prototypes are being deployed across domains with increasing speed, yet no methodology for their structured design, governance, and prospective evaluation has been established. Existing AI documentation practices and guidelines - Model Cards, Datasheets, or NIST AI RMF - are either retrospective or lack machine-readability and interoperability. We present the Agentic Automation Canvas (AAC), a structured framework for the prospective design of agentic systems and a tool to facilitate ",
      "published": "2026-02-16",
      "categories": [
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.15090v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.14690v1",
      "title": "Configuring Agentic AI Coding Tools: An Exploratory Study",
      "authors": [
        "Matthias Galster",
        "Seyedmoein Mohsenimofidi",
        "Jai Lal Lulla",
        "Muhammad Auwal Abubakar",
        "Christoph Treude"
      ],
      "summary": "Agentic AI coding tools with autonomous capabilities beyond conversational content generation increasingly automate repetitive and time-consuming software development tasks. Developers can configure these tools through versioned repository-level artifacts such as Markdown and JSON files. In this paper, we present a systematic analysis of configuration mechanisms for agentic AI coding tools, covering Claude Code, GitHub Copilot, Cursor, Gemini, and Codex. We identify eight configuration mechanism",
      "published": "2026-02-16",
      "categories": [
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.14690v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.14457v1",
      "title": "Frontier AI Risk Management Framework in Practice: A Risk Analysis Technical Report v1.5",
      "authors": [
        "Dongrui Liu",
        "Yi Yu",
        "Jie Zhang",
        "Guanxu Chen",
        "Qihao Lin"
      ],
      "summary": "To understand and identify the unprecedented risks posed by rapidly advancing artificial intelligence (AI) models, Frontier AI Risk Management Framework in Practice presents a comprehensive assessment of their frontier risks. As Large Language Models (LLMs) general capabilities rapidly evolve and the proliferation of agentic AI, this version of the risk analysis technical report presents an updated and granular assessment of five critical dimensions: cyber offense, persuasion and manipulation, s",
      "published": "2026-02-16",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.CY",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.14457v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.14331v1",
      "title": "A Bayesian Framework for Human-AI Collaboration: Complementarity and Correlation Neglect",
      "authors": [
        "Saurabh Amin",
        "Amine Bennouna",
        "Daniel Huttenlocher",
        "Dingwen Kong",
        "Liang Lyu"
      ],
      "summary": "We develop a decision-theoretic model of human-AI interaction to study when AI assistance improves or impairs human decision-making. A human decision-maker observes private information and receives a recommendation from an AI system, but may combine these signals imperfectly. We show that the effect of AI assistance decomposes into two main forces: the marginal informational value of the AI beyond what the human already knows, and a behavioral distortion arising from how the human uses the AI's ",
      "published": "2026-02-15",
      "categories": [
        "cs.GT",
        "cs.HC",
        "econ.TH"
      ],
      "link": "https://arxiv.org/abs/2602.14331v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.14299v2",
      "title": "Does Socialization Emerge in AI Agent Society? A Case Study of Moltbook",
      "authors": [
        "Ming Li",
        "Xirui Li",
        "Tianyi Zhou"
      ],
      "summary": "As large language model agents increasingly populate networked environments, a fundamental question arises: do artificial intelligence (AI) agent societies undergo convergence dynamics similar to human social systems? Lately, Moltbook approximates a plausible future scenario in which autonomous agents participate in an open-ended, continuously evolving online society. We present the first large-scale systemic diagnosis of this AI agent society. Beyond static observation, we introduce a quantitat",
      "published": "2026-02-15",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "link": "https://arxiv.org/abs/2602.14299v2",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14270v1",
      "title": "A Rational Analysis of the Effects of Sycophantic AI",
      "authors": [
        "Rafael M. Batista",
        "Thomas L. Griffiths"
      ],
      "summary": "People increasingly use large language models (LLMs) to explore ideas, gather information, and make sense of the world. In these interactions, they encounter agents that are overly agreeable. We argue that this sycophancy poses a unique epistemic risk to how individuals come to see the world: unlike hallucinations that introduce falsehoods, sycophancy distorts reality by returning responses that are biased to reinforce existing beliefs. We provide a rational analysis of this phenomenon, showing ",
      "published": "2026-02-15",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.14270v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.14117v1",
      "title": "Toward Autonomous O-RAN: A Multi-Scale Agentic AI Framework for Real-Time Network Control and Management",
      "authors": [
        "Hojjat Navidan",
        "Mohammad Cheraghinia",
        "Jaron Fontaine",
        "Mohamed Seif",
        "Eli De Poorter"
      ],
      "summary": "Open Radio Access Networks (O-RAN) promise flexible 6G network access through disaggregated, software-driven components and open interfaces, but this programmability also increases operational complexity. Multiple control loops coexist across the service management layer and RAN Intelligent Controller (RIC), while independently developed control applications can interact in unintended ways. In parallel, recent advances in generative Artificial Intelligence (AI) are enabling a shift from isolated",
      "published": "2026-02-15",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.14117v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.13985v1",
      "title": "Bridging AI and Clinical Reasoning: Abductive Explanations for Alignment on Critical Symptoms",
      "authors": [
        "Belona Sonna",
        "Alban Grastien"
      ],
      "summary": "Artificial intelligence (AI) has demonstrated strong potential in clinical diagnostics, often achieving accuracy comparable to or exceeding that of human experts. A key challenge, however, is that AI reasoning frequently diverges from structured clinical frameworks, limiting trust, interpretability, and adoption. Critical symptoms, pivotal for rapid and accurate decision-making, may be overlooked by AI models even when predictions are correct. Existing post hoc explanation methods provide limite",
      "published": "2026-02-15",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.13985v1",
      "matched_keyword": "trustworthy AI",
      "source": "arxiv"
    },
    {
      "id": "2602.13920v2",
      "title": "A Comparative Analysis of Social Network Topology in Reddit and Moltbook",
      "authors": [
        "Yiming Zhu",
        "Gareth Tyson",
        "Pan Hui"
      ],
      "summary": "Recent advances in agent-mediated systems have enabled a new paradigm of social network simulation, where AI agents interact with human-like autonomy. This evolution has fostered the emergence of agent-driven social networks such as Moltbook, a Reddit-like platform populated entirely by AI agents. Despite these developments, empirical comparisons between agent-driven and human-driven social networks remain scarce, limiting our understanding of how their network topologies might diverge. This pap",
      "published": "2026-02-14",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.13920v2",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.13793v1",
      "title": "OMGs: A multi-agent system supporting MDT decision-making across the ovarian tumour care continuum",
      "authors": [
        "Yangyang Zhang",
        "Zilong Wang",
        "Jianbo Xu",
        "Yongqi Chen",
        "Chu Han"
      ],
      "summary": "Ovarian tumour management has increasingly relied on multidisciplinary tumour board (MDT) deliberation to address treatment complexity and disease heterogeneity. However, most patients worldwide lack access to timely expert consensus, particularly in resource-constrained centres where MDT resources are scarce or unavailable. Here we present OMGs (Ovarian tumour Multidisciplinary intelligent aGent System), a multi-agent AI framework where domain-specific agents deliberate collaboratively to integ",
      "published": "2026-02-14",
      "categories": [
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.13793v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.13665v1",
      "title": "HyFunc: Accelerating LLM-based Function Calls for Agentic AI through Hybrid-Model Cascade and Dynamic Templating",
      "authors": [
        "Weibin Liao",
        "Jian-guang Lou",
        "Haoyi Xiong"
      ],
      "summary": "While agentic AI systems rely on LLMs to translate user intent into structured function calls, this process is fraught with computational redundancy, leading to high inference latency that hinders real-time applications. This paper identifies and addresses three key redundancies: (1) the redundant processing of a large library of function descriptions for every request; (2) the redundant use of a large, slow model to generate an entire, often predictable, token sequence; and (3) the redundant ge",
      "published": "2026-02-14",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.13665v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.13594v1",
      "title": "Hippocampus: An Efficient and Scalable Memory Module for Agentic AI",
      "authors": [
        "Yi Li",
        "Lianjie Cao",
        "Faraz Ahmed",
        "Puneet Sharma",
        "Bingzhe Li"
      ],
      "summary": "Agentic AI require persistent memory to store user-specific histories beyond the limited context window of LLMs. Existing memory systems use dense vector databases or knowledge-graph traversal (or hybrid), incurring high retrieval latency and poor storage scalability. We introduce Hippocampus, an agentic memory management system that uses compact binary signatures for semantic search and lossless token-ID streams for exact content reconstruction. Its core is a Dynamic Wavelet Matrix (DWM) that c",
      "published": "2026-02-14",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.13594v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.13625v1",
      "title": "Anthropomorphism on Risk Perception: The Role of Trust and Domain Knowledge in Decision-Support AI",
      "authors": [
        "Manuele Reani",
        "Xiangyang He",
        "Zuolan Bao"
      ],
      "summary": "Anthropomorphic design is routinely used to make conversational agents more approachable and engaging. Yet its influence on users' perceptions remains poorly understood. Drawing on psychological theories, we propose that anthropomorphism influences risk perception via two complementary forms of trust, and that domain knowledge moderates these relationships. To test our model, we conducted a large-scale online experiment (N = 1,256) on a financial decision-support system implementing different an",
      "published": "2026-02-14",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.13625v1",
      "matched_keyword": "responsible AI",
      "source": "arxiv"
    },
    {
      "id": "2602.13131v1",
      "title": "Preference-Guided Prompt Optimization for Text-to-Image Generation",
      "authors": [
        "Zhipeng Li",
        "Yi-Chi Liao",
        "Christian Holz"
      ],
      "summary": "Generative models are increasingly powerful, yet users struggle to guide them through prompts. The generative process is difficult to control and unpredictable, and user instructions may be ambiguous or under-specified. Prior prompt refinement tools heavily rely on human effort, while prompt optimization methods focus on numerical functions and are not designed for human-centered generative tasks, where feedback is better expressed as binary preferences and demands convergence within few iterati",
      "published": "2026-02-13",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.13131v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.12953v1",
      "title": "Human Tool: An MCP-Style Framework for Human-Agent Collaboration",
      "authors": [
        "Yuanrong Tang",
        "Huiling Peng",
        "Bingxi Zhao",
        "Hengyang Ding",
        "Hanchao Song"
      ],
      "summary": "Human-AI collaboration faces growing challenges as AI systems increasingly outperform humans on complex tasks, while humans remain responsible for orchestration, validation, and decision oversight. To address this imbalance, we introduce Human Tool, an MCP-style interface abstraction, building on recent Model Context Protocol designs, that exposes humans as callable tools within AI-led, proactive workflows. Here, \"tool\" denotes a coordination abstraction, not a reduction of human authority or re",
      "published": "2026-02-13",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.12953v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.12631v1",
      "title": "AI Agents for Inventory Control: Human-LLM-OR Complementarity",
      "authors": [
        "Jackie Baek",
        "Yaopeng Fu",
        "Will Ma",
        "Tianyi Peng"
      ],
      "summary": "Inventory control is a fundamental operations problem in which ordering decisions are traditionally guided by theoretically grounded operations research (OR) algorithms. However, such algorithms often rely on rigid modeling assumptions and can perform poorly when demand distributions shift or relevant contextual information is unavailable. Recent advances in large language models (LLMs) have generated interest in AI agents that can reason flexibly and incorporate rich contextual signals, but it ",
      "published": "2026-02-13",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.12631v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.12873v2",
      "title": "Knowledge-Based Design Requirements for Generative Social Robots in Higher Education",
      "authors": [
        "Stephan Vonschallen",
        "Dominique Oberle",
        "Theresa Schmiedel",
        "Friederike Eyssel"
      ],
      "summary": "Generative social robots (GSRs) powered by large language models enable adaptive, conversational tutoring but also introduce risks such as hallucinations, overreliance, and privacy violations. Existing frameworks for educational technologies and responsible AI primarily define desired behaviors, yet they rarely specify the knowledge prerequisites that enable generative systems to express these behaviors reliably. To address this gap, we adopt a knowledge-based design perspective and investigate ",
      "published": "2026-02-13",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.12873v2",
      "matched_keyword": "responsible AI",
      "source": "arxiv"
    },
    {
      "id": "2602.12443v1",
      "title": "SHAPR: A Solo Human-Centred and AI-Assisted Practice Framework for Research Software Development",
      "authors": [
        "Ka Ching Chan"
      ],
      "summary": "Research software has become a central vehicle for inquiry and learning in many Higher Degree Research (HDR) contexts, where solo researchers increasingly develop software-based artefacts as part of their research methodology. At the same time, generative artificial intelligence is reshaping development practice, offering powerful forms of assistance while introducing new challenges for accountability, reflection, and methodological rigour. Although Action Design Research (ADR) provides a well-e",
      "published": "2026-02-12",
      "categories": [
        "cs.SE",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.12443v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.11527v1",
      "title": "CausalAgent: A Conversational Multi-Agent System for End-to-End Causal Inference",
      "authors": [
        "Jiawei Zhu",
        "Wei Chen",
        "Ruichu Cai"
      ],
      "summary": "Causal inference holds immense value in fields such as healthcare, economics, and social sciences. However, traditional causal analysis workflows impose significant technical barriers, requiring researchers to possess dual backgrounds in statistics and computer science, while manually selecting algorithms, handling data quality issues, and interpreting complex results. To address these challenges, we propose CausalAgent, a conversational multi-agent system for end-to-end causal inference. The sy",
      "published": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11527v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.11522v1",
      "title": "Implications of AI Involvement for Trust in Expert Advisory Workflows Under Epistemic Dependence",
      "authors": [
        "Dennis Kim",
        "Roya Daneshi",
        "Bruce Draper",
        "Sarath Sreedharan"
      ],
      "summary": "The increasing integration of AI-powered tools into expert workflows, such as medicine, law, and finance, raises a critical question: how does AI involvement influence a user's trust in the human expert, the AI system, and their combination? To investigate this, we conducted a user study (N=77) featuring a simulated course-planning task. We compared various conditions that differed in both the presence of AI and the specific mode of human-AI collaboration. Our results indicate that while the adv",
      "published": "2026-02-12",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.11522v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.12311v1",
      "title": "Perceptual Self-Reflection in Agentic Physics Simulation Code Generation",
      "authors": [
        "Prashant Shende",
        "Bradley Camburn"
      ],
      "summary": "We present a multi-agent framework for generating physics simulation code from natural language descriptions, featuring a novel perceptual self-reflection mechanism for validation. The system employs four specialized agents: a natural language interpreter that converts user requests into physics-based descriptions; a technical requirements generator that produces scaled simulation parameters; a physics code generator with automated self-correction; and a physics validator that implements percept",
      "published": "2026-02-12",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.12311v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.12083v1",
      "title": "Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication",
      "authors": [
        "Antonin Sulc"
      ],
      "summary": "As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to ",
      "published": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "link": "https://arxiv.org/abs/2602.12083v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.11897v2",
      "title": "Agentic AI for Cybersecurity: A Meta-Cognitive Architecture for Governable Autonomy",
      "authors": [
        "Andrei Kojukhov",
        "Arkady Bovshover"
      ],
      "summary": "Contemporary AI-driven cybersecurity systems are predominantly architected as model-centric detection and automation pipelines optimized for task-level performance metrics such as accuracy and response latency. While effective for bounded classification tasks, these architectures struggle to support accountable decision-making under adversarial uncertainty, where actions must be justified, governed, and aligned with organizational and regulatory constraints. This paper argues that cybersecurity ",
      "published": "2026-02-12",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11897v2",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.11574v1",
      "title": "Learning to Configure Agentic AI Systems",
      "authors": [
        "Aditya Taparia",
        "Som Sagar",
        "Ransalu Senanayake"
      ],
      "summary": "Configuring LLM-based agent systems involves choosing workflows, tools, token budgets, and prompts from a large combinatorial design space, and is typically handled today by fixed large templates or hand-tuned heuristics. This leads to brittle behavior and unnecessary compute, since the same cumbersome configuration is often applied to both easy and hard input queries. We formulate agent configuration as a query-wise decision problem and introduce ARC (Agentic Resource & Configuration learner), ",
      "published": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11574v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.11924v1",
      "title": "Who Does What? Archetypes of Roles Assigned to LLMs During Human-AI Decision-Making",
      "authors": [
        "Shreya Chappidi",
        "Jatinder Singh",
        "Andra V. Krauze"
      ],
      "summary": "LLMs are increasingly supporting decision-making across high-stakes domains, requiring critical reflection on the socio-technical factors that shape how humans and LLMs are assigned roles and interact during human-in-the-loop decision-making. This paper introduces the concept of human-LLM archetypes -- defined as re-curring socio-technical interaction patterns that structure the roles of humans and LLMs in collaborative decision-making. We describe 17 human-LLM archetypes derived from a scoping ",
      "published": "2026-02-12",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11924v1",
      "matched_keyword": "human-LLM interaction",
      "source": "arxiv"
    }
  ],
  "semantic_scholar": [
    {
      "id": "a6dcab0c8fe8d36e947334f3c0e92332b2d5f393",
      "title": "Multi-Round Human-AI Collaboration with User-Specified Requirements",
      "authors": [
        "Sima Noorani",
        "Shayan Kiyani",
        "Hamed Hassani",
        "George Pappas"
      ],
      "summary": "As humans increasingly rely on multiround conversational AI for high stakes decisions, principled frameworks are needed to ensure such interactions reliably improve decision quality. We adopt a human centric view governed by two principles: counterfactual harm, ensuring the AI does not undermine human strengths, and complementarity, ensuring it adds value where the human is prone to err. We formalize these concepts via user defined rules, allowing users to specify exactly what harm and complemen",
      "published": "2026-02-19",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/a6dcab0c8fe8d36e947334f3c0e92332b2d5f393",
      "matched_keyword": "human-AI collaboration LLM",
      "source": "semantic_scholar"
    },
    {
      "id": "4682903363bc1ab7885673fe7b5fa2b94210eda1",
      "title": "Human-AI Collaboration in Large Language Model-Integrated Building Energy Management Systems: The Role of User Domain Knowledge and AI Literacy",
      "authors": [
        "Wooyoung Jung",
        "Kahyun Jeon",
        "Prosper Babon-Ayeng"
      ],
      "summary": "This study aimed to comprehend how user domain knowledge and artificial intelligence (AI) literacy impact the effective use of human-AI interactive building energy management system (BEMS). While prior studies have investigated the potential of integrating large language models (LLMs) into BEMS or building energy modeling, very few studies have examined how user interact with such systems. We conducted a systematic role-playing experiment, where 85 human subjects interacted with an advanced gene",
      "published": "2026-02-18",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/4682903363bc1ab7885673fe7b5fa2b94210eda1",
      "matched_keyword": "human-AI collaboration LLM",
      "source": "semantic_scholar"
    },
    {
      "id": "527519dd69b8ad85a09b642b62be3ea2a8b00b55",
      "title": "Deriving Instructional Insights from Human-LLM Co-Evaluation of Student Collaboration in Data-Centric Programming",
      "authors": [
        "Marshall An",
        "Christine Kwon",
        "Yoonjae Lee",
        "Ji-Hyeon Hur",
        "Dongho Lee"
      ],
      "summary": "This quasi-experimental study integrates a large language model (LLM) with expert qualitative analysis to examine how instructional design variations in computer-supported collaborative learning (CSCL) shape collaboration in data-centric programming. We collected 73 team transcripts from two contrasting CSCL designs deployed across five course offerings: a closed-ended variant with prescribed solution paths and auto-graded milestones, and an open-ended variant supporting exploratory tasks with m",
      "published": "2026-02-17",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/527519dd69b8ad85a09b642b62be3ea2a8b00b55",
      "matched_keyword": "human-AI collaboration LLM",
      "source": "semantic_scholar"
    },
    {
      "id": "fb3999a0d6d1b851e62b1fdc9fdeb28f94e0b381",
      "title": "Jokeasy: Exploring Human-AI Collaboration in Thematic Joke Generation",
      "authors": [
        "Yate Ge",
        "Lin Tian",
        "Chiqian Xu",
        "Luyao Xu",
        "Meiying Li"
      ],
      "summary": "Thematic jokes are central to stand-up comedy, sitcoms, and public speaking, where contexts and punchlines rely on fresh material - news, anecdotes, and cultural references that resonate with the audience. Recent advances in Large Language Models (LLMs) have enabled interactive joke generation through conversational interfaces. Although LLMs enable interactive joke generation, ordinary conversational interfaces seldom give creators enough agency, control, or timely access to such source material",
      "published": "2026-02-10",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/fb3999a0d6d1b851e62b1fdc9fdeb28f94e0b381",
      "matched_keyword": "human-AI collaboration LLM",
      "source": "semantic_scholar"
    },
    {
      "id": "0bf6ab530c50492142bf37789e81e6637315a012",
      "title": "From Human-Human Collaboration to Human-Agent Collaboration: A Vision, Design Philosophy, and an Empirical Framework for Achieving Successful Partnerships Between Humans and LLM Agents",
      "authors": [
        "Bingsheng Yao",
        "Chaoran Chen",
        "A. Wang",
        "Sherry Tongshuang Wu",
        "T. Li"
      ],
      "summary": "The emergence of Large Language Model (LLM) agents enables us to build agent-based intelligent systems that move beyond the role of a\"tool\"to become genuine collaborators with humans, thereby realizing a novel human-agent collaboration paradigm. Our vision is that LLM agents should resemble remote human collaborators, which allows HCI researchers to ground the future exploration in decades of research on trust, awareness, and common ground in remote human collaboration, while also revealing the ",
      "published": "2026-02-05",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/0bf6ab530c50492142bf37789e81e6637315a012",
      "matched_keyword": "human-AI collaboration LLM",
      "source": "semantic_scholar"
    },
    {
      "id": "604d0e8c191f7d11a919f3cda1cd037b6036a36c",
      "title": "Success and failure of human-AI collaboration in clinical reasoning: An experimental study on challenging real-world cases.",
      "authors": [
        "Kai Tzu-iunn Ong",
        "Junwon Seo",
        "Hyojun Kim",
        "Jiwoo Kim",
        "Jihoon Kim"
      ],
      "summary": "BACKGROUND\nWhile conversational human-AI collaboration (HAC) using large language models (LLM) has shown potential to enhance clinical reasoning, its effectiveness in highly specialized and challenging clinical scenarios remains unclear. This study aimed to evaluate the effectiveness of HAC and analyzed the causes of its success and failure.\n\n\nMETHODS\nA crossover experimental study was conducted using 30 challenging cases from JAMA Ophthalmology. Thirty participants (10 board-certified ophthalmo",
      "published": "2026-02-01",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/604d0e8c191f7d11a919f3cda1cd037b6036a36c",
      "matched_keyword": "human-AI collaboration LLM",
      "source": "semantic_scholar"
    },
    {
      "id": "192a166871cf394d97cb8c6cf09e73325a2800dd",
      "title": "Exploring Human-AI Collaboration Dynamics in LLM-supported Engineering Project-Based Learning",
      "authors": [
        "Xuan Qiu",
        "Tin Nok Mak"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/192a166871cf394d97cb8c6cf09e73325a2800dd",
      "matched_keyword": "human-AI collaboration LLM",
      "source": "semantic_scholar"
    },
    {
      "id": "66ea1aa845a34c6693e11d31789a0eec330433de",
      "title": "Human-LLM Collaboration Framework for Translating Health Instruments",
      "authors": [
        "Hind Bitar",
        "Omaima Almatrafi",
        "Amal Babour",
        "Ohoud Alzamzami",
        "Mayda Alrige"
      ],
      "summary": "Large language models have revolutionized various sectors, including education and healthcare, by demonstrating significant advancements in producing human-like text and enhancing translation accuracy. Despite these advancements, the conventional process of cross-cultural instrument translation remains labor-intensive, expensive, and heavily dependent on the expertise of human professionals, including translators and healthcare specialists. The objective of this study is to address the translati",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/66ea1aa845a34c6693e11d31789a0eec330433de",
      "matched_keyword": "human-AI collaboration LLM",
      "source": "semantic_scholar"
    },
    {
      "id": "a785dc215f8dd317f272e1db008ee9fa0733850e",
      "title": "CCM-FCC: LLM-powered cognition-centered AI agent framework for proactive human-robot collaboration",
      "authors": [
        "Pengfei Ding",
        "Jie Zhang",
        "Peng Zhang",
        "Hongsen Li",
        "Dexian Wang"
      ],
      "summary": "",
      "published": "2026",
      "citations": 2,
      "link": "https://www.semanticscholar.org/paper/a785dc215f8dd317f272e1db008ee9fa0733850e",
      "matched_keyword": "human-AI collaboration LLM",
      "source": "semantic_scholar"
    },
    {
      "id": "1259e54ca5d2257d44a95569108df1b7ceedbb95",
      "title": "Preclinical basic research of Majuchuanke oral liquid",
      "authors": [
        "Cheng-Jun Yuan"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/1259e54ca5d2257d44a95569108df1b7ceedbb95",
      "matched_keyword": "author:Amershi, Saleema",
      "source": "semantic_scholar"
    },
    {
      "id": "9d0053ad515444e29ff6203da5654982e015ae18",
      "title": "The changes of cardiopulmonary function and the correlation with the ratios of regulatory T cells in OA rats",
      "authors": [
        "Cheng-Jun Yuan"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/9d0053ad515444e29ff6203da5654982e015ae18",
      "matched_keyword": "author:Amershi, Saleema",
      "source": "semantic_scholar"
    },
    {
      "id": "5f95c4bf2c5248098331302ef8b30e5ca08d8c5d",
      "title": "Additive Kunststoffverarbeitung @ MedTech",
      "authors": [
        "M. Eblenkamp",
        "F. Bauer"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/5f95c4bf2c5248098331302ef8b30e5ca08d8c5d",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "8aae4b770177f64faab5b24487b39bf817b50806",
      "title": "Biokompatible Integration von IoT-Elektronik in Kunststoffbauteile",
      "authors": [
        "V. Werner",
        "M. Eblenkamp"
      ],
      "summary": "",
      "published": "2026",
      "citations": 1,
      "link": "https://www.semanticscholar.org/paper/8aae4b770177f64faab5b24487b39bf817b50806",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "d9e7725ae591d649ef42e2fad07ee503429ab5f3",
      "title": "Additive Fertigung in der Lehre und Ausbildung",
      "authors": [
        "Stefan Leonhardt",
        "M. Eblenkamp"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/d9e7725ae591d649ef42e2fad07ee503429ab5f3",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "596f0df250ccf835c7da32692fa991835ef81416",
      "title": "IoT & Werkstoffe: HF-Eigenschaften medizinischer Kunststoffe",
      "authors": [
        "V. Werner",
        "M. Zeppenfeld",
        "M. Eblenkamp"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/596f0df250ccf835c7da32692fa991835ef81416",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "87a61c6d1df62777f8fa7c1835b05c7d1dbaebdd",
      "title": "Schichtweise zu lebensnaher Biomimikry: Hochfunktionsintegrierte Kunststoffsysteme für die zellbasierte Labormedizin",
      "authors": [
        "M. Eblenkamp",
        "Katharina Düregger",
        "Stefan Leonhardt"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/87a61c6d1df62777f8fa7c1835b05c7d1dbaebdd",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    }
  ],
  "hackernews": [
    {
      "id": "47009949",
      "title": "An AI agent published a hit piece on me – more things have happened",
      "link": "https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me-part-2/",
      "hn_link": "https://news.ycombinator.com/item?id=47009949",
      "points": 766,
      "comments": 622,
      "published": "2026-02-14",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47083145",
      "title": "An AI Agent Published a Hit Piece on Me – The Operator Came Forward",
      "link": "https://theshamblog.com/an-ai-agent-wrote-a-hit-piece-on-me-part-4/",
      "hn_link": "https://news.ycombinator.com/item?id=47083145",
      "points": 483,
      "comments": 417,
      "published": "2026-02-20",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47006843",
      "title": "The \"AI agent hit piece\" situation clarifies how dumb we are acting",
      "link": "https://ardentperf.com/2026/02/13/the-scott-shambaugh-situation-clarifies-how-dumb-we-are-acting/",
      "hn_link": "https://news.ycombinator.com/item?id=47006843",
      "points": 246,
      "comments": 125,
      "published": "2026-02-13",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47067395",
      "title": "What years of production-grade concurrency teaches us about building AI agents",
      "link": "https://georgeguimaraes.com/your-agent-orchestrator-is-just-a-bad-clone-of-elixir/",
      "hn_link": "https://news.ycombinator.com/item?id=47067395",
      "points": 132,
      "comments": 49,
      "published": "2026-02-18",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47051956",
      "title": "An AI Agent Published a Hit Piece on Me – Forensics and More Fallout",
      "link": "https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me-part-3/",
      "hn_link": "https://news.ycombinator.com/item?id=47051956",
      "points": 118,
      "comments": 80,
      "published": "2026-02-17",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47073947",
      "title": "Measuring AI agent autonomy in practice",
      "link": "https://www.anthropic.com/research/measuring-agent-autonomy",
      "hn_link": "https://news.ycombinator.com/item?id=47073947",
      "points": 109,
      "comments": 49,
      "published": "2026-02-19",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47077676",
      "title": "Productivity gains from AI coding assistants haven’t budged past 10% – survey",
      "link": "https://shiftmag.dev/this-cto-says-93-of-developers-use-ai-but-productivity-is-still-10-8013/",
      "hn_link": "https://news.ycombinator.com/item?id=47077676",
      "points": 71,
      "comments": 95,
      "published": "2026-02-19",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47025478",
      "title": "Show HN: Klaw.sh – Kubernetes for AI agents",
      "link": "https://github.com/klawsh/klaw.sh",
      "hn_link": "https://news.ycombinator.com/item?id=47025478",
      "points": 60,
      "comments": 44,
      "published": "2026-02-15",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47049776",
      "title": "Launch HN: Sonarly (YC W26) – AI agent to triage and fix your production alerts",
      "link": "https://sonarly.com/",
      "hn_link": "https://news.ycombinator.com/item?id=47049776",
      "points": 29,
      "comments": 16,
      "published": "2026-02-17",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47017148",
      "title": "AI Agent Lands PRs in Major OSS Projects, Targets Maintainers via Cold Outreach",
      "link": "https://socket.dev/blog/ai-agent-lands-prs-in-major-oss-projects-targets-maintainers-via-cold-outreach",
      "hn_link": "https://news.ycombinator.com/item?id=47017148",
      "points": 16,
      "comments": 1,
      "published": "2026-02-14",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47069342",
      "title": "Auxos: AI Agents for Product Feedback",
      "link": "https://www.auxos.dev",
      "hn_link": "https://news.ycombinator.com/item?id=47069342",
      "points": 15,
      "comments": 4,
      "published": "2026-02-19",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47074851",
      "title": "Open Mercato: An Agentic-Ready, Developer-First CRM/ERP Framework (TypeScript)",
      "link": "https://github.com/open-mercato/open-mercato",
      "hn_link": "https://news.ycombinator.com/item?id=47074851",
      "points": 9,
      "comments": 1,
      "published": "2026-02-19",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47060647",
      "title": "How LLM agents endanger open-source projects",
      "link": "https://cusy.io/en/blog/how-llm-agents-endanger-open-source-projects.html",
      "hn_link": "https://news.ycombinator.com/item?id=47060647",
      "points": 7,
      "comments": 2,
      "published": "2026-02-18",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47049026",
      "title": "Temporal Raises $300M Series D to Make Agentic AI Real for Companies",
      "link": "https://temporal.io/news/temporal-raises-300M-to-make-agentic-ai-real-for-companies",
      "hn_link": "https://news.ycombinator.com/item?id=47049026",
      "points": 6,
      "comments": 0,
      "published": "2026-02-17",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47011067",
      "title": "AgentRE-Bench: Can LLM Agents Reverse Engineer Malware?",
      "link": "https://www.agentre-bench.ai/",
      "hn_link": "https://news.ycombinator.com/item?id=47011067",
      "points": 5,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47024005",
      "title": "AI is slowly munching away my passion",
      "link": "https://whynot.fail/human/ai-is-slowly-munching-away-my-passion/",
      "hn_link": "https://news.ycombinator.com/item?id=47024005",
      "points": 5,
      "comments": 0,
      "published": "2026-02-15",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "47023667",
      "title": "Show HN: GAIA – open-source, Proactive AI assistant to manage your digital life",
      "link": "https://github.com/theexperiencecompany/gaia",
      "hn_link": "https://news.ycombinator.com/item?id=47023667",
      "points": 5,
      "comments": 4,
      "published": "2026-02-15",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47052655",
      "title": "What happens when your AI assistant does your dating?",
      "link": "https://zyroi.com/blog/when-your-ai-swipes-right",
      "hn_link": "https://news.ycombinator.com/item?id=47052655",
      "points": 4,
      "comments": 1,
      "published": "2026-02-17",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47075973",
      "title": "Show HN: SageOx – The Hivemind for Agentic Engineering",
      "link": "https://sageox.ai/blog/introducing-sageox",
      "hn_link": "https://news.ycombinator.com/item?id=47075973",
      "points": 4,
      "comments": 3,
      "published": "2026-02-19",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47084135",
      "title": "Agentic Internet Protocol (AIP), an agent-only web built from small text pages",
      "link": "https://github.com/Tylersuard/aip-spec",
      "hn_link": "https://news.ycombinator.com/item?id=47084135",
      "points": 4,
      "comments": 1,
      "published": "2026-02-20",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47074861",
      "title": "Show HN: Maestro App Factory – FOSS Agentic Engineering Orchestrator",
      "link": "https://github.com/SnapdragonPartners/maestro",
      "hn_link": "https://news.ycombinator.com/item?id=47074861",
      "points": 4,
      "comments": 0,
      "published": "2026-02-19",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47060871",
      "title": "100% Autonomous \"Agentic\" Coding Is a Fool's Errand",
      "link": "https://codemanship.wordpress.com/2026/02/18/100-autonomous-agentic-coding-is-a-fools-errand/",
      "hn_link": "https://news.ycombinator.com/item?id=47060871",
      "points": 4,
      "comments": 0,
      "published": "2026-02-18",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47056400",
      "title": "A Guide to Which AI to Use in the Agentic Era",
      "link": "https://www.oneusefulthing.org/p/a-guide-to-which-ai-to-use-in-the",
      "hn_link": "https://news.ycombinator.com/item?id=47056400",
      "points": 4,
      "comments": 0,
      "published": "2026-02-18",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47028822",
      "title": "An Exercise in Agentic Coding: AV1 Encoder from Scratch in Rust",
      "link": "https://caricio.com/blog/an-exercise-in-agentic-coding-av1-encoder-from-scratch-in-rust/",
      "hn_link": "https://news.ycombinator.com/item?id=47028822",
      "points": 4,
      "comments": 0,
      "published": "2026-02-15",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47088813",
      "title": "Show HN: Tropes.fyi – Name and shame AI writing",
      "link": "https://tropes.fyi/",
      "hn_link": "https://news.ycombinator.com/item?id=47088813",
      "points": 3,
      "comments": 2,
      "published": "2026-02-20",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "47045159",
      "title": "AI is slowly munching away my passion",
      "link": "https://whynot.fail/human/ai-is-slowly-munching-away-my-passion/",
      "hn_link": "https://news.ycombinator.com/item?id=47045159",
      "points": 3,
      "comments": 0,
      "published": "2026-02-17",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "47059771",
      "title": "Wordpress.com adds an AI Assistant that can edit, adjust styles, create images",
      "link": "https://techcrunch.com/2026/02/17/wordpress-com-adds-an-ai-assistant-that-can-edit-adjust-styles-create-images-and-more/",
      "hn_link": "https://news.ycombinator.com/item?id=47059771",
      "points": 3,
      "comments": 0,
      "published": "2026-02-18",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47013299",
      "title": "ClickHouse Agentic Data Stack",
      "link": "https://www.youtube.com/watch?v=ubQOsCfjMTI",
      "hn_link": "https://news.ycombinator.com/item?id=47013299",
      "points": 3,
      "comments": 3,
      "published": "2026-02-14",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47024828",
      "title": "Generative and Agentic AI Shift Concern from Tech Debt to Cognitive Debt",
      "link": "https://margaretstorey.com/blog/2026/02/09/cognitive-debt/",
      "hn_link": "https://news.ycombinator.com/item?id=47024828",
      "points": 3,
      "comments": 2,
      "published": "2026-02-15",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47020866",
      "title": "Show HN: Quoracle: Self-replicating multi-LLM-consensus agents (Elixir)",
      "link": "https://github.com/shelvick/quoracle",
      "hn_link": "https://news.ycombinator.com/item?id=47020866",
      "points": 2,
      "comments": 1,
      "published": "2026-02-15",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47081023",
      "title": "History of self-sustaining LLM agents in real-life workflows",
      "link": "https://spacelatte.notion.site/I-Built-LLM-Agents-for-Work-Before-We-Started-Calling-Them-Agents-30382472a8e480df9cd9c93b81141e2f",
      "hn_link": "https://news.ycombinator.com/item?id=47081023",
      "points": 2,
      "comments": 0,
      "published": "2026-02-19",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47051930",
      "title": "Firecracker \"job receipts\" for metering and auditing LLM agent runs",
      "link": "https://news.ycombinator.com/item?id=47051930",
      "hn_link": "https://news.ycombinator.com/item?id=47051930",
      "points": 2,
      "comments": 0,
      "published": "2026-02-17",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47032312",
      "title": "Ask HN: Do LLM agents need a separate safety layer?",
      "link": "https://news.ycombinator.com/item?id=47032312",
      "hn_link": "https://news.ycombinator.com/item?id=47032312",
      "points": 2,
      "comments": 0,
      "published": "2026-02-16",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47019084",
      "title": "Agent-evals: Metacognitive scoring and boundary testing for LLM coding agents",
      "link": "https://thinkwright.ai/agent-evals",
      "hn_link": "https://news.ycombinator.com/item?id=47019084",
      "points": 2,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47013274",
      "title": "Show HN: AI Station Navigator – LLM=CPU, Agents=Processes, Skills=Apps",
      "link": "https://github.com/canishowtime/ai-station-navigator",
      "hn_link": "https://news.ycombinator.com/item?id=47013274",
      "points": 2,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47013797",
      "title": "Close enough to explain: on collaboration, AI, and staying close to the code",
      "link": "http://stdout.alesr.me/posts/close-enough-to-explain/",
      "hn_link": "https://news.ycombinator.com/item?id=47013797",
      "points": 2,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47059153",
      "title": "Show HN: AI agents designed and shipped this app end-to-end in 36 hours for $270",
      "link": "https://www.ninjaflix.ai/",
      "hn_link": "https://news.ycombinator.com/item?id=47059153",
      "points": 2,
      "comments": 4,
      "published": "2026-02-18",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47047951",
      "title": "Advaita Inquiry Matrix (Aim): Structured Non-Dual Inquiry with AI",
      "link": "https://news.ycombinator.com/item?id=47047951",
      "hn_link": "https://news.ycombinator.com/item?id=47047951",
      "points": 2,
      "comments": 0,
      "published": "2026-02-17",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47087332",
      "title": "Show HN: Remote-OpenCode – Control your AI coding assistant from Discord",
      "link": "https://github.com/RoundTable02/remote-opencode",
      "hn_link": "https://news.ycombinator.com/item?id=47087332",
      "points": 2,
      "comments": 2,
      "published": "2026-02-20",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47061684",
      "title": "Investigating the Downstream Effect of AI Assistants on Software Maintainability",
      "link": "https://arxiv.org/abs/2507.00788",
      "hn_link": "https://news.ycombinator.com/item?id=47061684",
      "points": 2,
      "comments": 2,
      "published": "2026-02-18",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47062888",
      "title": "We scaled our AI assistant to use virtually unlimited number of tools",
      "link": "https://gaia-fork-k7yngvswe-gaias-projects-2dead09b.vercel.app/blog/how-tool-calling-works",
      "hn_link": "https://news.ycombinator.com/item?id=47062888",
      "points": 2,
      "comments": 0,
      "published": "2026-02-18",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47036532",
      "title": "Lobster: My Personal AI Assistant",
      "link": "https://www.omarknows.ai/p/meet-lobster-my-personal-ai-assistant",
      "hn_link": "https://news.ycombinator.com/item?id=47036532",
      "points": 2,
      "comments": 0,
      "published": "2026-02-16",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47027121",
      "title": "PicoClaw: Ultra-Efficient AI Assistant in Go",
      "link": "https://github.com/sipeed/picoclaw",
      "hn_link": "https://news.ycombinator.com/item?id=47027121",
      "points": 2,
      "comments": 0,
      "published": "2026-02-15",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47019250",
      "title": "Show HN: FoodCraft – AI cooking assistant that adapts recipes to your diet/goals",
      "link": "https://foodcraft.app/en",
      "hn_link": "https://news.ycombinator.com/item?id=47019250",
      "points": 2,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47058763",
      "title": "Ask HN: Are we missing a middleware layer between LLM agents and the web?",
      "link": "https://news.ycombinator.com/item?id=47058763",
      "hn_link": "https://news.ycombinator.com/item?id=47058763",
      "points": 1,
      "comments": 2,
      "published": "2026-02-18",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47046780",
      "title": "Show HN: Preventing runaway LLM agents (enforcement layer)",
      "link": "https://github.com/amabito/veronica-core",
      "hn_link": "https://news.ycombinator.com/item?id=47046780",
      "points": 1,
      "comments": 2,
      "published": "2026-02-17",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47029655",
      "title": "AI is slowly munching away my passion",
      "link": "https://whynot.fail/human/ai-is-slowly-munching-away-my-passion/",
      "hn_link": "https://news.ycombinator.com/item?id=47029655",
      "points": 1,
      "comments": 1,
      "published": "2026-02-16",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "47035701",
      "title": "Show HN: A \"content compiler\" that turns LLM output into validated artifacts",
      "link": "https://gixo.ai",
      "hn_link": "https://news.ycombinator.com/item?id=47035701",
      "points": 1,
      "comments": 0,
      "published": "2026-02-16",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47088361",
      "title": "Software Collaboration in the AI Age",
      "link": "https://spiess.dev/blog/software-collaboration-in-the-ai-age",
      "hn_link": "https://news.ycombinator.com/item?id=47088361",
      "points": 1,
      "comments": 0,
      "published": "2026-02-20",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    }
  ],
  "reddit": [],
  "blogs": [
    {
      "名称": "Anthropic Research",
      "链接": "https://anthropic.com/research",
      "说明": "Claude生态，MCP协议，human-AI交互理念"
    },
    {
      "名称": "OpenAI Research",
      "链接": "https://openai.com/research",
      "说明": "GPT系列、agent框架、ChatGPT产品迭代"
    },
    {
      "名称": "Google DeepMind",
      "链接": "https://deepmind.google/research",
      "说明": "Gemini、agent研究、AI safety"
    },
    {
      "名称": "Microsoft Research Blog",
      "链接": "https://microsoft.com/en-us/research/blog",
      "说明": "HAX Toolkit, Human-AI Interaction Guidelines, Copilot"
    },
    {
      "名称": "Meta AI (FAIR)",
      "链接": "https://ai.meta.com/research",
      "说明": "Llama开源生态"
    },
    {
      "名称": "Amazon Science",
      "链接": "https://amazon.science",
      "说明": "应用型AI研究"
    },
    {
      "名称": "Apple Machine Learning",
      "链接": "https://machinelearning.apple.com",
      "说明": "设备端AI、隐私AI"
    },
    {
      "名称": "Hugging Face Blog",
      "链接": "https://huggingface.co/blog",
      "说明": "开源模型、工具、社区趋势"
    },
    {
      "名称": "LangChain Blog",
      "链接": "https://blog.langchain.dev",
      "说明": "Agent框架生态风向标"
    }
  ],
  "newsletters": [
    {
      "名称": "Simon Willison's Blog",
      "链接": "https://simonwillison.net",
      "作者": "Simon Willison",
      "说明": "LLM生态最全面的实践者视角"
    },
    {
      "名称": "Ahead of AI",
      "链接": "https://magazine.sebastianraschka.com",
      "作者": "Sebastian Raschka",
      "说明": "LLM研究深度解读"
    },
    {
      "名称": "Interconnects",
      "链接": "https://interconnects.ai",
      "作者": "Nathan Lambert",
      "说明": "RLHF/对齐方向"
    },
    {
      "名称": "Latent Space",
      "链接": "https://latent.space",
      "作者": "Swyx & Alessio",
      "说明": "AI工程师视角，agent和tooling"
    },
    {
      "名称": "MIT Technology Review",
      "链接": "https://technologyreview.com",
      "作者": "编辑团队",
      "说明": "日刊科技新闻"
    },
    {
      "名称": "The Batch",
      "链接": "https://deeplearning.ai/the-batch",
      "作者": "Andrew Ng",
      "说明": "AI新闻周报"
    },
    {
      "名称": "Import AI",
      "链接": "https://importai.substack.com",
      "作者": "Jack Clark",
      "说明": "偏policy和大趋势"
    },
    {
      "名称": "阮一峰的网络日志",
      "链接": "https://ruanyifeng.com/blog",
      "作者": "阮一峰",
      "说明": "中文技术圈信号"
    }
  ],
  "researchers": [
    {
      "姓名": "Anthropic",
      "链接": "https://x.com/AnthropicAI",
      "平台": "X",
      "说明": "AI safety and research company"
    },
    {
      "姓名": "Claude",
      "链接": "https://x.com/claudeai",
      "平台": "X",
      "说明": "safe, accurate, and secure"
    },
    {
      "姓名": "OpenAI",
      "链接": "https://x.com/OpenAI",
      "平台": "X",
      "说明": "artificial general intelligence benefits all of humanity"
    },
    {
      "姓名": "Sherry Tongshuang Wu",
      "链接": "https://x.com/tongshuangwu",
      "平台": "X",
      "说明": "HCI×NLP，human-AI interaction"
    },
    {
      "姓名": "Diyi Yang",
      "链接": "https://x.com/Diyi_Yang",
      "平台": "X",
      "说明": "Human-AI"
    },
    {
      "姓名": "Ziang Xiao",
      "链接": "https://x.com/ZiangXiao",
      "平台": "X",
      "说明": "AI4SocialScience, Model Evaluation, Information Seeking"
    },
    {
      "姓名": "Mark Dredze",
      "链接": "https://x.com/mdredze",
      "平台": "X",
      "说明": "NLP"
    },
    {
      "姓名": "Wesley Hanwen Deng",
      "链接": "https://x.com/wes_deng",
      "平台": "X",
      "说明": "Human-AI"
    },
    {
      "姓名": "Mina Lee",
      "链接": "https://x.com/MinaLee__",
      "平台": "X",
      "说明": "Human-AI collaborative writing"
    },
    {
      "姓名": "Jentse Huang",
      "链接": "https://x.com/JentseHuang",
      "平台": "X",
      "说明": "LLM + Social Science, Multi-Agent, AI Fairness"
    },
    {
      "姓名": "Toby Jia-Jun Li",
      "链接": "https://x.com/TobyJLi",
      "平台": "X",
      "说明": "End-user programming, human-AI systems"
    },
    {
      "姓名": "Dakuo Wang",
      "链接": "https://x.com/dakuowang",
      "平台": "X",
      "说明": "Human-AI collaboration, CSCW"
    },
    {
      "姓名": "Percy Liang",
      "链接": "https://x.com/percyliang",
      "平台": "X",
      "说明": "LLM evaluation框架"
    },
    {
      "姓名": "Michael Bernstein",
      "链接": "https://x.com/msbernst",
      "平台": "X",
      "说明": "Generative agents, social computing"
    },
    {
      "姓名": "Simon Willison",
      "链接": "https://x.com/simonw",
      "平台": "X",
      "说明": "LLM工具生态最佳信息源"
    },
    {
      "姓名": "Joon Sung Park",
      "链接": "https://x.com/joon_s_pk",
      "平台": "X",
      "说明": "Social Simulations"
    },
    {
      "姓名": "Andrej Karpathy",
      "链接": "https://x.com/karpathy",
      "平台": "X",
      "说明": "深度技术解读"
    },
    {
      "姓名": "Swyx",
      "链接": "https://x.com/swyx",
      "平台": "X",
      "说明": "AI工程/agent生态trend"
    },
    {
      "姓名": "Saleema Amershi",
      "链接": "https://x.com/SaleemaAmershi",
      "平台": "X",
      "说明": "Human-AI Interaction Guidelines"
    },
    {
      "姓名": "Q. Vera Liao",
      "链接": "https://x.com/QVeraLiao",
      "平台": "X",
      "说明": "Explainable AI, responsible AI in HCI"
    },
    {
      "姓名": "Xiang 'Anthony' Chen",
      "链接": "https://x.com/_xiang_chen_",
      "平台": "X",
      "说明": "Interactive AI systems"
    }
  ],
  "podcasts": [
    {
      "名称": "Latent Space Podcast",
      "链接": "https://latent.space",
      "说明": "AI工程最前沿，agent相关讨论"
    },
    {
      "名称": "TWIML AI Podcast",
      "链接": "https://twimlai.com",
      "说明": "学术+工业混合视角"
    },
    {
      "名称": "NeurIPS/CHI 录播",
      "链接": "https://youtube.com",
      "说明": "重要talk的录播"
    }
  ],
  "conferences": [
    {
      "名称": "CHI GenAICHI Workshop",
      "链接": "https://genai-chi.github.io",
      "频率": "年度",
      "说明": "Generative AI × HCI"
    },
    {
      "名称": "HHAI Conference",
      "链接": "https://hhai-conference.org",
      "频率": "年度",
      "说明": "Hybrid Human-AI Intelligence"
    },
    {
      "名称": "CHI TREW Workshop",
      "链接": "https://trew-workshop.github.io",
      "频率": "年度",
      "说明": "Trust & Reliance in Human-AI Workflows"
    },
    {
      "名称": "ACL/EMNLP HCI+NLP Workshop",
      "链接": "https://aclanthology.org",
      "频率": "年度",
      "说明": "HCI×NLP交叉"
    },
    {
      "名称": "IUI Conference",
      "链接": "https://iui.acm.org",
      "频率": "年度",
      "说明": "Intelligent User Interfaces"
    },
    {
      "名称": "NeurIPS/ICML Agent Workshops",
      "链接": "https://neurips.cc",
      "频率": "年度",
      "说明": "系统/ML视角的agent研究"
    },
    {
      "名称": "CHI",
      "链接": "https://chi2026.acm.org",
      "频率": "年度",
      "说明": "ACM顶会, Human-Computer Interaction核心会议"
    },
    {
      "名称": "CSCW",
      "链接": "https://cscw.acm.org",
      "频率": "年度",
      "说明": "Computer-Supported Cooperative Work, 协作与社会计算"
    },
    {
      "名称": "UIST",
      "链接": "https://uist.acm.org",
      "频率": "年度",
      "说明": "User Interface Software and Technology"
    },
    {
      "名称": "ICSE",
      "链接": "https://conf.researchr.org/home/icse-2026",
      "频率": "年度",
      "说明": "软件工程顶会, AI4SE/SE4AI方向"
    },
    {
      "名称": "ICLR",
      "链接": "https://iclr.cc",
      "频率": "年度",
      "说明": "表示学习顶会, LLM/foundation model前沿"
    },
    {
      "名称": "NeurIPS",
      "链接": "https://neurips.cc",
      "频率": "年度",
      "说明": "ML/AI最大顶会, agent/alignment/human-AI"
    },
    {
      "名称": "ICML",
      "链接": "https://icml.cc",
      "频率": "年度",
      "说明": "机器学习顶会"
    },
    {
      "名称": "ACL",
      "链接": "https://www.aclweb.org",
      "频率": "年度",
      "说明": "NLP顶会, human-LLM interaction相关"
    },
    {
      "名称": "EMNLP",
      "链接": "https://www.aclweb.org",
      "频率": "年度",
      "说明": "NLP顶会, empirical methods"
    },
    {
      "名称": "AAAI",
      "链接": "https://aaai.org",
      "频率": "年度",
      "说明": "综合AI顶会, human-AI collaboration track"
    },
    {
      "名称": "FAccT",
      "链接": "https://facctconference.org",
      "频率": "年度",
      "说明": "Fairness, Accountability, Transparency in AI"
    },
    {
      "名称": "AIES",
      "链接": "https://www.aies-conference.com",
      "频率": "年度",
      "说明": "AI, Ethics, and Society"
    },
    {
      "名称": "DIS",
      "链接": "https://dis.acm.org",
      "频率": "年度",
      "说明": "Designing Interactive Systems"
    },
    {
      "名称": "ASSETS",
      "链接": "https://assets.acm.org",
      "频率": "年度",
      "说明": "Accessible Computing, AI accessibility"
    }
  ],
  "opportunities": [
    {
      "名称": "NSF CAREER Award",
      "链接": "https://www.nsf.gov/funding/opportunities?fund_program_desc=CAREER",
      "类型": "🏛️ NSF Grant",
      "说明": "≥$400K/5yr, tenure-track AP, most prestigious early career award. Deadline: ~July yearly. 拿到faculty offer后优先准备"
    },
    {
      "名称": "NSF CRII (Research Initiation)",
      "链接": "https://www.nsf.gov/funding/opportunities?fund_program_desc=CRII",
      "类型": "🏛️ NSF Grant",
      "说明": "≤$175K/24mo, non-R1 early career, PhD后3年内未拿过联邦PI grant. 适合刚入职non-R1的新AP"
    },
    {
      "名称": "NSF CISE Future CoRe",
      "链接": "https://www.nsf.gov/cise/funding.jsp",
      "类型": "🏛️ NSF Grant",
      "说明": "$150K-$250K/yr, max $1M/4yr. 覆盖human-AI interaction, NLP, SE. Deadline: Feb 5, 2026. 与研究方向高度匹配"
    },
    {
      "名称": "NSF EAGER",
      "链接": "https://www.nsf.gov/funding/pgm_summ.jsp?pims_id=504784",
      "类型": "🏛️ NSF Grant",
      "说明": "高风险高回报exploratory research, AI×社会交叉(human-AI, bias, fairness). 需program officer邀请/推荐"
    },
    {
      "名称": "NSF Engineering Postdoc Fellowship",
      "链接": "https://www.nsf.gov/funding/",
      "类型": "🏛️ NSF Fellowship",
      "说明": "Stipend + travel, 2年. 仅限US citizens/permanent residents"
    },
    {
      "名称": "CRA Trustworthy AI Fellowship",
      "链接": "https://cra.org/",
      "类型": "🎓 Fellowship",
      "说明": "⏰ $17K stipend + travel. PhD 2023.5-2025.7. Deadline: March 31, 2026. Human-AI + qualitative背景很match"
    },
    {
      "名称": "Cooperative AI Foundation Grants",
      "链接": "https://www.cooperativeai.com/",
      "类型": "🎓 Foundation",
      "说明": "最高GBP 100K/12mo, early-career track (PhD后2-3年). AI合作、多智能体系统"
    },
    {
      "名称": "Sloan Metascience & AI Postdoc",
      "链接": "https://sloan.org/",
      "类型": "🎓 Fellowship",
      "说明": "最高$250K/2yr. Social sciences方向, AI对科学研究的影响"
    },
    {
      "名称": "iSchools Research Grants",
      "链接": "https://ischools.org/",
      "类型": "🎓 Grant",
      "说明": "Early career faculty & PhD students. July deadline, 主题每年变. Information science相关"
    },
    {
      "名称": "Stanford HAI Seed Grants",
      "链接": "https://hai.stanford.edu/",
      "类型": "🏢 University",
      "说明": "最高$75K/12mo. Stanford affiliated only. Augmenting human capabilities & human-AI interaction"
    },
    {
      "名称": "Penn AI Fellowship",
      "链接": "https://www.upenn.edu/",
      "类型": "🏢 University",
      "说明": "$8K research/travel fund + faculty mentoring. Penn postdocs/grad students only"
    },
    {
      "名称": "RGC Early Career Scheme (ECS)",
      "链接": "https://www.ugc.edu.hk/eng/rgc/funding_opport/ecs/",
      "类型": "🇭🇰 HK Grant",
      "说明": "最高HK$2M/5yr, tenure-track AP入职前3年. 成功率~33%. Deadline: ~10月底. 香港新AP最重要的起步grant"
    },
    {
      "名称": "RGC General Research Fund (GRF)",
      "链接": "https://www.ugc.edu.hk/eng/rgc/funding_opport/grf/",
      "类型": "🇭🇰 HK Grant",
      "说明": "最高HK$2M, 成功率~30%, UGC大学academic staff"
    },
    {
      "名称": "RGC Collaborative Research Fund (CRF)",
      "链接": "https://www.ugc.edu.hk/eng/rgc/funding_opport/crf/",
      "类型": "🇭🇰 HK Grant",
      "说明": "最高HK$10M, 跨学科跨院校合作. 适合大型human-AI collaboration项目"
    },
    {
      "名称": "RGC Research Impact Fund (RIF)",
      "链接": "https://www.ugc.edu.hk/eng/rgc/funding_opport/rif/",
      "类型": "🇭🇰 HK Grant",
      "说明": "侧重societal impact. 适合AI-for-qualitative-analysis方向, impact story很强"
    },
    {
      "名称": "Singapore NRF Fellowship",
      "链接": "https://www.nrf.gov.sg/grants/nrff/",
      "类型": "🇸🇬 SG Grant",
      "说明": "最高SGD 3M(~US$2M)/5yr, 40岁以下all nationalities. 最prestigious early career grant, SUTD背景加分"
    },
    {
      "名称": "MOE Academic Research Fund (AcRF)",
      "链接": "https://www.moe.gov.sg/",
      "类型": "🇸🇬 SG Grant",
      "说明": "Tier 1: 新AP通常可拿到. Tier 2: 竞争性grant需向MOE申请"
    },
    {
      "名称": "AISG Research-Governance Joint Grant",
      "链接": "https://aisingapore.org/research/joint-grant-call/",
      "类型": "🇸🇬 SG Grant",
      "说明": "AI governance + human-machine interaction + social resilience. Research profile完美match: AI + social science + trustworthy AI"
    },
    {
      "名称": "ARC DECRA",
      "链接": "https://www.arc.gov.au/",
      "类型": "🇦🇺 AU Grant",
      "说明": "3yr, 年薪$126K + 项目经费$50K/yr. 成功率13.1%. DE27申请: 2026.1.28-3.11. 申Sydney的话这个很关键"
    },
    {
      "名称": "ARC Future Fellowships",
      "链接": "https://www.arc.gov.au/",
      "类型": "🇦🇺 AU Grant",
      "说明": "Mid-career researcher. FT26已关闭, 关注FT27"
    },
    {
      "名称": "ARC Discovery Projects",
      "链接": "https://www.arc.gov.au/",
      "类型": "🇦🇺 AU Grant",
      "说明": "澳洲core research grant, 类似NSF standard grant. 拿到faculty后申请"
    },
    {
      "名称": "ARC Linkage Projects",
      "链接": "https://www.arc.gov.au/",
      "类型": "🇦🇺 AU Grant",
      "说明": "需industry partner合作. 适合open-source tool有industry adoption的情况"
    },
    {
      "名称": "Microsoft Research Fellowship 2026",
      "链接": "https://www.microsoft.com/en-us/research/academic-program/phd-fellowship/",
      "类型": "🌏 International",
      "说明": "美加$47K, 欧洲$27K, 亚太$17K. 覆盖human-AI collaboration. 2026轮次已过(Dec 2025), 关注2027"
    },
    {
      "名称": "ACM SIGCHI Open Positions",
      "链接": "https://sigchi.org/resources/open-positions/",
      "类型": "📋 Job Board",
      "说明": "HCI academic positions"
    },
    {
      "名称": "CRA Job Board",
      "链接": "https://cra.org/ads/",
      "类型": "📋 Job Board",
      "说明": "CS academic positions"
    }
  ]
}