{
  "meta": {
    "fetched_at": "2026-02-15T22:14:07.246287",
    "lookback_days": 7,
    "keywords": [
      "human-AI collaboration",
      "LLM agent",
      "AI agent",
      "agentic AI",
      "human-centered AI",
      "qualitative analysis LLM",
      "human-LLM interaction",
      "responsible AI",
      "trustworthy AI",
      "AI-assisted analysis",
      "collaborative AI systems",
      "computer-supported cooperative work"
    ]
  },
  "arxiv": [
    {
      "id": "2602.11527v1",
      "title": "CausalAgent: A Conversational Multi-Agent System for End-to-End Causal Inference",
      "authors": [
        "Jiawei Zhu",
        "Wei Chen",
        "Ruichu Cai"
      ],
      "summary": "Causal inference holds immense value in fields such as healthcare, economics, and social sciences. However, traditional causal analysis workflows impose significant technical barriers, requiring researchers to possess dual backgrounds in statistics and computer science, while manually selecting algorithms, handling data quality issues, and interpreting complex results. To address these challenges, we propose CausalAgent, a conversational multi-agent system for end-to-end causal inference. The sy",
      "published": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11527v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.11522v1",
      "title": "Implications of AI Involvement for Trust in Expert Advisory Workflows Under Epistemic Dependence",
      "authors": [
        "Dennis Kim",
        "Roya Daneshi",
        "Bruce Draper",
        "Sarath Sreedharan"
      ],
      "summary": "The increasing integration of AI-powered tools into expert workflows, such as medicine, law, and finance, raises a critical question: how does AI involvement influence a user's trust in the human expert, the AI system, and their combination? To investigate this, we conducted a user study (N=77) featuring a simulated course-planning task. We compared various conditions that differed in both the presence of AI and the specific mode of human-AI collaboration. Our results indicate that while the adv",
      "published": "2026-02-12",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.11522v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.12259v1",
      "title": "Think like a Scientist: Physics-guided LLM Agent for Equation Discovery",
      "authors": [
        "Jianke Yang",
        "Ohm Venkatachalam",
        "Mohammad Kianezhad",
        "Sharvaree Vadgama",
        "Rose Yu"
      ],
      "summary": "Explaining observed phenomena through symbolic, interpretable formulas is a fundamental goal of science. Recently, large language models (LLMs) have emerged as promising tools for symbolic equation discovery, owing to their broad domain knowledge and strong reasoning capabilities. However, most existing LLM-based systems try to guess equations directly from data, without modeling the multi-step reasoning process that scientists often follow: first inferring physical properties such as symmetries",
      "published": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.12259v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11964v1",
      "title": "Gaia2: Benchmarking LLM Agents on Dynamic and Asynchronous Environments",
      "authors": [
        "Romain Froger",
        "Pierre Andrews",
        "Matteo Bettini",
        "Amar Budhiraja",
        "Ricardo Silveira Cabral"
      ],
      "summary": "We introduce Gaia2, a benchmark for evaluating large language model agents in realistic, asynchronous environments. Unlike prior static or synchronous evaluations, Gaia2 introduces scenarios where environments evolve independently of agent actions, requiring agents to operate under temporal constraints, adapt to noisy and dynamic events, resolve ambiguity, and collaborate with other agents. Each scenario is paired with a write-action verifier, enabling fine-grained, action-level evaluation and m",
      "published": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11964v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11767v1",
      "title": "TSR: Trajectory-Search Rollouts for Multi-Turn RL of LLM Agents",
      "authors": [
        "Aladin Djuhera",
        "Swanand Ravindra Kadhe",
        "Farhan Ahmed",
        "Holger Boche"
      ],
      "summary": "Advances in large language models (LLMs) are driving a shift toward using reinforcement learning (RL) to train agents from iterative, multi-turn interactions across tasks. However, multi-turn RL remains challenging as rewards are often sparse or delayed, and environments can be stochastic. In this regime, naive trajectory sampling can hinder exploitation and induce mode collapse. We propose TSR (Trajectory-Search Rollouts), a training-time approach that repurposes test-time scaling ideas for imp",
      "published": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.11767v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11754v1",
      "title": "Cooperation Breakdown in LLM Agents Under Communication Delays",
      "authors": [
        "Keita Nishimoto",
        "Kimitaka Asatani",
        "Ichiro Sakata"
      ],
      "summary": "LLM-based multi-agent systems (LLM-MAS), in which autonomous AI agents cooperate to solve tasks, are gaining increasing attention. For such systems to be deployed in society, agents must be able to establish cooperation and coordination under real-world computational and communication constraints. We propose the FLCOA framework (Five Layers for Cooperation/Coordination among Autonomous Agents) to conceptualize how cooperation and coordination emerge in groups of autonomous agents, and highlight ",
      "published": "2026-02-12",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT"
      ],
      "link": "https://arxiv.org/abs/2602.11754v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11749v1",
      "title": "AIR: Improving Agent Safety through Incident Response",
      "authors": [
        "Zibo Xiao",
        "Jun Sun",
        "Junjie Chen"
      ],
      "summary": "Large Language Model (LLM) agents are increasingly deployed in practice across a wide range of autonomous applications. Yet current safety mechanisms for LLM agents focus almost exclusively on preventing failures in advance, providing limited capabilities for responding to, containing, or recovering from incidents after they inevitably arise. In this work, we introduce AIR, the first incident response framework for LLM agent systems. AIR defines a domain-specific language for managing the incide",
      "published": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11749v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11619v1",
      "title": "When Agents Disagree With Themselves: Measuring Behavioral Consistency in LLM-Based Agents",
      "authors": [
        "Aman Mehta"
      ],
      "summary": "Run the same LLM agent on the same task twice: do you get the same behavior? We find the answer is often no. In a study of 3,000 agent runs across three models (Llama 3.1 70B, GPT-4o, and Claude Sonnet 4.5) on HotpotQA, we observe that ReAct-style agents produce 2.0--4.2 distinct action sequences per 10 runs on average, even with identical inputs. More importantly, this variance predicts failure: tasks with consistent behavior ($\\leq$2 unique paths) achieve 80--92% accuracy, while highly inconsi",
      "published": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11619v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.12268v1",
      "title": "CM2: Reinforcement Learning with Checklist Rewards for Multi-Turn and Multi-Step Agentic Tool Use",
      "authors": [
        "Zhen Zhang",
        "Kaiqiang Song",
        "Xun Wang",
        "Yebowen Hu",
        "Weixiang Yan"
      ],
      "summary": "AI agents are increasingly used to solve real-world tasks by reasoning over multi-turn user interactions and invoking external tools. However, applying reinforcement learning to such settings remains difficult: realistic objectives often lack verifiable rewards and instead emphasize open-ended behaviors; moreover, RL for multi-turn, multi-step agentic tool use is still underexplored; and building and maintaining executable tool environments is costly, limiting scale and coverage. We propose CM2,",
      "published": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.12268v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.12207v1",
      "title": "VIRENA: Virtual Arena for Research, Education, and Democratic Innovation",
      "authors": [
        "Emma Hoes",
        "K. Jonathan Klueser",
        "Fabrizio Gilardi"
      ],
      "summary": "Digital platforms shape how people communicate, deliberate, and form opinions. Studying these dynamics has become increasingly difficult due to restricted data access, ethical constraints on real-world experiments, and limitations of existing research tools. VIRENA (Virtual Arena) is a platform that enables controlled experimentation in realistic social media environments. Multiple participants interact simultaneously in realistic replicas of feed-based platforms (Instagram, Facebook, Reddit) an",
      "published": "2026-02-12",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SI"
      ],
      "link": "https://arxiv.org/abs/2602.12207v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.12144v1",
      "title": "On the Adoption of AI Coding Agents in Open-source Android and iOS Development",
      "authors": [
        "Muhammad Ahmad Khan",
        "Hasnain Ali",
        "Muneeb Rana",
        "Muhammad Saqib Ilyas",
        "Abdul Ali Bangash"
      ],
      "summary": "AI coding agents are increasingly contributing to software development, yet their impact on mobile development has received little empirical attention. In this paper, we present the first category-level empirical study of agent-generated code in open-source mobile app projects. We analyzed PR acceptance behaviors across mobile platforms, agents, and task categories using 2,901 AI-authored pull requests (PRs) in 193 verified Android and iOS open-source GitHub repositories in the AIDev dataset. We",
      "published": "2026-02-12",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.12144v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.12136v1",
      "title": "Embodied AI Agents for Team Collaboration in Co-located Blue-Collar Work",
      "authors": [
        "Kaisa Vaananen",
        "Niels van Berkel",
        "Donald McMillan",
        "Thomas Olsson"
      ],
      "summary": "Blue-collar work is often highly collaborative, embodied, and situated in shared physical environments, yet most research on collaborative AI has focused on white-collar work. This position paper explores how the embodied nature of AI agents can support team collaboration and communication in co-located blue-collar workplaces. From the context of our newly started CAI-BLUE research project, we present two speculative scenarios from industrial and maintenance contexts that illustrate how embodied",
      "published": "2026-02-12",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.12136v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11931v1",
      "title": "AdaptEvolve: Improving Efficiency of Evolutionary AI Agents through Adaptive Model Selection",
      "authors": [
        "Pretam Ray",
        "Pratik Prabhanjan Brahma",
        "Zicheng Liu",
        "Emad Barsoum"
      ],
      "summary": "Evolutionary agentic systems intensify the trade-off between computational efficiency and reasoning capability by repeatedly invoking large language models (LLMs) during inference. This setting raises a central question: how can an agent dynamically select an LLM that is sufficiently capable for the current generation step while remaining computationally efficient? While model cascades offer a practical mechanism for balancing this trade-off, existing routing strategies typically rely on static ",
      "published": "2026-02-12",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11931v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11897v1",
      "title": "Agentic AI for Cybersecurity: A Meta-Cognitive Architecture for Governable Autonomy",
      "authors": [
        "Andrei Kojukhov",
        "Arkady Bovshover"
      ],
      "summary": "Contemporary AI-driven cybersecurity systems are predominantly architected as model-centric detection and automation pipelines optimized for task-level performance metrics such as accuracy and response latency. While effective for bounded classification tasks, these architectures struggle to support accountable decision-making under adversarial uncertainty, where actions must be justified, governed, and aligned with organizational and regulatory constraints. This paper argues that cybersecurity ",
      "published": "2026-02-12",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11897v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11865v1",
      "title": "Intelligent AI Delegation",
      "authors": [
        "Nenad Tomašev",
        "Matija Franklin",
        "Simon Osindero"
      ],
      "summary": "AI agents are able to tackle increasingly complex tasks. To achieve more ambitious goals, AI agents need to be able to meaningfully decompose problems into manageable sub-components, and safely delegate their completion across to other AI agents and humans alike. Yet, existing task decomposition and delegation methods rely on simple heuristics, and are not able to dynamically adapt to environmental changes and robustly handle unexpected failures. Here we propose an adaptive framework for intelli",
      "published": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11865v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.12083v1",
      "title": "Differentiable Modal Logic for Multi-Agent Diagnosis, Orchestration and Communication",
      "authors": [
        "Antonin Sulc"
      ],
      "summary": "As multi-agent AI systems evolve from simple chatbots to autonomous swarms, debugging semantic failures requires reasoning about knowledge, belief, causality, and obligation, precisely what modal logic was designed to formalize. However, traditional modal logic requires manual specification of relationship structures that are unknown or dynamic in real systems. This tutorial demonstrates differentiable modal logic (DML), implemented via Modal Logical Neural Networks (MLNNs), enabling systems to ",
      "published": "2026-02-12",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "link": "https://arxiv.org/abs/2602.12083v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.11574v1",
      "title": "Learning to Configure Agentic AI Systems",
      "authors": [
        "Aditya Taparia",
        "Som Sagar",
        "Ransalu Senanayake"
      ],
      "summary": "Configuring LLM-based agent systems involves choosing workflows, tools, token budgets, and prompts from a large combinatorial design space, and is typically handled today by fixed large templates or hand-tuned heuristics. This leads to brittle behavior and unnecessary compute, since the same cumbersome configuration is often applied to both easy and hard input queries. We formulate agent configuration as a query-wise decision problem and introduce ARC (Agentic Resource & Configuration learner), ",
      "published": "2026-02-12",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11574v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.11924v1",
      "title": "Who Does What? Archetypes of Roles Assigned to LLMs During Human-AI Decision-Making",
      "authors": [
        "Shreya Chappidi",
        "Jatinder Singh",
        "Andra V. Krauze"
      ],
      "summary": "LLMs are increasingly supporting decision-making across high-stakes domains, requiring critical reflection on the socio-technical factors that shape how humans and LLMs are assigned roles and interact during human-in-the-loop decision-making. This paper introduces the concept of human-LLM archetypes -- defined as re-curring socio-technical interaction patterns that structure the roles of humans and LLMs in collaborative decision-making. We describe 17 human-LLM archetypes derived from a scoping ",
      "published": "2026-02-12",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11924v1",
      "matched_keyword": "human-LLM interaction",
      "source": "arxiv"
    },
    {
      "id": "2602.11025v1",
      "title": "Reality Copilot: Voice-First Human-AI Collaboration in Mixed Reality Using Large Multimodal Models",
      "authors": [
        "Liuchuan Yu",
        "Yongqi Zhang",
        "Lap-Fai Yu"
      ],
      "summary": "Large Multimodal Models (LMMs) have shown strong potential for assisting users in tasks, such as programming, content creation, and information access, yet their interaction remains largely limited to traditional interfaces such as desktops and smartphones. Meanwhile, advances in mixed reality (MR) hardware have enabled applications that extend beyond entertainment and into everyday use. However, most existing MR systems rely primarily on manual input (e.g., hand gestures or controllers) and pro",
      "published": "2026-02-11",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.11025v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.11354v1",
      "title": "ReplicatorBench: Benchmarking LLM Agents for Replicability in Social and Behavioral Sciences",
      "authors": [
        "Bang Nguyen",
        "Dominik Soós",
        "Qian Ma",
        "Rochana R. Obadage",
        "Zack Ranjan"
      ],
      "summary": "The literature has witnessed an emerging interest in AI agents for automated assessment of scientific papers. Existing benchmarks focus primarily on the computational aspect of this task, testing agents' ability to reproduce or replicate research outcomes when having access to the code and data. This setting, while foundational, (1) fails to capture the inconsistent availability of new data for replication as opposed to reproduction, and (2) lacks ground-truth diversity by focusing only on repro",
      "published": "2026-02-11",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.11354v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11351v1",
      "title": "Pushing Forward Pareto Frontiers of Proactive Agents with Behavioral Agentic Optimization",
      "authors": [
        "Yihang Yao",
        "Zhepeng Cen",
        "Haohong Lin",
        "Shiqi Liu",
        "Zuxin Liu"
      ],
      "summary": "Proactive large language model (LLM) agents aim to actively plan, query, and interact over multiple turns, enabling efficient task completion beyond passive instruction following and making them essential for real-world, user-centric applications. Agentic reinforcement learning (RL) has recently emerged as a promising solution for training such agents in multi-turn settings, allowing interaction strategies to be learned from feedback. However, existing pipelines face a critical challenge in bala",
      "published": "2026-02-11",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.11351v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11348v1",
      "title": "AgentNoiseBench: Benchmarking Robustness of Tool-Using LLM Agents Under Noisy Condition",
      "authors": [
        "Ruipeng Wang",
        "Yuxin Chen",
        "Yukai Wang",
        "Chang Wu",
        "Junfeng Fang"
      ],
      "summary": "Recent advances in large language models have enabled LLM-based agents to achieve strong performance on a variety of benchmarks. However, their performance in real-world deployments often that observed on benchmark settings, especially in complex and imperfect environments. This discrepancy largely arises because prevailing training and evaluation paradigms are typically built on idealized assumptions, overlooking the inherent stochasticity and noise present in real-world interactions. To bridge",
      "published": "2026-02-11",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11348v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11243v1",
      "title": "Evaluating Memory Structure in LLM Agents",
      "authors": [
        "Alina Shutova",
        "Alexandra Olenina",
        "Ivan Vinogradov",
        "Anton Sinitsin"
      ],
      "summary": "Modern LLM-based agents and chat assistants rely on long-term memory frameworks to store reusable knowledge, recall user preferences, and augment reasoning. As researchers create more complex memory architectures, it becomes increasingly difficult to analyze their capabilities and guide future memory designs. Most long-term memory benchmarks focus on simple fact retention, multi-hop recall, and time-based changes. While undoubtedly important, these capabilities can often be achieved with simple ",
      "published": "2026-02-11",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.11243v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11224v1",
      "title": "Agent-Diff: Benchmarking LLM Agents on Enterprise API Tasks via Code Execution with State-Diff-Based Evaluation",
      "authors": [
        "Hubert M. Pysklo",
        "Artem Zhuravel",
        "Patrick D. Watson"
      ],
      "summary": "We present Agent-Diff, a novel benchmarking framework for evaluating agentic Large Language Models (LLMs) on real-world tasks that execute code via external APIs. Agentic LLM performance varies due to differences in models, external tool access, prompt structures, and agentic frameworks. Benchmarks must make fundamental trade-offs between a sandboxed approach that controls for variation in software environments and more ecologically valid approaches employing real services. Agent-Diff attempts t",
      "published": "2026-02-11",
      "categories": [
        "cs.SE",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.11224v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.10715v1",
      "title": "Locomo-Plus: Beyond-Factual Cognitive Memory Evaluation Framework for LLM Agents",
      "authors": [
        "Yifei Li",
        "Weidong Guo",
        "Lingling Zhang",
        "Rongman Xu",
        "Muye Huang"
      ],
      "summary": "Long-term conversational memory is a core capability for LLM-based dialogue systems, yet existing benchmarks and evaluation protocols primarily focus on surface-level factual recall. In realistic interactions, appropriate responses often depend on implicit constraints such as user state, goals, or values that are not explicitly queried later. To evaluate this setting, we introduce \\textbf{LoCoMo-Plus}, a benchmark for assessing cognitive memory under cue--trigger semantic disconnect, where model",
      "published": "2026-02-11",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.10715v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.10620v1",
      "title": "ISD-Agent-Bench: A Comprehensive Benchmark for Evaluating LLM-based Instructional Design Agents",
      "authors": [
        "YoungHoon Jeon",
        "Suwan Kim",
        "Haein Son",
        "Sookbun Lee",
        "Yeil Jeong"
      ],
      "summary": "Large Language Model (LLM) agents have shown promising potential in automating Instructional Systems Design (ISD), a systematic approach to developing educational programs. However, evaluating these agents remains challenging due to the lack of standardized benchmarks and the risk of LLM-as-judge bias. We present ISD-Agent-Bench, a comprehensive benchmark comprising 25,795 scenarios generated via a Context Matrix framework that combines 51 contextual variables across 5 categories with 33 ISD sub",
      "published": "2026-02-11",
      "categories": [
        "cs.SE",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.10620v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.10479v1",
      "title": "From Prompt-Response to Goal-Directed Systems: The Evolution of Agentic AI Software Architecture",
      "authors": [
        "Mamdouh Alenezi"
      ],
      "summary": "Agentic AI denotes an architectural transition from stateless, prompt-driven generative models toward goal-directed systems capable of autonomous perception, planning, action, and adaptation through iterative control loops. This paper examines this transition by connecting foundational intelligent agent theories, including reactive, deliberative, and Belief-Desire-Intention models, with contemporary LLM-centric approaches such as tool invocation, memory-augmented reasoning, and multi-agent coord",
      "published": "2026-02-11",
      "categories": [
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.10479v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.10453v1",
      "title": "The Landscape of Prompt Injection Threats in LLM Agents: From Taxonomy to Analysis",
      "authors": [
        "Peiran Wang",
        "Xinfeng Li",
        "Chong Xiang",
        "Jinghuai Zhang",
        "Ying Li"
      ],
      "summary": "The evolution of Large Language Models (LLMs) has resulted in a paradigm shift towards autonomous agents, necessitating robust security against Prompt Injection (PI) vulnerabilities where untrusted inputs hijack agent behaviors. This SoK presents a comprehensive overview of the PI landscape, covering attacks, defenses, and their evaluation practices. Through a systematic literature review and quantitative analysis, we establish taxonomies that categorize PI attacks by payload generation strategi",
      "published": "2026-02-11",
      "categories": [
        "cs.CR",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.10453v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.10429v1",
      "title": "AIvilization v0: Toward Large-Scale Artificial Social Simulation with a Unified Agent Architecture and Adaptive Agent Profiles",
      "authors": [
        "Wenkai Fan",
        "Shurui Zhang",
        "Xiaolong Wang",
        "Haowei Yang",
        "Tsz Wai Chan"
      ],
      "summary": "AIvilization v0 is a publicly deployed large-scale artificial society that couples a resource-constrained sandbox economy with a unified LLM-agent architecture, aiming to sustain long-horizon autonomy while remaining executable under rapidly changing environment. To mitigate the tension between goal stability and reactive correctness, we introduce (i) a hierarchical branch-thinking planner that decomposes life goals into parallel objective branches and uses simulation-guided validation plus tier",
      "published": "2026-02-11",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.10429v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11409v1",
      "title": "TRACER: Trajectory Risk Aggregation for Critical Episodes in Agentic Reasoning",
      "authors": [
        "Sina Tayebati",
        "Divake Kumar",
        "Nastaran Darabi",
        "Davide Ettori",
        "Ranganath Krishnan"
      ],
      "summary": "Estimating uncertainty for AI agents in real-world multi-turn tool-using interaction with humans is difficult because failures are often triggered by sparse critical episodes (e.g., looping, incoherent tool use, or user-agent miscoordination) even when local generation appears confident. Existing uncertainty proxies focus on single-shot text generation and therefore miss these trajectory-level breakdown signals. We introduce TRACER, a trajectory-level uncertainty metric for dual-control Tool-Age",
      "published": "2026-02-11",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11409v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11327v1",
      "title": "Security Threat Modeling for Emerging AI-Agent Protocols: A Comparative Analysis of MCP, A2A, Agora, and ANP",
      "authors": [
        "Zeynab Anbiaee",
        "Mahdi Rabbani",
        "Mansur Mirani",
        "Gunjan Piya",
        "Igor Opushnyev"
      ],
      "summary": "The rapid development of the AI agent communication protocols, including the Model Context Protocol (MCP), Agent2Agent (A2A), Agora, and Agent Network Protocol (ANP), is reshaping how AI agents communicate with tools, services, and each other. While these protocols support scalable multi-agent interaction and cross-organizational interoperability, their security principles remain understudied, and standardized threat modeling is limited; no protocol-centric risk assessment framework has been est",
      "published": "2026-02-11",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11327v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.10814v1",
      "title": "See, Plan, Snap: Evaluating Multimodal GUI Agents in Scratch",
      "authors": [
        "Xingyi Zhang",
        "Yulei Ye",
        "Kaifeng Huang",
        "Wenhao Li",
        "Xiangfeng Wang"
      ],
      "summary": "Block-based programming environments such as Scratch play a central role in low-code education, yet evaluating the capabilities of AI agents to construct programs through Graphical User Interfaces (GUIs) remains underexplored. We introduce ScratchWorld, a benchmark for evaluating multimodal GUI agents on program-by-construction tasks in Scratch. Grounded in the Use-Modify-Create pedagogical framework, ScratchWorld comprises 83 curated tasks spanning four distinct problem categories: Create, Debu",
      "published": "2026-02-11",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.10814v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.11412v1",
      "title": "When Visibility Outpaces Verification: Delayed Verification and Narrative Lock-in in Agentic AI Discourse",
      "authors": [
        "Hanjing Shi",
        "Dominic DiFranzo"
      ],
      "summary": "Agentic AI systems-autonomous entities capable of independent planning and execution-reshape the landscape of human-AI trust. Long before direct system exposure, user expectations are mediated through high-stakes public discourse on social platforms. However, platform-mediated engagement signals (e.g., upvotes) may inadvertently function as a ``credibility proxy,'' potentially stifling critical evaluation.   This paper investigates the interplay between social proof and verification timing in on",
      "published": "2026-02-11",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.11412v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.11301v1",
      "title": "The PBSAI Governance Ecosystem: A Multi-Agent AI Reference Architecture for Securing Enterprise AI Estates",
      "authors": [
        "John M. Willis"
      ],
      "summary": "Enterprises are rapidly deploying large language models, retrieval augmented generation pipelines, and tool using agents into production, often on shared high performance computing clusters and cloud accelerator platforms that also support defensive analytics. These systems increasingly function not as isolated models but as AI estates: socio technical systems spanning models, agents, data pipelines, security tooling, human workflows, and hyperscale infrastructure. Existing governance and securi",
      "published": "2026-02-11",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "link": "https://arxiv.org/abs/2602.11301v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.11024v1",
      "title": "Chain-of-Look Spatial Reasoning for Dense Surgical Instrument Counting",
      "authors": [
        "Rishikesh Bhyri",
        "Brian R Quaranto",
        "Philip J Seger",
        "Kaity Tung",
        "Brendan Fox"
      ],
      "summary": "Accurate counting of surgical instruments in Operating Rooms (OR) is a critical prerequisite for ensuring patient safety during surgery. Despite recent progress of large visual-language models and agentic AI, accurately counting such instruments remains highly challenging, particularly in dense scenarios where instruments are tightly clustered. To address this problem, we introduce Chain-of-Look, a novel visual reasoning framework that mimics the sequential human counting process by enforcing a ",
      "published": "2026-02-11",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.11024v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.10465v1",
      "title": "Authenticated Workflows: A Systems Approach to Protecting Agentic AI",
      "authors": [
        "Mohan Rajagopalan",
        "Vinay Rao"
      ],
      "summary": "Agentic AI systems automate enterprise workflows but existing defenses--guardrails, semantic filters--are probabilistic and routinely bypassed. We introduce authenticated workflows, the first complete trust layer for enterprise agentic AI. Security reduces to protecting four fundamental boundaries: prompts, tools, data, and context. We enforce intent (operations satisfy organizational policies) and integrity (operations are cryptographically authentic) at every boundary crossing, combining crypt",
      "published": "2026-02-11",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.MA"
      ],
      "link": "https://arxiv.org/abs/2602.10465v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.10450v1",
      "title": "Constructing Industrial-Scale Optimization Modeling Benchmark",
      "authors": [
        "Zhong Li",
        "Hongliang Lu",
        "Tao Wei",
        "Wenyu Liu",
        "Yuxuan Chen"
      ],
      "summary": "Optimization modeling underpins decision-making in logistics, manufacturing, energy, and finance, yet translating natural-language requirements into correct optimization formulations and solver-executable code remains labor-intensive. Although large language models (LLMs) have been explored for this task, evaluation is still dominated by toy-sized or synthetic benchmarks, masking the difficulty of industrial problems with $10^{3}$--$10^{6}$ (or more) variables and constraints. A key bottleneck i",
      "published": "2026-02-11",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "link": "https://arxiv.org/abs/2602.10450v1",
      "matched_keyword": "human-LLM interaction",
      "source": "arxiv"
    },
    {
      "id": "2602.10177v2",
      "title": "Towards Autonomous Mathematics Research",
      "authors": [
        "Tony Feng",
        "Trieu H. Trinh",
        "Garrett Bingham",
        "Dawsen Hwang",
        "Yuri Chervonyi"
      ],
      "summary": "Recent advances in foundational models have yielded reasoning systems capable of achieving a gold-medal standard at the International Mathematical Olympiad. The transition from competition-level problem-solving to professional research, however, requires navigating vast literature and constructing long-horizon proofs. In this work, we introduce Aletheia, a math research agent that iteratively generates, verifies, and revises solutions end-to-end in natural language. Specifically, Aletheia is pow",
      "published": "2026-02-10",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "link": "https://arxiv.org/abs/2602.10177v2",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.10001v1",
      "title": "Human-AI Synergy Supports Collective Creative Search",
      "authors": [
        "Chenyi Li",
        "Raja Marjieh",
        "Haoyu Hu",
        "Mark Steyvers",
        "Katherine M. Collins"
      ],
      "summary": "Generative AI is increasingly transforming creativity into a hybrid human-artificial process, but its impact on the quality and diversity of creative output remains unclear. We study collective creativity using a controlled word-guessing task that balances open-endedness with an objective measure of task performance. Participants attempt to infer a hidden target word, scored based on the semantic similarity of their guesses to the target, while also observing the best guess from previous players",
      "published": "2026-02-10",
      "categories": [
        "cs.SI",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.10001v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.09496v1",
      "title": "Jokeasy: Exploring Human-AI Collaboration in Thematic Joke Generation",
      "authors": [
        "Yate Ge",
        "Lin Tian",
        "Chiqian Xu",
        "Luyao Xu",
        "Meiying Li"
      ],
      "summary": "Thematic jokes are central to stand-up comedy, sitcoms, and public speaking, where contexts and punchlines rely on fresh material - news, anecdotes, and cultural references that resonate with the audience. Recent advances in Large Language Models (LLMs) have enabled interactive joke generation through conversational interfaces. Although LLMs enable interactive joke generation, ordinary conversational interfaces seldom give creators enough agency, control, or timely access to such source material",
      "published": "2026-02-10",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.09496v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.09423v1",
      "title": "Beyond Input-Output: Rethinking Creativity through Design-by-Analogy in Human-AI Collaboration",
      "authors": [
        "Xuechen Li",
        "Shuai Zhang",
        "Nan Cao",
        "Qing Chen"
      ],
      "summary": "While the proliferation of foundation models has significantly boosted individual productivity, it also introduces a potential challenge: the homogenization of creative content. In response, we revisit Design-by-Analogy (DbA), a cognitively grounded approach that fosters novel solutions by mapping inspiration across domains. However, prevailing perspectives often restrict DbA to early ideation or specific data modalities, while reducing AI-driven design to simplified input-output pipelines. Such",
      "published": "2026-02-10",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.09423v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.10226v1",
      "title": "Self-Evolving Recommendation System: End-To-End Autonomous Model Optimization With LLM Agents",
      "authors": [
        "Haochen Wang",
        "Yi Wu",
        "Daryl Chang",
        "Li Wei",
        "Lukasz Heldt"
      ],
      "summary": "Optimizing large-scale machine learning systems, such as recommendation models for global video platforms, requires navigating a massive hyperparameter search space and, more critically, designing sophisticated optimizers, architectures, and reward functions to capture nuanced user behaviors. Achieving substantial improvements in these areas is a non-trivial task, traditionally relying on extensive manual iterations to test new hypotheses. We propose a self-evolving system that leverages Large L",
      "published": "2026-02-10",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.10226v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.10046v1",
      "title": "Artisan: Agentic Artifact Evaluation",
      "authors": [
        "Doehyun Baek",
        "Michael Pradel"
      ],
      "summary": "Artifact evaluation has become standard practice in the software engineering community to ensure the reproducibility of research results. However, the current manual process is labor-intensive, and hence, done only as a one-time assessment for a subset of all papers. To support the artifact evaluation effort, we present Artisan, an automated LLM agent for reproducing research results given a paper and its artifact. The approach is enabled by two key contributions: First, we frame the reproductio",
      "published": "2026-02-10",
      "categories": [
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.10046v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.09937v1",
      "title": "Why Do AI Agents Systematically Fail at Cloud Root Cause Analysis?",
      "authors": [
        "Taeyoon Kim",
        "Woohyeok Park",
        "Hoyeong Yun",
        "Kyungyong Lee"
      ],
      "summary": "Failures in large-scale cloud systems incur substantial financial losses, making automated Root Cause Analysis (RCA) essential for operational stability. Recent efforts leverage Large Language Model (LLM) agents to automate this task, yet existing systems exhibit low detection accuracy even with capable models, and current evaluation frameworks assess only final answer correctness without revealing why the agent's reasoning failed. This paper presents a process level failure analysis of LLM-base",
      "published": "2026-02-10",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.09937v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.09817v1",
      "title": "AnalyticsGPT: An LLM Workflow for Scientometric Question Answering",
      "authors": [
        "Khang Ly",
        "Georgios Cheirmpos",
        "Adrian Raudaschl",
        "Christopher James",
        "Seyed Amin Tabatabaei"
      ],
      "summary": "This paper introduces AnalyticsGPT, an intuitive and efficient large language model (LLM)-powered workflow for scientometric question answering. This underrepresented downstream task addresses the subcategory of meta-scientific questions concerning the \"science of science.\" When compared to traditional scientific question answering based on papers, the task poses unique challenges in the planning phase. Namely, the need for named-entity recognition of academic entities within questions and multi",
      "published": "2026-02-10",
      "categories": [
        "cs.CL",
        "cs.DL"
      ],
      "link": "https://arxiv.org/abs/2602.09817v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.10009v1",
      "title": "Discovering High Level Patterns from Simulation Traces",
      "authors": [
        "Sean Memery",
        "Kartic Subr"
      ],
      "summary": "Artificial intelligence (AI) agents embedded in environments with physics-based interaction face many challenges including reasoning, planning, summarization, and question answering. This problem is exacerbated when a human user wishes to either guide or interact with the agent in natural language. Although the use of Language Models (LMs) is the default choice, as an AI tool, they struggle with tasks involving physics. The LM's capability for physical reasoning is learned from observational dat",
      "published": "2026-02-10",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.10009v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.09345v1",
      "title": "AgentCgroup: Understanding and Controlling OS Resources of AI Agents",
      "authors": [
        "Yusheng Zheng",
        "Jiakun Fan",
        "Quanzhi Fu",
        "Yiwei Yang",
        "Wei Zhang"
      ],
      "summary": "AI agents are increasingly deployed in multi-tenant cloud environments, where they execute diverse tool calls within sandboxed containers, each call with distinct resource demands and rapid fluctuations. We present a systematic characterization of OS-level resource dynamics in sandboxed AI coding agents, analyzing 144 software engineering tasks from the SWE-rebench benchmark across two LLM models. Our measurements reveal that (1) OS-level execution (tool calls, container and agent initialization",
      "published": "2026-02-10",
      "categories": [
        "cs.OS",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.09345v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.09286v1",
      "title": "Human Control Is the Anchor, Not the Answer: Early Divergence of Oversight in Agentic AI Communities",
      "authors": [
        "Hanjing Shi",
        "Dominic DiFranzo"
      ],
      "summary": "Oversight for agentic AI is often discussed as a single goal (\"human control\"), yet early adoption may produce role-specific expectations. We present a comparative analysis of two newly active Reddit communities in Jan--Feb 2026 that reflect different socio-technical roles: r/OpenClaw (deployment and operations) and r/Moltbook (agent-centered social interaction). We conceptualize this period as an early-stage crystallization phase, where oversight expectations form before norms reach equilibrium",
      "published": "2026-02-10",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.09286v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.10295v1",
      "title": "ECHO: An Open Research Platform for Evaluation of Chat, Human Behavior, and Outcomes",
      "authors": [
        "Jiqun Liu",
        "Nischal Dinesh",
        "Ran Yu"
      ],
      "summary": "ECHO (Evaluation of Chat, Human behavior, and Outcomes) is an open research platform designed to support reproducible, mixed-method studies of human interaction with both conversational AI systems and Web search engines. It enables researchers from varying disciplines to orchestrate end-to-end experimental workflows that integrate consent and background surveys, chat-based and search-based information-seeking sessions, writing or judgment tasks, and pre- and post-task evaluations within a unifie",
      "published": "2026-02-10",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.IR"
      ],
      "link": "https://arxiv.org/abs/2602.10295v1",
      "matched_keyword": "human-centered AI",
      "source": "arxiv"
    },
    {
      "id": "2602.09841v1",
      "title": "Hybrid Responsible AI-Stochastic Approach for SLA Compliance in Multivendor 6G Networks",
      "authors": [
        "Emanuel Figetakis",
        "Ahmed Refaey Hussein"
      ],
      "summary": "The convergence of AI and 6G network automation introduces new challenges in maintaining transparency, fairness, and accountability across multivendor management systems. Although closed-loop AI orchestration improves adaptability and self-optimization, it also creates a responsibility gap, where violations of SLAs cannot be causally attributed to specific agents or vendors. This paper presents a hybrid responsible AI-stochastic learning framework that embeds fairness, robustness, and auditabili",
      "published": "2026-02-10",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.09841v1",
      "matched_keyword": "responsible AI",
      "source": "arxiv"
    },
    {
      "id": "2602.09269v1",
      "title": "Measuring Inclusion in Interaction: Inclusion Analytics for Human-AI Collaborative Learning",
      "authors": [
        "Jaeyoon Choi",
        "Nia Nixon"
      ],
      "summary": "Inclusion, equity, and access are widely valued in AI and education, yet are often assessed through coarse sample descriptors or post-hoc self-reports that miss how inclusion is shaped moment by moment in collaborative problem solving (CPS). In this proof-of-concept paper, we introduce inclusion analytics, a discourse-based framework for examining inclusion as a dynamic, interactional process in CPS. We conceptualize inclusion along three complementary dimensions -- participation equity, affecti",
      "published": "2026-02-09",
      "categories": [
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.09269v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.09185v1",
      "title": "AIDev: Studying AI Coding Agents on GitHub",
      "authors": [
        "Hao Li",
        "Haoxiang Zhang",
        "Ahmed E. Hassan"
      ],
      "summary": "AI coding agents are rapidly transforming software engineering by performing tasks such as feature development, debugging, and testing. Despite their growing impact, the research community lacks a comprehensive dataset capturing how these agents are used in real-world projects. To address this gap, we introduce AIDev, a large-scale dataset focused on agent-authored pull requests (Agentic-PRs) in real-world GitHub repositories. AIDev aggregates 932,791 Agentic-PRs produced by five agents: OpenAI ",
      "published": "2026-02-09",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.09185v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.09270v1",
      "title": "Collective Behavior of AI Agents: the Case of Moltbook",
      "authors": [
        "Giordano De Marzo",
        "David Garcia"
      ],
      "summary": "We present a large scale data analysis of Moltbook, a Reddit-style social media platform exclusively populated by AI agents. Analyzing over 369,000 posts and 3.0 million comments from approximately 46,000 active agents, we find that AI collective behavior exhibits many of the same statistical regularities observed in human online communities: heavy-tailed distributions of activity, power-law scaling of popularity metrics, and temporal decay patterns consistent with limited attention dynamics. Ho",
      "published": "2026-02-09",
      "categories": [
        "physics.soc-ph",
        "cs.CL",
        "cs.MA"
      ],
      "link": "https://arxiv.org/abs/2602.09270v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.09163v1",
      "title": "FlyAOC: Evaluating Agentic Ontology Curation of Drosophila Scientific Knowledge Bases",
      "authors": [
        "Xingjian Zhang",
        "Sophia Moylan",
        "Ziyang Xiong",
        "Qiaozhu Mei",
        "Yichen Luo"
      ],
      "summary": "Scientific knowledge bases accelerate discovery by curating findings from primary literature into structured, queryable formats for both human researchers and emerging AI systems. Maintaining these resources requires expert curators to search relevant papers, reconcile evidence across documents, and produce ontology-grounded annotations - a workflow that existing benchmarks, focused on isolated subtasks like named entity recognition or relation extraction, do not capture. We present FlyBench to ",
      "published": "2026-02-09",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "link": "https://arxiv.org/abs/2602.09163v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.08949v1",
      "title": "Digital Twin and Agentic AI for Wild Fire Disaster Management: Intelligent Virtual Situation Room",
      "authors": [
        "Mohammad Morsali",
        "Siavash H. Khajavi"
      ],
      "summary": "According to the United Nations, wildfire frequency and intensity are projected to increase by approximately 14% by 2030 and 30% by 2050 due to global warming, posing critical threats to life, infrastructure, and ecosystems. Conventional disaster management frameworks rely on static simulations and passive data acquisition, hindering their ability to adapt to arbitrarily evolving wildfire episodes in real-time. To address these limitations, we introduce the Intelligent Virtual Situation Room (IV",
      "published": "2026-02-09",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.08949v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.08554v1",
      "title": "Three Lessons from Citizen-Centric Participatory AI Design",
      "authors": [
        "Eike Schneiders",
        "Sarah Kiden",
        "Beining Zhang",
        "Bruno Rafael Queiros Arcanjo",
        "Zhaoxing Li"
      ],
      "summary": "This workshop paper examines challenges in designing agentic AI systems from a citizen-centric perspective. Drawing on three participatory workshops conducted in 2025 with members of the general public and cross-sector stakeholders, we explore how societal values and expectations shape visions of future AI agents. Using constructive design research methods, participants engaged in storytelling and lo-fi prototyping to reflect on potential community impacts. We identify three key challenges: enab",
      "published": "2026-02-09",
      "categories": [
        "cs.CY",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.08554v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.07754v1",
      "title": "Humanizing AI Grading: Student-Centered Insights on Fairness, Trust, Consistency and Transparency",
      "authors": [
        "Bahare Riahi",
        "Veronica Catete"
      ],
      "summary": "This study investigates students' perceptions of Artificial Intelligence (AI) grading systems in an undergraduate computer science course (n = 27), focusing on a block-based programming final project. Guided by the ethical principles framework articulated by Jobin (2019), our study examines fairness, trust, consistency, and transparency in AI grading by comparing AI-generated feedback with original human-graded feedback. Findings reveal concerns about AI's lack of contextual understanding and pe",
      "published": "2026-02-08",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.07754v1",
      "matched_keyword": "trustworthy AI",
      "source": "arxiv"
    },
    {
      "id": "2602.07491v1",
      "title": "GraphAgents: Knowledge Graph-Guided Agentic AI for Cross-Domain Materials Design",
      "authors": [
        "Isabella A. Stewart",
        "Tarjei Paule Hage",
        "Yu-Chuan Hsu",
        "Markus J. Buehler"
      ],
      "summary": "Large Language Models (LLMs) promise to accelerate discovery by reasoning across the expanding scientific landscape. Yet, the challenge is no longer access to information but connecting it in meaningful, domain-spanning ways. In materials science, where innovation demands integrating concepts from molecular chemistry to mechanical performance, this is especially acute. Neither humans nor single-agent LLMs can fully contend with this torrent of information, with the latter often prone to hallucin",
      "published": "2026-02-07",
      "categories": [
        "cs.AI",
        "cond-mat.mes-hall",
        "cond-mat.mtrl-sci",
        "cond-mat.soft",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.07491v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.07433v1",
      "title": "Multi-Agent Systems Shape Social Norms for Prosocial Behavior Change",
      "authors": [
        "Yibin Feng",
        "Tianqi Song",
        "Yugin Tan",
        "Zicheng Zhu",
        "Yi-Chieh Lee"
      ],
      "summary": "Social norm interventions are used promote prosocial behaviors by highlighting prevalent actions, but their effectiveness is often limited in heterogeneous populations where shared understandings of desirable behaviors are lacking. This study explores whether multi-agent systems can establish \"virtual social norms\" to encourage donation behavior. We conducted an online experiment where participants interacted with a group of agents to discuss donation behaviors. Changes in perceived social norms",
      "published": "2026-02-07",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "link": "https://arxiv.org/abs/2602.07433v1",
      "matched_keyword": "computer-supported cooperative work",
      "source": "arxiv"
    }
  ],
  "semantic_scholar": [
    {
      "id": "527519dd69b8ad85a09b642b62be3ea2a8b00b55",
      "title": "Deriving Instructional Insights from Human-LLM Co-Evaluation of Student Collaboration in Data-Centric Programming",
      "authors": [
        "Marshall An",
        "Christine Kwon",
        "Yoonjae Lee",
        "Ji-Hyeon Hur",
        "Dongho Lee"
      ],
      "summary": "",
      "published": "2026-02-18",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/527519dd69b8ad85a09b642b62be3ea2a8b00b55",
      "matched_keyword": "LLM qualitative analysis",
      "source": "semantic_scholar"
    },
    {
      "id": "e0d1a005ae6b2adecd6c78a160e5b2da1f97f054",
      "title": "Generative AI for interdisciplinary collaborative design: an agent-based workflow orchestration framework guided by R³ invariants",
      "authors": [
        "Ruohao Gao",
        "Lingwan Huang",
        "Zenghui Wang",
        "Shijian Cang"
      ],
      "summary": "",
      "published": "2026-02-12",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/e0d1a005ae6b2adecd6c78a160e5b2da1f97f054",
      "matched_keyword": "AI agent workflow",
      "source": "semantic_scholar"
    },
    {
      "id": "8fae2c3f7f1f69a60ba18e320af041317bb2609b",
      "title": "Zero-shot stance detection in practice: insights on training, prompting, and decoding with a capable lightweight LLM",
      "authors": [
        "Rachith Aiyappa",
        "Shruthi Senthilmani",
        "Jisun An",
        "Haewoon Kwak",
        "Yong-Yeol Ahn"
      ],
      "summary": "We investigate the performance of Large Language Model (LLM)-based zero-shot stance detection on tweets. Using FlanT5-XXL, an instruction-tuned open-source LLM, with the SemEval 2016 Tasks 6A, 6B, and P-Stance datasets, we analyze how its performance varies under different prompts and decoding strategies, as well as potential model biases. We show that the zero-shot approach can match or outperform state-of-the-art methods, including fine-tuned models. Additionally, we provide practical insights",
      "published": "2026-02-12",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/8fae2c3f7f1f69a60ba18e320af041317bb2609b",
      "matched_keyword": "LLM qualitative analysis",
      "source": "semantic_scholar"
    },
    {
      "id": "f8f14298320d24e5965d932a4513610b89940aae",
      "title": "An AI Agent for Automated Causal Inference in Epidemiology",
      "authors": [
        "H. Liu",
        "K. Shi",
        "A. li",
        "X. Li",
        "J. Chu"
      ],
      "summary": "",
      "published": "2026-02-06",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/f8f14298320d24e5965d932a4513610b89940aae",
      "matched_keyword": "AI agent workflow",
      "source": "semantic_scholar"
    },
    {
      "id": "79943a6125980b551b485446b7a307692fd8e3dc",
      "title": "Multi-agent AI",
      "authors": [
        "Simeon Allmendinger",
        "Lukas Bonenberger",
        "Kathrin Endres",
        "Dominik Fetzer",
        "H. Gimpel"
      ],
      "summary": "",
      "published": "2026-02-06",
      "citations": 2,
      "link": "https://www.semanticscholar.org/paper/79943a6125980b551b485446b7a307692fd8e3dc",
      "matched_keyword": "AI agent workflow",
      "source": "semantic_scholar"
    },
    {
      "id": "b901ef580574dc6b16cc2a61f56802e781b7aeff",
      "title": "Testing LLM Diagnostics in Endodontics: The Impact of Linguistic Variation on Unseen Cases.",
      "authors": [
        "Itrat Batool",
        "N. Naved",
        "F. Umer"
      ],
      "summary": "AIM\nTo assess the diagnostic performance of two language models, GPT-5 Plus and Gemini 2.5 Flash using a curated benchmark dataset of unseen endodontic and restorative dentistry related clinical case scenarios and the linguistic variations introduced around the original dataset. Additionally, a descriptive qualitative analysis was performed on a subset of cases to evaluate the quality of reasoning generated by both models.\n\n\nMETHODOLOGY\nOne hundred single best answer MCQs were generated using st",
      "published": "2026-02-05",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/b901ef580574dc6b16cc2a61f56802e781b7aeff",
      "matched_keyword": "LLM qualitative analysis",
      "source": "semantic_scholar"
    },
    {
      "id": "d5d656f4328e4eb0c170421b4d8b186a4e0549ef",
      "title": "Designing AI Agent Workflows for Consumer Behavior Applications: A Practitioner's Framework",
      "authors": [
        "Pratik Khedekar",
        "Abhishek Vangipuram",
        "Sravan Reddy Kathi"
      ],
      "summary": "The rapid advancement of large language model capabilities has created unprecedented opportunities for AI agent systems in consumer behavior applications, yet translating generic agent capabilities into production-ready business solutions remains challenging. While existing research provides automated workflow generation methods and generic architectural patterns, no systematic methodology exists for designing agent workflows that address the unique requirements of consumer behavior domains incl",
      "published": "2026-02-01",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/d5d656f4328e4eb0c170421b4d8b186a4e0549ef",
      "matched_keyword": "AI agent workflow",
      "source": "semantic_scholar"
    },
    {
      "id": "b7a0a1d5d16fc1994c2242878653906ba015455b",
      "title": "LeagueBot: A Voice LLM Companion of Cognitive and Emotional Support for Novice Players in Competitive Games",
      "authors": [
        "Jungmin Lee",
        "Inhee Cho",
        "Youngjae Yoo"
      ],
      "summary": "Competitive games pose steep learning curves and strong social pressures, often discouraging novice players and limiting sustained engagement. To address these challenges, this study introduces LeagueBot, a large language model-based voice chatbot designed to provide both informational and emotional support during live gameplay in league of legends, one of the most competitive multiplayer online battle arena games. In a within-subjects experiment with 33 novice players, LeagueBot was found to re",
      "published": "2026-02-01",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/b7a0a1d5d16fc1994c2242878653906ba015455b",
      "matched_keyword": "LLM qualitative analysis",
      "source": "semantic_scholar"
    },
    {
      "id": "5eb71f6e5f5bf8b1f7299601df0eb309576edc96",
      "title": "How topic content shapes LLM personality-tailored persuasion: semantic anchoring and topic stereotype effects",
      "authors": [
        "Shuang Xu",
        "Zili Zhou",
        "Nan Zhao"
      ],
      "summary": "Large language models (LLMs) have shown promise in generating personality-tailored persuasive messages, yet their effectiveness remains inconsistent across contexts. This research systematically investigated how the characteristics of recommended products or actions shapes the efficacy of LLM- generated personality-tailored persuasion through three experimental studies (N = 618). Study 1 revealed that personality-matching effects were limited and inconsistent when the core features of the recomm",
      "published": "2026-01-30",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/5eb71f6e5f5bf8b1f7299601df0eb309576edc96",
      "matched_keyword": "LLM qualitative analysis",
      "source": "semantic_scholar"
    },
    {
      "id": "663b9b66552b16d2874dbb93e815a8c4e3d1cc2d",
      "title": "AI Agent with Browser Automation",
      "authors": [
        "Abdul Mateen",
        "Priyanka K R",
        "Chethana BM",
        "Leela C",
        "Sujith Kumar S"
      ],
      "summary": "This project presents the design and implementation of an intelligent AI agent capable of performing automated actions within a web browser environment. The proposed system integrates natural-language understanding, task decomposition, and browser-level automation to execute user- defined goals such as data extraction, form submission, website navigation, report generation, and repetitive workflow operations. The agent combines machine learning models with rule-based logic to accurately interpre",
      "published": "2026-01-27",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/663b9b66552b16d2874dbb93e815a8c4e3d1cc2d",
      "matched_keyword": "AI agent workflow",
      "source": "semantic_scholar"
    },
    {
      "id": "2e207f78284460ce59438de4512e2ba3b8127547",
      "title": "HYBRID SENSING AND CLOUD DEPLOYED AGENT MESH FOR AI‑DRIVEN TRAFFIC OPTIMIZATION IN CONGESTED CITIES",
      "authors": [
        "Florin Andreescu",
        "Dorin Simionescu"
      ],
      "summary": "Urban traffic congestion in crowded cities is increasingly shaped by short term demand fluctuations, spillback formation, and heterogeneous vehicle dynamics, which challenge fixed time signal plans and reactive controllers. This paper proposes an AI enabled intersection agent that combines (i) a deep learning (DL) predictor for short horizon traffic forecasting (15–60 minutes) and (ii) an intersection level machine learning (ML) controller that applies bounded adaptations of green times based on",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/2e207f78284460ce59438de4512e2ba3b8127547",
      "matched_keyword": "AI agent workflow",
      "source": "semantic_scholar"
    },
    {
      "id": "7321344ff13d71d7f1c6035636751206d0590782",
      "title": "LLM QLoRA Fine-Tuning of Llama, DeepSeek, and Qwen: A Skyrim Case Study",
      "authors": [
        "M. E. Monteiro",
        "Marcos Talau",
        "Heitor Silvério Lopes"
      ],
      "summary": "Fine-tuning Large Language Models (LLMs) for domains that demand extensive background knowledge, such as video game lore, involves navigating trade-offs between model architecture, scale, and the organization of training data. In this study, we examine these factors through the use of Quantized Low-Rank Adaptation (QLoRA) applied to the lore of Skyrim®. Our analysis considers nine models from the DeepSeek, Llama, and Qwen families at three parameter scales (~8B, ~13B, and ~33B). Each model was f",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/7321344ff13d71d7f1c6035636751206d0590782",
      "matched_keyword": "LLM qualitative analysis",
      "source": "semantic_scholar"
    },
    {
      "id": "1259e54ca5d2257d44a95569108df1b7ceedbb95",
      "title": "Preclinical basic research of Majuchuanke oral liquid",
      "authors": [
        "Cheng-Jun Yuan"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/1259e54ca5d2257d44a95569108df1b7ceedbb95",
      "matched_keyword": "author:Amershi, Saleema",
      "source": "semantic_scholar"
    },
    {
      "id": "9d0053ad515444e29ff6203da5654982e015ae18",
      "title": "The changes of cardiopulmonary function and the correlation with the ratios of regulatory T cells in OA rats",
      "authors": [
        "Cheng-Jun Yuan"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/9d0053ad515444e29ff6203da5654982e015ae18",
      "matched_keyword": "author:Amershi, Saleema",
      "source": "semantic_scholar"
    },
    {
      "id": "5f95c4bf2c5248098331302ef8b30e5ca08d8c5d",
      "title": "Additive Kunststoffverarbeitung @ MedTech",
      "authors": [
        "M. Eblenkamp",
        "F. Bauer"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/5f95c4bf2c5248098331302ef8b30e5ca08d8c5d",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "8aae4b770177f64faab5b24487b39bf817b50806",
      "title": "Biokompatible Integration von IoT-Elektronik in Kunststoffbauteile",
      "authors": [
        "V. Werner",
        "M. Eblenkamp"
      ],
      "summary": "",
      "published": "2026",
      "citations": 1,
      "link": "https://www.semanticscholar.org/paper/8aae4b770177f64faab5b24487b39bf817b50806",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "d9e7725ae591d649ef42e2fad07ee503429ab5f3",
      "title": "Additive Fertigung in der Lehre und Ausbildung",
      "authors": [
        "Stefan Leonhardt",
        "M. Eblenkamp"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/d9e7725ae591d649ef42e2fad07ee503429ab5f3",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "596f0df250ccf835c7da32692fa991835ef81416",
      "title": "IoT & Werkstoffe: HF-Eigenschaften medizinischer Kunststoffe",
      "authors": [
        "V. Werner",
        "M. Zeppenfeld",
        "M. Eblenkamp"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/596f0df250ccf835c7da32692fa991835ef81416",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "87a61c6d1df62777f8fa7c1835b05c7d1dbaebdd",
      "title": "Schichtweise zu lebensnaher Biomimikry: Hochfunktionsintegrierte Kunststoffsysteme für die zellbasierte Labormedizin",
      "authors": [
        "M. Eblenkamp",
        "Katharina Düregger",
        "Stefan Leonhardt"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/87a61c6d1df62777f8fa7c1835b05c7d1dbaebdd",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    }
  ],
  "hackernews": [
    {
      "id": "46990729",
      "title": "An AI agent published a hit piece on me",
      "link": "https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/",
      "hn_link": "https://news.ycombinator.com/item?id=46990729",
      "points": 2320,
      "comments": 945,
      "published": "2026-02-12",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "46987559",
      "title": "AI agent opens a PR write a blogpost to shames the maintainer who closes it",
      "link": "https://github.com/matplotlib/matplotlib/pull/31132",
      "hn_link": "https://news.ycombinator.com/item?id=46987559",
      "points": 944,
      "comments": 746,
      "published": "2026-02-12",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47009949",
      "title": "An AI agent published a hit piece on me – more things have happened",
      "link": "https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me-part-2/",
      "hn_link": "https://news.ycombinator.com/item?id=47009949",
      "points": 725,
      "comments": 600,
      "published": "2026-02-14",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "46961345",
      "title": "Ex-GitHub CEO launches a new developer platform for AI agents",
      "link": "https://entire.io/blog/hello-entire-world/",
      "hn_link": "https://news.ycombinator.com/item?id=46961345",
      "points": 610,
      "comments": 575,
      "published": "2026-02-10",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "46954920",
      "title": "Frontier AI agents violate ethical constraints 30–50% of time, pressured by KPIs",
      "link": "https://arxiv.org/abs/2512.20798",
      "hn_link": "https://news.ycombinator.com/item?id=46954920",
      "points": 544,
      "comments": 366,
      "published": "2026-02-10",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "46974853",
      "title": "GLM-5: Targeting complex systems engineering and long-horizon agentic tasks",
      "link": "https://z.ai/blog/glm-5",
      "hn_link": "https://news.ycombinator.com/item?id=46974853",
      "points": 480,
      "comments": 519,
      "published": "2026-02-11",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "46977210",
      "title": "GLM-5: From Vibe Coding to Agentic Engineering",
      "link": "https://z.ai/blog/glm-5",
      "hn_link": "https://news.ycombinator.com/item?id=46977210",
      "points": 378,
      "comments": 8,
      "published": "2026-02-11",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47006843",
      "title": "The \"AI agent hit piece\" situation clarifies how dumb we are acting",
      "link": "https://ardentperf.com/2026/02/13/the-scott-shambaugh-situation-clarifies-how-dumb-we-are-acting/",
      "hn_link": "https://news.ycombinator.com/item?id=47006843",
      "points": 241,
      "comments": 125,
      "published": "2026-02-13",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "46946593",
      "title": "Show HN: AI agents play SimCity through a REST API",
      "link": "https://hallucinatingsplines.com",
      "hn_link": "https://news.ycombinator.com/item?id=46946593",
      "points": 216,
      "comments": 72,
      "published": "2026-02-09",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "46993587",
      "title": "Show HN: Moltis – AI assistant with memory, tools, and self-extending skills",
      "link": "https://www.moltis.org",
      "hn_link": "https://news.ycombinator.com/item?id=46993587",
      "points": 122,
      "comments": 48,
      "published": "2026-02-12",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "46974515",
      "title": "Show HN: CodeRLM – Tree-sitter-backed code indexing for LLM agents",
      "link": "https://github.com/JaredStewart/coderlm/blob/main/server/REPL_to_API.md",
      "hn_link": "https://news.ycombinator.com/item?id=46974515",
      "points": 79,
      "comments": 37,
      "published": "2026-02-11",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47004203",
      "title": "I ditched OpenClaw and built a more secure AI agent (Blink and Mac Mini)",
      "link": "https://coder.com/blog/why-i-ditched-openclaw-and-built-a-more-secure-ai-agent-on-blink-mac-mini",
      "hn_link": "https://news.ycombinator.com/item?id=47004203",
      "points": 52,
      "comments": 58,
      "published": "2026-02-13",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "46997526",
      "title": "Cloudflare adds real-time Markdown rendering for AI agents",
      "link": "https://blog.cloudflare.com/markdown-for-agents/",
      "hn_link": "https://news.ycombinator.com/item?id=46997526",
      "points": 45,
      "comments": 22,
      "published": "2026-02-13",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47002633",
      "title": "Safe YOLO Mode: Running LLM agents in vms with Libvirt and Virsh",
      "link": "https://www.metachris.dev/2026/02/safe-yolo-mode-running-llm-agents-in-vms-with-libvirt-and-virsh/",
      "hn_link": "https://news.ycombinator.com/item?id=47002633",
      "points": 30,
      "comments": 9,
      "published": "2026-02-13",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "46954685",
      "title": "EU finds the AI assistant in WhatsApp violating anti trust",
      "link": "https://ec.europa.eu/commission/presscorner/detail/en/ip_26_310",
      "hn_link": "https://news.ycombinator.com/item?id=46954685",
      "points": 30,
      "comments": 5,
      "published": "2026-02-10",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "46948820",
      "title": "The Most Popular Agentic Open-Source Tools (2026 Edition)",
      "link": "https://you.com/resources/popular-agentic-open-source-tools-2026",
      "hn_link": "https://news.ycombinator.com/item?id=46948820",
      "points": 30,
      "comments": 12,
      "published": "2026-02-09",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "46943506",
      "title": "Stack Overflow for AI Coding Agents",
      "link": "https://shareful.ai",
      "hn_link": "https://news.ycombinator.com/item?id=46943506",
      "points": 20,
      "comments": 12,
      "published": "2026-02-09",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "46977327",
      "title": "Show HN: Deadend CLI – Open-source self-hosted agentic pentest tooling",
      "link": "https://github.com/xoxruns/deadend-cli",
      "hn_link": "https://news.ycombinator.com/item?id=46977327",
      "points": 18,
      "comments": 7,
      "published": "2026-02-11",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "46984452",
      "title": "Ask HN: Has anyone achieved recursive self-improvement with agentic tools?",
      "link": "https://news.ycombinator.com/item?id=46984452",
      "hn_link": "https://news.ycombinator.com/item?id=46984452",
      "points": 9,
      "comments": 14,
      "published": "2026-02-12",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "46979278",
      "title": "Show HN: Open Benchmarks Grants– a $3M commitment to close the AI eval gap",
      "link": "https://benchmarks.snorkel.ai/closing-the-evaluation-gap-in-agentic-ai/",
      "hn_link": "https://news.ycombinator.com/item?id=46979278",
      "points": 6,
      "comments": 0,
      "published": "2026-02-11",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "46991720",
      "title": "BashoBot – A Personal AI Assistant Built with Bash",
      "link": "https://github.com/uraimo/bashobot",
      "hn_link": "https://news.ycombinator.com/item?id=46991720",
      "points": 6,
      "comments": 0,
      "published": "2026-02-12",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47011067",
      "title": "AgentRE-Bench: Can LLM Agents Reverse Engineer Malware?",
      "link": "https://www.agentre-bench.ai/",
      "hn_link": "https://news.ycombinator.com/item?id=47011067",
      "points": 5,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47024005",
      "title": "AI is slowly munching away my passion",
      "link": "https://whynot.fail/human/ai-is-slowly-munching-away-my-passion/",
      "hn_link": "https://news.ycombinator.com/item?id=47024005",
      "points": 5,
      "comments": 0,
      "published": "2026-02-15",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "47023667",
      "title": "Show HN: GAIA – open-source, Proactive AI assistant to manage your digital life",
      "link": "https://github.com/theexperiencecompany/gaia",
      "hn_link": "https://news.ycombinator.com/item?id=47023667",
      "points": 5,
      "comments": 4,
      "published": "2026-02-15",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "46966941",
      "title": "Show HN: Cube – The Agentic Analytics Platform [video]",
      "link": "https://www.youtube.com/watch?v=f9RMT6WMAlc",
      "hn_link": "https://news.ycombinator.com/item?id=46966941",
      "points": 5,
      "comments": 1,
      "published": "2026-02-10",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "46959177",
      "title": "Stripe Minions – End to end agentic coding",
      "link": "https://stripe.dev/blog/minions-stripes-one-shot-end-to-end-coding-agents",
      "hn_link": "https://news.ycombinator.com/item?id=46959177",
      "points": 5,
      "comments": 0,
      "published": "2026-02-10",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "46959793",
      "title": "PicoClaw ultra-lightweight personal AI Assistant run on just 10MB of RAM",
      "link": "https://www.cnx-software.com/2026/02/10/picoclaw-ultra-lightweight-personal-ai-assistant-run-on-just-10mb-of-ram/",
      "hn_link": "https://news.ycombinator.com/item?id=46959793",
      "points": 4,
      "comments": 0,
      "published": "2026-02-10",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "46951774",
      "title": "Agentic Coding Is Draining Your Moat",
      "link": "https://www.slwip.com/agentic-coding-is-draining-your-moat/",
      "hn_link": "https://news.ycombinator.com/item?id=46951774",
      "points": 4,
      "comments": 4,
      "published": "2026-02-09",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "46970307",
      "title": "Show HN: Microagentic Stacking – Manifesto for Reliable Agentic AI Architecture",
      "link": "https://github.com/ericmora/microagentic-stacking",
      "hn_link": "https://news.ycombinator.com/item?id=46970307",
      "points": 4,
      "comments": 0,
      "published": "2026-02-11",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "46954615",
      "title": "Agentic Tool Patterns – 54 patterns for building tools LLM agents can use",
      "link": "https://blog.arcade.dev/mcp-tool-patterns",
      "hn_link": "https://news.ycombinator.com/item?id=46954615",
      "points": 3,
      "comments": 1,
      "published": "2026-02-10",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "46985767",
      "title": "Show HN: PaperLab – Markdown editor that deliberately does less",
      "link": "https://news.ycombinator.com/item?id=46985767",
      "hn_link": "https://news.ycombinator.com/item?id=46985767",
      "points": 3,
      "comments": 3,
      "published": "2026-02-12",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "46946621",
      "title": "Show HN: BB – A persistent message broker for AI agents (MCP, Ed25519, Matrix)",
      "link": "https://bb.org.ai/",
      "hn_link": "https://news.ycombinator.com/item?id=46946621",
      "points": 3,
      "comments": 0,
      "published": "2026-02-09",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "46959759",
      "title": "Cecli AI Coding Assistant",
      "link": "https://cecli.dev",
      "hn_link": "https://news.ycombinator.com/item?id=46959759",
      "points": 3,
      "comments": 1,
      "published": "2026-02-10",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "46959187",
      "title": "Show HN: GitScrum MCP Server for Claude and AI Assistants",
      "link": "https://github.com/gitscrum-core/mcp-server",
      "hn_link": "https://news.ycombinator.com/item?id=46959187",
      "points": 3,
      "comments": 0,
      "published": "2026-02-10",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "46958991",
      "title": "Show HN: Selling an AI interview assistant with ~2k users (no revenue)",
      "link": "https://github.com/evinjohnn/natively-cluely-ai-assistant",
      "hn_link": "https://news.ycombinator.com/item?id=46958991",
      "points": 3,
      "comments": 0,
      "published": "2026-02-10",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "46960638",
      "title": "The Agentic Waterfall: How the AI Industry Is Regressing Software Development",
      "link": "https://github.com/Jk1484/agentic-waterfall",
      "hn_link": "https://news.ycombinator.com/item?id=46960638",
      "points": 3,
      "comments": 5,
      "published": "2026-02-10",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "46961872",
      "title": "NeuroForge – Observe emergent behavior in autonomous multi-agent LLM networks",
      "link": "https://agents.glide2.app",
      "hn_link": "https://news.ycombinator.com/item?id=46961872",
      "points": 2,
      "comments": 1,
      "published": "2026-02-10",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47019084",
      "title": "Agent-evals: Metacognitive scoring and boundary testing for LLM coding agents",
      "link": "https://thinkwright.ai/agent-evals",
      "hn_link": "https://news.ycombinator.com/item?id=47019084",
      "points": 2,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47013274",
      "title": "Show HN: AI Station Navigator – LLM=CPU, Agents=Processes, Skills=Apps",
      "link": "https://github.com/canishowtime/ai-station-navigator",
      "hn_link": "https://news.ycombinator.com/item?id=47013274",
      "points": 2,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47000034",
      "title": "Expensively Quadratic: The LLM Agent Cost Curve",
      "link": "https://blog.exe.dev/expensively-quadratic",
      "hn_link": "https://news.ycombinator.com/item?id=47000034",
      "points": 2,
      "comments": 0,
      "published": "2026-02-13",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "46958841",
      "title": "Lightweight Memory Construction with Dynamic Evolution for LLM Agents",
      "link": "https://arxiv.org/abs/2601.14287",
      "hn_link": "https://news.ycombinator.com/item?id=46958841",
      "points": 2,
      "comments": 0,
      "published": "2026-02-10",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47013797",
      "title": "Close enough to explain: on collaboration, AI, and staying close to the code",
      "link": "http://stdout.alesr.me/posts/close-enough-to-explain/",
      "hn_link": "https://news.ycombinator.com/item?id=47013797",
      "points": 2,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "46965082",
      "title": "Is human collaboration the answer to the skill formation risks by AI?",
      "link": "https://www.gethopp.app/blog/pair-prompting",
      "hn_link": "https://news.ycombinator.com/item?id=46965082",
      "points": 2,
      "comments": 1,
      "published": "2026-02-10",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "46958590",
      "title": "Show HN: OpenClaw Draws – Pair your AI bot with others to create pixel art, LIVE",
      "link": "https://openclawdraws.com",
      "hn_link": "https://news.ycombinator.com/item?id=46958590",
      "points": 2,
      "comments": 0,
      "published": "2026-02-10",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "46948164",
      "title": "Show HN: TapnClaw – Deploy your own OpenClaw AI assistant in 5 min, zero config",
      "link": "https://tapnclaw.com",
      "hn_link": "https://news.ycombinator.com/item?id=46948164",
      "points": 2,
      "comments": 1,
      "published": "2026-02-09",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47017740",
      "title": "PicoClaw: Ultra-Efficient AI Assistant in Go",
      "link": "https://github.com/sipeed/picoclaw",
      "hn_link": "https://news.ycombinator.com/item?id=47017740",
      "points": 2,
      "comments": 0,
      "published": "2026-02-14",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "46987545",
      "title": "I built a community where LLM agents discuss marketing ideas for my app",
      "link": "https://news.ycombinator.com/item?id=46987545",
      "hn_link": "https://news.ycombinator.com/item?id=46987545",
      "points": 1,
      "comments": 2,
      "published": "2026-02-12",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "46997728",
      "title": "Authoring, simulating, and testing dynamic human-AI group conversations",
      "link": "https://research.google/blog/beyond-one-on-one-authoring-simulating-and-testing-dynamic-human-ai-group-conversations/",
      "hn_link": "https://news.ycombinator.com/item?id=46997728",
      "points": 1,
      "comments": 0,
      "published": "2026-02-13",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "46953463",
      "title": "Show HN: Insurance AI Benchmark – 510 scenarios from production",
      "link": "https://huggingface.co/datasets/pashas/insurance-ai-reliability-benchmark",
      "hn_link": "https://news.ycombinator.com/item?id=46953463",
      "points": 1,
      "comments": 0,
      "published": "2026-02-10",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "46953458",
      "title": "Show HN: Hybrid Orchestrator – Reliable AI agents for finance",
      "link": "https://github.com/pavelsukhachev/hybrid-orchestrator",
      "hn_link": "https://news.ycombinator.com/item?id=46953458",
      "points": 1,
      "comments": 0,
      "published": "2026-02-10",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "46972819",
      "title": "Cursor-agent-team: Single-conversation, multi-role AI collaboration framework",
      "link": "https://github.com/thiswind/cursor-agent-team",
      "hn_link": "https://news.ycombinator.com/item?id=46972819",
      "points": 1,
      "comments": 1,
      "published": "2026-02-11",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "46984895",
      "title": "Show HN: MoltHub – GitHub for AI Agents with Trust-Based Auto-Merge",
      "link": "https://molt-hub.org",
      "hn_link": "https://news.ycombinator.com/item?id=46984895",
      "points": 1,
      "comments": 0,
      "published": "2026-02-12",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "46941757",
      "title": "Show HN: Dwrite.me A minimalist writing space that blocks copypaste to fight AI",
      "link": "https://dwrite.me",
      "hn_link": "https://news.ycombinator.com/item?id=46941757",
      "points": 1,
      "comments": 2,
      "published": "2026-02-09",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    }
  ],
  "reddit": [],
  "blogs": [
    {
      "名称": "Anthropic Research",
      "链接": "https://anthropic.com/research",
      "说明": "Claude生态，MCP协议，human-AI交互理念"
    },
    {
      "名称": "OpenAI Research",
      "链接": "https://openai.com/research",
      "说明": "GPT系列、agent框架、ChatGPT产品迭代"
    },
    {
      "名称": "Google DeepMind",
      "链接": "https://deepmind.google/research",
      "说明": "Gemini、agent研究、AI safety"
    },
    {
      "名称": "Microsoft Research Blog",
      "链接": "https://microsoft.com/en-us/research/blog",
      "说明": "HAX Toolkit, Human-AI Interaction Guidelines, Copilot"
    },
    {
      "名称": "Meta AI (FAIR)",
      "链接": "https://ai.meta.com/research",
      "说明": "Llama开源生态"
    },
    {
      "名称": "Amazon Science",
      "链接": "https://amazon.science",
      "说明": "应用型AI研究"
    },
    {
      "名称": "Apple Machine Learning",
      "链接": "https://machinelearning.apple.com",
      "说明": "设备端AI、隐私AI"
    },
    {
      "名称": "Hugging Face Blog",
      "链接": "https://huggingface.co/blog",
      "说明": "开源模型、工具、社区趋势"
    },
    {
      "名称": "LangChain Blog",
      "链接": "https://blog.langchain.dev",
      "说明": "Agent框架生态风向标"
    }
  ],
  "newsletters": [
    {
      "名称": "Simon Willison's Blog",
      "链接": "https://simonwillison.net",
      "作者": "Simon Willison",
      "说明": "LLM生态最全面的实践者视角"
    },
    {
      "名称": "Ahead of AI",
      "链接": "https://magazine.sebastianraschka.com",
      "作者": "Sebastian Raschka",
      "说明": "LLM研究深度解读"
    },
    {
      "名称": "Interconnects",
      "链接": "https://interconnects.ai",
      "作者": "Nathan Lambert",
      "说明": "RLHF/对齐方向"
    },
    {
      "名称": "Latent Space",
      "链接": "https://latent.space",
      "作者": "Swyx & Alessio",
      "说明": "AI工程师视角，agent和tooling"
    },
    {
      "名称": "MIT Technology Review",
      "链接": "https://technologyreview.com",
      "作者": "编辑团队",
      "说明": "日刊科技新闻"
    },
    {
      "名称": "The Batch",
      "链接": "https://deeplearning.ai/the-batch",
      "作者": "Andrew Ng",
      "说明": "AI新闻周报"
    },
    {
      "名称": "Import AI",
      "链接": "https://importai.substack.com",
      "作者": "Jack Clark",
      "说明": "偏policy和大趋势"
    },
    {
      "名称": "阮一峰的网络日志",
      "链接": "https://ruanyifeng.com/blog",
      "作者": "阮一峰",
      "说明": "中文技术圈信号"
    }
  ],
  "researchers": [
    {
      "姓名": "Anthropic",
      "链接": "https://x.com/AnthropicAI",
      "平台": "X",
      "说明": "AI safety and research company"
    },
    {
      "姓名": "Claude",
      "链接": "https://x.com/claudeai",
      "平台": "X",
      "说明": "safe, accurate, and secure"
    },
    {
      "姓名": "OpenAI",
      "链接": "https://x.com/OpenAI",
      "平台": "X",
      "说明": "artificial general intelligence benefits all of humanity"
    },
    {
      "姓名": "Sherry Tongshuang Wu",
      "链接": "https://x.com/tongshuangwu",
      "平台": "X",
      "说明": "HCI×NLP，human-AI interaction"
    },
    {
      "姓名": "Diyi Yang",
      "链接": "https://x.com/Diyi_Yang",
      "平台": "X",
      "说明": "Human-AI"
    },
    {
      "姓名": "Ziang Xiao",
      "链接": "https://x.com/ZiangXiao",
      "平台": "X",
      "说明": "AI4SocialScience, Model Evaluation, Information Seeking"
    },
    {
      "姓名": "Mark Dredze",
      "链接": "https://x.com/mdredze",
      "平台": "X",
      "说明": "NLP"
    },
    {
      "姓名": "Wesley Hanwen Deng",
      "链接": "https://x.com/wes_deng",
      "平台": "X",
      "说明": "Human-AI"
    },
    {
      "姓名": "Mina Lee",
      "链接": "https://x.com/MinaLee__",
      "平台": "X",
      "说明": "Human-AI collaborative writing"
    },
    {
      "姓名": "Jentse Huang",
      "链接": "https://x.com/JentseHuang",
      "平台": "X",
      "说明": "LLM + Social Science, Multi-Agent, AI Fairness"
    },
    {
      "姓名": "Toby Jia-Jun Li",
      "链接": "https://x.com/TobyJLi",
      "平台": "X",
      "说明": "End-user programming, human-AI systems"
    },
    {
      "姓名": "Dakuo Wang",
      "链接": "https://x.com/dakuowang",
      "平台": "X",
      "说明": "Human-AI collaboration, CSCW"
    },
    {
      "姓名": "Percy Liang",
      "链接": "https://x.com/percyliang",
      "平台": "X",
      "说明": "LLM evaluation框架"
    },
    {
      "姓名": "Michael Bernstein",
      "链接": "https://x.com/msbernst",
      "平台": "X",
      "说明": "Generative agents, social computing"
    },
    {
      "姓名": "Simon Willison",
      "链接": "https://x.com/simonw",
      "平台": "X",
      "说明": "LLM工具生态最佳信息源"
    },
    {
      "姓名": "Joon Sung Park",
      "链接": "https://x.com/joon_s_pk",
      "平台": "X",
      "说明": "Social Simulations"
    },
    {
      "姓名": "Andrej Karpathy",
      "链接": "https://x.com/karpathy",
      "平台": "X",
      "说明": "深度技术解读"
    },
    {
      "姓名": "Swyx",
      "链接": "https://x.com/swyx",
      "平台": "X",
      "说明": "AI工程/agent生态trend"
    },
    {
      "姓名": "Saleema Amershi",
      "链接": "https://x.com/SaleemaAmershi",
      "平台": "X",
      "说明": "Human-AI Interaction Guidelines"
    },
    {
      "姓名": "Q. Vera Liao",
      "链接": "https://x.com/QVeraLiao",
      "平台": "X",
      "说明": "Explainable AI, responsible AI in HCI"
    },
    {
      "姓名": "Xiang 'Anthony' Chen",
      "链接": "https://x.com/_xiang_chen_",
      "平台": "X",
      "说明": "Interactive AI systems"
    }
  ],
  "podcasts": [
    {
      "名称": "Latent Space Podcast",
      "链接": "https://latent.space",
      "说明": "AI工程最前沿，agent相关讨论"
    },
    {
      "名称": "TWIML AI Podcast",
      "链接": "https://twimlai.com",
      "说明": "学术+工业混合视角"
    },
    {
      "名称": "NeurIPS/CHI 录播",
      "链接": "https://youtube.com",
      "说明": "重要talk的录播"
    }
  ],
  "conferences": [
    {
      "名称": "CHI GenAICHI Workshop",
      "链接": "https://genai-chi.github.io",
      "频率": "年度",
      "说明": "Generative AI × HCI"
    },
    {
      "名称": "HHAI Conference",
      "链接": "https://hhai-conference.org",
      "频率": "年度",
      "说明": "Hybrid Human-AI Intelligence"
    },
    {
      "名称": "CHI TREW Workshop",
      "链接": "https://trew-workshop.github.io",
      "频率": "年度",
      "说明": "Trust & Reliance in Human-AI Workflows"
    },
    {
      "名称": "ACL/EMNLP HCI+NLP Workshop",
      "链接": "https://aclanthology.org",
      "频率": "年度",
      "说明": "HCI×NLP交叉"
    },
    {
      "名称": "IUI Conference",
      "链接": "https://iui.acm.org",
      "频率": "年度",
      "说明": "Intelligent User Interfaces"
    },
    {
      "名称": "NeurIPS/ICML Agent Workshops",
      "链接": "https://neurips.cc",
      "频率": "年度",
      "说明": "系统/ML视角的agent研究"
    }
  ]
}