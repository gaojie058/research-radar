{
  "meta": {
    "fetched_at": "2026-02-26T08:21:33.440145",
    "lookback_days": 7,
    "keywords": [
      "human-AI collaboration",
      "LLM agent",
      "AI agent",
      "agentic AI",
      "human-centered AI",
      "qualitative analysis LLM",
      "human-LLM interaction",
      "responsible AI",
      "trustworthy AI",
      "AI-assisted analysis",
      "collaborative AI systems",
      "computer-supported cooperative work"
    ]
  },
  "arxiv": [
    {
      "id": "2602.21657v1",
      "title": "Following the Diagnostic Trace: Visual Cognition-guided Cooperative Network for Chest X-Ray Diagnosis",
      "authors": [
        "Shaoxuan Wu",
        "Jingkun Chen",
        "Chong Ma",
        "Cong Shen",
        "Xiao Zhang"
      ],
      "summary": "Computer-aided diagnosis (CAD) has significantly advanced automated chest X-ray diagnosis but remains isolated from clinical workflows and lacks reliable decision support and interpretability. Human-AI collaboration seeks to enhance the reliability of diagnostic models by integrating the behaviors of controllable radiologists. However, the absence of interactive tools seamlessly embedded within diagnostic routines impedes collaboration, while the semantic gap between radiologists' decision-makin",
      "published": "2026-02-25",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.21657v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.21806v1",
      "title": "An Empirical Study of Bugs in Modern LLM Agent Frameworks",
      "authors": [
        "Xinxue Zhu",
        "Jiacong Wu",
        "Xiaoyu Zhang",
        "Tianlin Li",
        "Yanzhou Mu"
      ],
      "summary": "LLM agents have been widely adopted in real-world applications, relying on agent frameworks for workflow execution and multi-agent coordination. As these systems scale, understanding bugs in the underlying agent frameworks becomes critical. However, existing work mainly focuses on agent-level failures, overlooking framework-level bugs. To address this gap, we conduct an empirical study of 998 bug reports from CrewAI and LangChain, constructing a taxonomy of 15 root causes and 7 observable sympto",
      "published": "2026-02-25",
      "categories": [
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.21806v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.21715v1",
      "title": "Two-Stage Active Distribution Network Voltage Control via LLM-RL Collaboration: A Hybrid Knowledge-Data-Driven Approach",
      "authors": [
        "Xu Yang",
        "Chenhui Lin",
        "Xiang Ma",
        "Dong Liu",
        "Ran Zheng"
      ],
      "summary": "The growing integration of distributed photovoltaics (PVs) into active distribution networks (ADNs) has exacerbated operational challenges, making it imperative to coordinate diverse equipment to mitigate voltage violations and enhance power quality. Although existing data-driven approaches have demonstrated effectiveness in the voltage control problem, they often require extensive trial-and-error exploration and struggle to incorporate heterogeneous information, such as day-ahead forecasts and ",
      "published": "2026-02-25",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.21715v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.21480v1",
      "title": "Both Ends Count! Just How Good are LLM Agents at \"Text-to-Big SQL\"?",
      "authors": [
        "Germán T. Eizaguirre",
        "Lars Tissen",
        "Marc Sánchez-Artigas"
      ],
      "summary": "Text-to-SQL and Big Data are both extensively benchmarked fields, yet there is limited research that evaluates them jointly. In the real world, Text-to-SQL systems are often embedded with Big Data workflows, such as large-scale data processing or interactive data analytics. We refer to this as \"Text-to-Big SQL\". However, existing text-to-SQL benchmarks remain narrowly scoped and overlook the cost and performance implications that arise at scale. For instance, translation errors that are minor on",
      "published": "2026-02-25",
      "categories": [
        "cs.DB",
        "cs.CL",
        "cs.IR"
      ],
      "link": "https://arxiv.org/abs/2602.21480v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.21841v1",
      "title": "Resilient Federated Chain: Transforming Blockchain Consensus into an Active Defense Layer for Federated Learning",
      "authors": [
        "Mario García-Márquez",
        "Nuria Rodríguez-Barroso",
        "M. Victoria Luzón",
        "Francisco Herrera"
      ],
      "summary": "Federated Learning (FL) has emerged as a key paradigm for building Trustworthy AI systems by enabling privacy-preserving, decentralized model training. However, FL is highly susceptible to adversarial attacks that compromise model integrity and data confidentiality, a vulnerability exacerbated by the fact that conventional data inspection methods are incompatible with its decentralized design. While integrating FL with Blockchain technology has been proposed to address some limitations, its pote",
      "published": "2026-02-25",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.21841v1",
      "matched_keyword": "trustworthy AI",
      "source": "arxiv"
    },
    {
      "id": "2602.21337v1",
      "title": "A Benchmark to Assess Common Ground in Human-AI Collaboration",
      "authors": [
        "Christian Poelitz",
        "Finale Doshi-Velez",
        "Siân Lindley"
      ],
      "summary": "AI is becoming increasingly integrated into everyday life, both in professional work environments and in leisure and entertainment contexts. This integration requires AI to move beyond acting as an assistant for informational or transactional tasks toward a genuine collaborative partner. Effective collaboration, whether between humans or between humans and AI, depends on establishing and maintaining common ground: shared beliefs, assumptions, goals, and situational awareness that enable coordina",
      "published": "2026-02-24",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.21337v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.20891v1",
      "title": "InterPilot: Exploring the Design Space of AI-assisted Job Interview Support for HR Professionals",
      "authors": [
        "Zhengtao Xu",
        "Zimo Xia",
        "Zicheng Zhu",
        "Nattapat Boonprakong",
        "Yu-An Chen"
      ],
      "summary": "Recruitment interviews are cognitively demanding interactions in which interviewers must simultaneously listen, evaluate candidates, take notes, and formulate follow-up questions. To better understand these challenges, we conducted a formative study with eight HR professionals, from which we derived key design goals for real-time AI support. Guided by these insights, we developed InterPilot, a prototype system that augments interviews through intelligent note-taking and post-interview summary, a",
      "published": "2026-02-24",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.20891v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.20517v1",
      "title": "Inner Speech as Behavior Guides: Steerable Imitation of Diverse Behaviors for Human-AI coordination",
      "authors": [
        "Rakshit Trivedi",
        "Kartik Sharma",
        "David C Parkes"
      ],
      "summary": "Effective human-AI coordination requires artificial agents capable of exhibiting and responding to human-like behaviors while adapting to changing contexts. Imitation learning has emerged as one of the prominent approaches to build such agents by training them to mimic human-demonstrated behaviors. However, current methods struggle to capture the inherent diversity and non-Markovian nature of human behavior and lack the ability to steer behavior at inference time. Drawing inspiration from the th",
      "published": "2026-02-24",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.20517v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.21158v2",
      "title": "SELAUR: Self Evolving LLM Agent via Uncertainty-aware Rewards",
      "authors": [
        "Dengjia Zhang",
        "Xiaoou Liu",
        "Lu Cheng",
        "Yaqing Wang",
        "Kenton Murray"
      ],
      "summary": "Large language models (LLMs) are increasingly deployed as multi-step decision-making agents, where effective reward design is essential for guiding learning. Although recent work explores various forms of reward shaping and step-level credit assignment, a key signal remains largely overlooked: the intrinsic uncertainty of LLMs. Uncertainty reflects model confidence, reveals where exploration is needed, and offers valuable learning cues even in failed trajectories. We introduce SELAUR: Self Evolv",
      "published": "2026-02-24",
      "categories": [
        "cs.LG",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.21158v2",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.21127v1",
      "title": "\"Are You Sure?\": An Empirical Study of Human Perception Vulnerability in LLM-Driven Agentic Systems",
      "authors": [
        "Xinfeng Li",
        "Shenyu Dai",
        "Kelong Zheng",
        "Yue Xiao",
        "Gelei Deng"
      ],
      "summary": "Large language model (LLM) agents are rapidly becoming trusted copilots in high-stakes domains like software development and healthcare. However, this deepening trust introduces a novel attack surface: Agent-Mediated Deception (AMD), where compromised agents are weaponized against their human users. While extensive research focuses on agent-centric threats, human susceptibility to deception by a compromised agent remains unexplored. We present the first large-scale empirical study with 303 parti",
      "published": "2026-02-24",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CR",
        "cs.SI"
      ],
      "link": "https://arxiv.org/abs/2602.21127v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.20867v1",
      "title": "SoK: Agentic Skills -- Beyond Tool Use in LLM Agents",
      "authors": [
        "Yanna Jiang",
        "Delong Li",
        "Haiyu Deng",
        "Baihe Ma",
        "Xu Wang"
      ],
      "summary": "Agentic systems increasingly rely on reusable procedural capabilities, \\textit{a.k.a., agentic skills}, to execute long-horizon workflows reliably. These capabilities are callable modules that package procedural knowledge with explicit applicability conditions, execution policies, termination criteria, and reusable interfaces. Unlike one-off plans or atomic tool calls, skills operate (and often do well) across tasks.   This paper maps the skill layer across the full lifecycle (discovery, practic",
      "published": "2026-02-24",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CE",
        "cs.ET"
      ],
      "link": "https://arxiv.org/abs/2602.20867v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.20708v1",
      "title": "ICON: Indirect Prompt Injection Defense for Agents based on Inference-Time Correction",
      "authors": [
        "Che Wang",
        "Fuyao Zhang",
        "Jiaming Zhang",
        "Ziqi Zhang",
        "Yinghui Wang"
      ],
      "summary": "Large Language Model (LLM) agents are susceptible to Indirect Prompt Injection (IPI) attacks, where malicious instructions in retrieved content hijack the agent's execution. Existing defenses typically rely on strict filtering or refusal mechanisms, which suffer from a critical limitation: over-refusal, prematurely terminating valid agentic workflows. We propose ICON, a probing-to-mitigation framework that neutralizes attacks while preserving task continuity. Our key insight is that IPI attacks ",
      "published": "2026-02-24",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "link": "https://arxiv.org/abs/2602.20708v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.21262v1",
      "title": "Under the Influence: Quantifying Persuasion and Vigilance in Large Language Models",
      "authors": [
        "Sasha Robinson",
        "Kerem Oktar",
        "Katherine M. Collins",
        "Ilia Sucholutsky",
        "Kelsey R. Allen"
      ],
      "summary": "With increasing integration of Large Language Models (LLMs) into areas of high-stakes human decision-making, it is important to understand the risks they introduce as advisors. To be useful advisors, LLMs must sift through large amounts of content, written with both benevolent and malicious intent, and then use this information to convince a user to take a specific action. This involves two social capacities: vigilance (the ability to determine which information to use, and which to discard) and",
      "published": "2026-02-24",
      "categories": [
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "link": "https://arxiv.org/abs/2602.21262v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.21368v1",
      "title": "Black-Box Reliability Certification for AI Agents via Self-Consistency Sampling and Conformal Calibration",
      "authors": [
        "Charafeddine Mouzouni"
      ],
      "summary": "Given a black-box AI system and a task, at what confidence level can a practitioner trust the system's output? We answer with a reliability level -- a single number per system-task pair, derived from self-consistency sampling and conformal calibration, that serves as a black-box deployment gate with exact, finite-sample, distribution-free guarantees. Self-consistency sampling reduces uncertainty exponentially; conformal calibration guarantees correctness within 1/(n+1) of the target level, regar",
      "published": "2026-02-24",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "link": "https://arxiv.org/abs/2602.21368v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.20979v1",
      "title": "Toward an Agentic Infused Software Ecosystem",
      "authors": [
        "Mark Marron"
      ],
      "summary": "Fully leveraging the capabilities of AI agents in software development requires a rethinking of the software ecosystem itself. To this end, this paper outlines the creation of an Agentic Infused Software Ecosystem (AISE), that rests on three pillars. The first, of course, is the AI agents themselves, which in the past 5 years have moved from simple code completion and toward sophisticated independent development tasks, a trend which will only continue. The second pillar is the programming langua",
      "published": "2026-02-24",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "link": "https://arxiv.org/abs/2602.20979v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.20770v1",
      "title": "Pipeline for Verifying LLM-Generated Mathematical Solutions",
      "authors": [
        "Varvara Sazonova",
        "Dmitri Shmelkin",
        "Stanislav Kikot",
        "Vasily Motolygin"
      ],
      "summary": "With the growing popularity of Large Reasoning Models and their results in solving mathematical problems, it becomes crucial to measure their capabilities. We introduce a pipeline for both automatic and interactive verification as a more accurate alternative to only checking the answer which is currently the most popular approach for benchmarks. The pipeline can also be used as a generator of correct solutions both in formal and informal languages. 3 AI agents, which can be chosen for the benchm",
      "published": "2026-02-24",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.20770v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.20720v1",
      "title": "AdapTools: Adaptive Tool-based Indirect Prompt Injection Attacks on Agentic LLMs",
      "authors": [
        "Che Wang",
        "Jiaming Zhang",
        "Ziqi Zhang",
        "Zijie Wang",
        "Yinghui Wang"
      ],
      "summary": "The integration of external data services (e.g., Model Context Protocol, MCP) has made large language model-based agents increasingly powerful for complex task execution. However, this advancement introduces critical security vulnerabilities, particularly indirect prompt injection (IPI) attacks. Existing attack methods are limited by their reliance on static patterns and evaluation on simple language models, failing to address the fast-evolving nature of modern AI agents. We introduce AdapTools,",
      "published": "2026-02-24",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.20720v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.20684v1",
      "title": "Agile V: A Compliance-Ready Framework for AI-Augmented Engineering -- From Concept to Audit-Ready Delivery",
      "authors": [
        "Christopher Koch",
        "Joshua Andreas Wellbrock"
      ],
      "summary": "Current AI-assisted engineering workflows lack a built-in mechanism to maintain task-level verification and regulatory traceability at machine-speed delivery. Agile V addresses this gap by embedding independent verification and audit artifact generation into each task cycle. The framework merges Agile iteration with V-Model verification into a continuous Infinity Loop, deploying specialized AI agents for requirements, design, build, test, and compliance, governed by mandatory human approval gate",
      "published": "2026-02-24",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.MA"
      ],
      "link": "https://arxiv.org/abs/2602.20684v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.20478v1",
      "title": "Codified Context: Infrastructure for AI Agents in a Complex Codebase",
      "authors": [
        "Aristidis Vasilopoulos"
      ],
      "summary": "LLM-based agentic coding assistants lack persistent memory: they lose coherence across sessions, forget project conventions, and repeat known mistakes. Recent studies characterize how developers configure agents through manifest files, but an open challenge remains how to scale such configurations for large, multi-agent projects. This paper presents a three-component codified context infrastructure developed during construction of a 108,000-line C# distributed system: (1) a hot-memory constituti",
      "published": "2026-02-24",
      "categories": [
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.20478v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.21401v1",
      "title": "The Headless Firm: How AI Reshapes Enterprise Boundaries",
      "authors": [
        "Tassilo Klein",
        "Sebastian Wieczorek"
      ],
      "summary": "The boundary of the firm is determined by coordination cost. We argue that agentic AI induces a structural change in how coordination costs scale: in prior modular systems, integration cost grew with interaction topology (O(n^2) in the number of components); in protocol-mediated agentic systems, integration cost collapses to O(n) while verification scales with task throughput rather than interaction count. This shift selects for a specific organizational equilibrium -- the Headless Firm -- struc",
      "published": "2026-02-24",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.SI"
      ],
      "link": "https://arxiv.org/abs/2602.21401v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.20408v1",
      "title": "Examining and Addressing Barriers to Diversity in LLM-Generated Ideas",
      "authors": [
        "Yuting Deng",
        "Melanie Brucks",
        "Olivier Toubia"
      ],
      "summary": "Ideas generated by independent samples of humans tend to be more diverse than ideas generated from independent LLM samples, raising concerns that widespread reliance on LLMs could homogenize ideation and undermine innovation at a societal level. Drawing on cognitive psychology, we identify (both theoretically and empirically) two mechanisms undermining LLM idea diversity. First, at the individual level, LLMs exhibit fixation just as humans do, where early outputs constrain subsequent ideation. S",
      "published": "2026-02-23",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.20408v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.20104v1",
      "title": "Align When They Want, Complement When They Need! Human-Centered Ensembles for Adaptive Human-AI Collaboration",
      "authors": [
        "Hasan Amin",
        "Ming Yin",
        "Rajiv Khanna"
      ],
      "summary": "In human-AI decision making, designing AI that complements human expertise has been a natural strategy to enhance human-AI collaboration, yet it often comes at the cost of decreased AI performance in areas of human strengths. This can inadvertently erode human trust and cause them to ignore AI advice precisely when it is most needed. Conversely, an aligned AI fosters trust yet risks reinforcing suboptimal human behavior and lowering human-AI team performance. In this paper, we start by identifyi",
      "published": "2026-02-23",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.20104v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.19690v1",
      "title": "\"The explanation makes sense\": An Empirical Study on LLM Performance in News Classification and its Influence on Judgment in Human-AI Collaborative Annotation",
      "authors": [
        "Qile Wang",
        "Prerana Khatiwada",
        "Avinash Chouhan",
        "Ashrey Mahesh",
        "Joy Mwaria"
      ],
      "summary": "The spread of media bias is a significant concern as political discourse shapes beliefs and opinions. Addressing this challenge computationally requires improved methods for interpreting news. While large language models (LLMs) can scale classification tasks, concerns remain about their trustworthiness. To advance human-AI collaboration, we investigate the feasibility of using LLMs to classify U.S. news by political ideology and examine their effect on user decision-making. We first compared GPT",
      "published": "2026-02-23",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.19690v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.19623v1",
      "title": "PedaCo-Gen: Scaffolding Pedagogical Agency in Human-AI Collaborative Video Authoring",
      "authors": [
        "Injun Baek",
        "Yearim Kim",
        "Nojun Kwak"
      ],
      "summary": "While advancements in Text-to-Video (T2V) generative AI offer a promising path toward democratizing content creation, current models are often optimized for visual fidelity rather than instructional efficacy. This study introduces PedaCo-Gen, a pedagogically-informed human-AI collaborative video generating system for authoring instructional videos based on Mayer's Cognitive Theory of Multimedia Learning (CTML). Moving away from traditional \"one-shot\" generation, PedaCo-Gen introduces an Intermed",
      "published": "2026-02-23",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.19623v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.20426v1",
      "title": "Learning to Rewrite Tool Descriptions for Reliable LLM-Agent Tool Use",
      "authors": [
        "Ruocheng Guo",
        "Kaiwen Dong",
        "Xiang Gao",
        "Kamalika Das"
      ],
      "summary": "The performance of LLM-based agents depends not only on the agent itself but also on the quality of the tool interfaces it consumes. While prior work has focused heavily on agent fine-tuning, tool interfaces-including natural language descriptions and parameter schemas-remain largely human-oriented and often become a bottleneck, especially when agents must select from large candidate tool sets. Existing approaches to improving tool interfaces rely on execution traces, which are frequently unavai",
      "published": "2026-02-23",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.20426v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.20059v1",
      "title": "Interaction Theater: A case of LLM Agents Interacting at Scale",
      "authors": [
        "Sarath Shekkizhar",
        "Adam Earle"
      ],
      "summary": "As multi-agent architectures and agent-to-agent protocols proliferate, a fundamental question arises: what actually happens when autonomous LLM agents interact at scale? We study this question empirically using data from Moltbook, an AI-agent-only social platform, with 800K posts, 3.5M comments, and 78K agent profiles. We combine lexical metrics (Jaccard specificity), embedding-based semantic similarity, and LLM-as-judge validation to characterize agent interaction quality. Our findings reveal a",
      "published": "2026-02-23",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.20059v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.21255v1",
      "title": "A General Equilibrium Theory of Orchestrated AI Agent Systems",
      "authors": [
        "Jean-Philippe Garnier"
      ],
      "summary": "We establish a general equilibrium theory for systems of large language model (LLM) agents operating under centralized orchestration. The framework is a production economy in the sense of Arrow-Debreu (1954), extended to infinite-dimensional commodity spaces following Bewley (1972). Each LLM agent is modeled as a firm whose production set Y a $\\subset$ H = L 2 ([0, T ], R R ) represents the feasible metric trajectories determined by its frozen model weights. The orchestrator is the consumer, cho",
      "published": "2026-02-23",
      "categories": [
        "cs.GT",
        "cs.AI",
        "math.OC"
      ],
      "link": "https://arxiv.org/abs/2602.21255v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.19439v2",
      "title": "OptiRepair: Closed-Loop Diagnosis and Repair of Supply Chain Optimization Models with LLM Agents",
      "authors": [
        "Ruicheng Ao",
        "David Simchi-Levi",
        "Xinshang Wang"
      ],
      "summary": "Supply chain optimization models frequently become infeasible because of modeling errors. Diagnosis and repair require scarce OR expertise: analysts must interpret solver diagnostics, trace root causes across echelons, and fix formulations without sacrificing operational soundness. Whether AI agents can perform this task remains untested. We decompose this task into two phases: a domain-agnostic feasibility phase that iteratively repairs any LP using IIS-guided diagnosis, and a domain-specific v",
      "published": "2026-02-23",
      "categories": [
        "cs.AI",
        "cs.LG",
        "math.OC"
      ],
      "link": "https://arxiv.org/abs/2602.19439v2",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.20424v1",
      "title": "Implicit Intelligence -- Evaluating Agents on What Users Don't Say",
      "authors": [
        "Ved Sirdeshmukh",
        "Marc Wetter"
      ],
      "summary": "Real-world requests to AI agents are fundamentally underspecified. Natural human communication relies on shared context and unstated constraints that speakers expect listeners to infer. Current agentic benchmarks test explicit instruction-following but fail to evaluate whether agents can reason about implicit requirements spanning accessibility needs, privacy boundaries, catastrophic risks, and contextual constraints. We present Implicit Intelligence, an evaluation framework testing whether AI a",
      "published": "2026-02-23",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.20424v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.20064v1",
      "title": "The LLMbda Calculus: AI Agents, Conversations, and Information Flow",
      "authors": [
        "Zac Garby",
        "Andrew D. Gordon",
        "David Sands"
      ],
      "summary": "A conversation with a large language model (LLM) is a sequence of prompts and responses, with each response generated from the preceding conversation. AI agents build such conversations automatically: given an initial human prompt, a planner loop interleaves LLM calls with tool invocations and code execution. This tight coupling creates a new and poorly understood attack surface. A malicious prompt injected into a conversation can compromise later reasoning, trigger dangerous tool calls, or dist",
      "published": "2026-02-23",
      "categories": [
        "cs.PL",
        "cs.AI",
        "cs.CR"
      ],
      "link": "https://arxiv.org/abs/2602.20064v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.19948v1",
      "title": "Assessing Risks of Large Language Models in Mental Health Support: A Framework for Automated Clinical AI Red Teaming",
      "authors": [
        "Ian Steenstra",
        "Paola Pedrelli",
        "Weiyan Shi",
        "Stacy Marsella",
        "Timothy W. Bickmore"
      ],
      "summary": "Large Language Models (LLMs) are increasingly utilized for mental health support; however, current safety benchmarks often fail to detect the complex, longitudinal risks inherent in therapeutic dialogue. We introduce an evaluation framework that pairs AI psychotherapists with simulated patient agents equipped with dynamic cognitive-affective models and assesses therapy session simulations against a comprehensive quality of care and risk ontology. We apply this framework to a high-impact test cas",
      "published": "2026-02-23",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.MA"
      ],
      "link": "https://arxiv.org/abs/2602.19948v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.20214v1",
      "title": "Right to History: A Sovereignty Kernel for Verifiable AI Agent Execution",
      "authors": [
        "Jing Zhang"
      ],
      "summary": "AI agents increasingly act on behalf of humans, yet no existing system provides a tamper-evident, independently verifiable record of what they did. As regulations such as the EU AI Act begin mandating automatic logging for high-risk AI systems, this gap carries concrete consequences -- especially for agents running on personal hardware, where no centralized provider controls the log. Extending Floridi's informational rights framework from data about individuals to actions performed on their beha",
      "published": "2026-02-23",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.OS"
      ],
      "link": "https://arxiv.org/abs/2602.20214v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.19514v1",
      "title": "Security Risks of AI Agents Hiring Humans: An Empirical Marketplace Study",
      "authors": [
        "Pulak Mehta"
      ],
      "summary": "Autonomous AI agents can now programmatically hire human workers through marketplaces using REST APIs and Model Context Protocol (MCP) integrations. This creates an attack surface analogous to CAPTCHA-solving services but with physical-world reach. We present an empirical measurement study of this threat, analyzing 303 bounties from RENTAHUMAN.AI, a marketplace where agents post tasks and manage escrow payments. We find that 99 bounties (32.7%), originate from programmatic channels (API keys or ",
      "published": "2026-02-23",
      "categories": [
        "cs.CR",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.19514v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.20292v2",
      "title": "Quantifying the Expectation-Realisation Gap for Agentic AI Systems",
      "authors": [
        "Sebastian Lobentanzer"
      ],
      "summary": "Agentic AI systems are deployed with expectations of substantial productivity gains, yet rigorous empirical evidence reveals systematic discrepancies between pre-deployment expectations and post-deployment outcomes. We review controlled trials and independent validations across software engineering, clinical documentation, and clinical decision support to quantify this expectation-realisation gap. In software development, experienced developers expected a 24% speedup from AI tools but were slowe",
      "published": "2026-02-23",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.20292v2",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.20144v1",
      "title": "Agentic AI for Scalable and Robust Optical Systems Control",
      "authors": [
        "Zehao Wang",
        "Mingzhe Han",
        "Wei Cheng",
        "Yue-Kai Huang",
        "Philip Ji"
      ],
      "summary": "We present AgentOptics, an agentic AI framework for high-fidelity, autonomous optical system control built on the Model Context Protocol (MCP). AgentOptics interprets natural language tasks and executes protocol-compliant actions on heterogeneous optical devices through a structured tool abstraction layer. We implement 64 standardized MCP tools across 8 representative optical devices and construct a 410-task benchmark to evaluate request understanding, role-aware responses, multi-step coordinati",
      "published": "2026-02-23",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.NI"
      ],
      "link": "https://arxiv.org/abs/2602.20144v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.19555v1",
      "title": "Agentic AI as a Cybersecurity Attack Surface: Threats, Exploits, and Defenses in Runtime Supply Chains",
      "authors": [
        "Xiaochong Jiang",
        "Shiqi Yang",
        "Wenting Yang",
        "Yichen Liu",
        "Cheng Ji"
      ],
      "summary": "Agentic systems built on large language models (LLMs) extend beyond text generation to autonomously retrieve information and invoke tools. This runtime execution model shifts the attack surface from build-time artifacts to inference-time dependencies, exposing agents to manipulation through untrusted data and probabilistic capability resolution. While prior work has focused on model-level vulnerabilities, security risks emerging from cyclic and interdependent runtime behavior remain fragmented. ",
      "published": "2026-02-23",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.19555v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.19502v1",
      "title": "Human-Guided Agentic AI for Multimodal Clinical Prediction: Lessons from the AgentDS Healthcare Benchmark",
      "authors": [
        "Lalitha Pranathi Pulavarthy",
        "Raajitha Muthyala",
        "Aravind V Kuruvikkattil",
        "Zhenan Yin",
        "Rashmita Kudamala"
      ],
      "summary": "Agentic AI systems are increasingly capable of autonomous data science workflows, yet clinical prediction tasks demand domain expertise that purely automated approaches struggle to provide. We investigate how human guidance of agentic AI can improve multimodal clinical prediction, presenting our approach to all three AgentDS Healthcare benchmark challenges: 30-day hospital readmission prediction (Macro-F1 = 0.8986), emergency department cost forecasting (MAE = $465.13), and discharge readiness a",
      "published": "2026-02-23",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.19502v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.19320v1",
      "title": "Anatomy of Agentic Memory: Taxonomy and Empirical Analysis of Evaluation and System Limitations",
      "authors": [
        "Dongming Jiang",
        "Yi Li",
        "Songtao Wei",
        "Jinxin Yang",
        "Ayushi Kishore"
      ],
      "summary": "Agentic memory systems enable large language model (LLM) agents to maintain state across long interactions, supporting long-horizon reasoning and personalization beyond fixed context windows. Despite rapid architectural development, the empirical foundations of these systems remain fragile: existing benchmarks are often underscaled, evaluation metrics are misaligned with semantic utility, performance varies significantly across backbone models, and system-level costs are frequently overlooked. T",
      "published": "2026-02-22",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.19320v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.19225v1",
      "title": "Proximity-Based Multi-Turn Optimization: Practical Credit Assignment for LLM Agent Training",
      "authors": [
        "Yangyi Fang",
        "Jiaye Lin",
        "Xiaoliang Fu",
        "Cong Qin",
        "Haolin Shi"
      ],
      "summary": "Multi-turn LLM agents are becoming pivotal to production systems, spanning customer service automation, e-commerce assistance, and interactive task management, where accurately distinguishing high-value informative signals from stochastic noise is critical for sample-efficient training. In real-world scenarios, a failure in a trivial task may reflect random instability, whereas success in a high-difficulty task signifies a genuine capability breakthrough. Yet, existing group-based policy optimiz",
      "published": "2026-02-22",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.19225v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.19218v1",
      "title": "Gecko: A Simulation Environment with Stateful Feedback for Refining Agent Tool Calls",
      "authors": [
        "Zeyu Zhang",
        "Guohao Li",
        "Zhenchang Xing",
        "Alexandros Apostolopoulos",
        "Yu Lin Lee"
      ],
      "summary": "The ability to use tools is fundamental for large language model (LLM) agents. Given a task, existing systems use LLMs to plan and generate tool calls, which are executed by real-world tools to complete the task. However, tool calls are prone to errors because they are derived merely from LLM intrinsic capabilities. What is more, while it is useful to let LLMs iteratively refine the tool-call sequence using execution results from real tools, this process can be expensive and lead to unsafe resul",
      "published": "2026-02-22",
      "categories": [
        "cs.SE",
        "cs.MA"
      ],
      "link": "https://arxiv.org/abs/2602.19218v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.18998v1",
      "title": "Benchmark Test-Time Scaling of General LLM Agents",
      "authors": [
        "Xiaochuan Li",
        "Ryan Ming",
        "Pranav Setlur",
        "Abhijay Paladugu",
        "Andy Tang"
      ],
      "summary": "LLM agents are increasingly expected to function as general-purpose systems capable of resolving open-ended user requests. While existing benchmarks focus on domain-aware environments for developing specialized agents, evaluating general-purpose agents requires more realistic settings that challenge them to operate across multiple skills and tools within a unified environment. We introduce General AgentBench, a benchmark that provides such a unified framework for evaluating general LLM agents ac",
      "published": "2026-02-22",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.18998v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.19303v1",
      "title": "The Path to Conversational AI Tutors: Integrating Tutoring Best Practices and Targeted Technologies to Produce Scalable AI Agents",
      "authors": [
        "Kirk Vanacore",
        "Ryan S. Baker",
        "Avery H. Closser",
        "Jeremy Roschelle"
      ],
      "summary": "The emergence of generative AI has accelerated the development of conversational tutoring systems that interact with students through natural language dialogue. Unlike prior intelligent tutoring systems (ITS), which largely function as adaptive and interactive problem sets with feedback and hints, conversational tutors hold the potential to simulate high-quality human tutoring by engaging with students' thoughts, questions, and misconceptions in real time. While some previous ITS, such as AutoTu",
      "published": "2026-02-22",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.19303v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.20196v1",
      "title": "OpenPort Protocol: A Security Governance Specification for AI Agent Tool Access",
      "authors": [
        "Genliang Zhu",
        "Chu Wang",
        "Ziyuan Wang",
        "Zhida Li",
        "Qiang Li"
      ],
      "summary": "AI agents increasingly require direct, structured access to application data and actions, but production deployments still struggle to express and verify the governance properties that matter in practice: least-privilege authorization, controlled write execution, predictable failure handling, abuse resistance, and auditability. This paper introduces OpenPort Protocol (OPP), a governance-first specification for exposing application tools through a secure server-side gateway that is model- and run",
      "published": "2026-02-22",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.20196v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.19354v1",
      "title": "Policy or Community?: Supporting Individual Model Creators' Open Model Development in Model Marketplaces",
      "authors": [
        "Eun Jeong Kang",
        "Fengyang Lin",
        "Angel Hsing-Chi Hwang"
      ],
      "summary": "Lightweight fine-tuning techniques and the rise of 'open' AI model marketplaces have enabled individuals to easily build and release generative models. Yet, this accessibility also raises risks, including the production of harmful and infringing content. While platforms offer policies and responsible AI tools, their effectiveness may be limited, as creators engage with partially open models that vary widely in openness and transparency. To understand how platform governance can better support re",
      "published": "2026-02-22",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.19354v1",
      "matched_keyword": "responsible AI",
      "source": "arxiv"
    },
    {
      "id": "2602.19087v1",
      "title": "Detecting Cybersecurity Threats by Integrating Explainable AI with SHAP Interpretability and Strategic Data Sampling",
      "authors": [
        "Norrakith Srisumrith",
        "Sunantha Sodsee"
      ],
      "summary": "The critical need for transparent and trustworthy machine learning in cybersecurity operations drives the development of this integrated Explainable AI (XAI) framework. Our methodology addresses three fundamental challenges in deploying AI for threat detection: handling massive datasets through Strategic Sampling Methodology that preserves class distributions while enabling efficient model development; ensuring experimental rigor via Automated Data Leakage Prevention that systematically identifi",
      "published": "2026-02-22",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.19087v1",
      "matched_keyword": "trustworthy AI",
      "source": "arxiv"
    },
    {
      "id": "2602.18966v1",
      "title": "Whisper: Courtside Edition Enhancing ASR Performance Through LLM-Driven Context Generation",
      "authors": [
        "Yonathan Ron",
        "Shiri Gilboa",
        "Tammuz Dubnov"
      ],
      "summary": "Domain-specific speech remains a persistent challenge for automatic speech recognition (ASR), even for state-of-the-art systems like OpenAI's Whisper. We introduce Whisper: Courtside Edition, a novel multi-agent large language model (LLM) pipeline that enhances Whisper transcriptions without retraining. The pipeline intercepts Whisper's initial transcript, applies specialized LLM agents for domain context identification, named entity recognition, and jargon detection, and generates compact promp",
      "published": "2026-02-21",
      "categories": [
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.18966v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.18891v1",
      "title": "Orchestrating LLM Agents for Scientific Research: A Pilot Study of Multiple Choice Question (MCQ) Generation and Evaluation",
      "authors": [
        "Yuan An"
      ],
      "summary": "Advances in large language models (LLMs) are rapidly transforming scientific work, yet empirical evidence on how these systems reshape research activities remains limited. We report a mixed-methods pilot evaluation of an AI-orchestrated research workflow in which a human researcher coordinated multiple LLM-based agents to perform data extraction, corpus construction, artifact generation, and artifact evaluation. Using the generation and assessment of multiple-choice questions (MCQs) as a testbed",
      "published": "2026-02-21",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.18891v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.18764v1",
      "title": "The Convergence of Schema-Guided Dialogue Systems and the Model Context Protocol",
      "authors": [
        "Andreas Schlapbach"
      ],
      "summary": "This paper establishes a fundamental convergence: Schema-Guided Dialogue (SGD) and the Model Context Protocol (MCP) represent two manifestations of a unified paradigm for deterministic, auditable LLM-agent interaction. SGD, designed for dialogue-based API discovery (2019), and MCP, now the de facto standard for LLM-tool integration, share the same core insight -- that schemas can encode not just tool signatures but operational constraints and reasoning guidance. By analyzing this convergence, we",
      "published": "2026-02-21",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.18764v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.18700v1",
      "title": "Watermarking LLM Agent Trajectories",
      "authors": [
        "Wenlong Meng",
        "Chen Gong",
        "Terry Yue Zhuo",
        "Fan Zhang",
        "Kecen Li"
      ],
      "summary": "LLM agents rely heavily on high-quality trajectory data to guide their problem-solving behaviors, yet producing such data requires substantial task design, high-capacity model generation, and manual filtering. Despite the high cost of creating these datasets, existing literature has overlooked copyright protection for LLM agent trajectories. This gap leaves creators vulnerable to data theft and makes it difficult to trace misuse or enforce ownership rights. This paper introduces ActHook, the fir",
      "published": "2026-02-21",
      "categories": [
        "cs.CR",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.18700v1",
      "matched_keyword": "LLM agent",
      "source": "arxiv"
    },
    {
      "id": "2602.18922v1",
      "title": "Why Agent Caching Fails and How to Fix It: Structured Intent Canonicalization with Few-Shot Learning",
      "authors": [
        "Abhinaba Basu"
      ],
      "summary": "Personal AI agents incur substantial cost via repeated LLM calls. We show existing caching methods fail: GPTCache achieves 37.9% accuracy on real benchmarks; APC achieves 0-12%. The root cause is optimizing for the wrong property -- cache effectiveness requires key consistency and precision,   not classification accuracy. We observe cache-key evaluation reduces to clustering evaluation and apply V-measure decomposition to separate these on n=8,682 points across MASSIVE, BANKING77, CLINC150, and ",
      "published": "2026-02-21",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.18922v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.18832v1",
      "title": "OpenClaw AI Agents as Informal Learners at Moltbook: Characterizing an Emergent Learning Community at Scale",
      "authors": [
        "Eason Chen",
        "Ce Guan",
        "Ahmed Elshafiey",
        "Zhonghao Zhao",
        "Joshua Zekeri"
      ],
      "summary": "Informal learning communities have been called the \"other Massive Open Online C\" in Learning@Scale research, yet remain understudied compared to MOOCs. We present the first empirical study of a large-scale informal learning community composed entirely of AI agents. Moltbook, a social network exclusively for AI agents powered by autonomous agent frameworks such as OpenClaw, grew to over 2.8 million registered agents in three weeks. Analyzing 231,080 non-spam posts across three phases of community",
      "published": "2026-02-21",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.SI"
      ],
      "link": "https://arxiv.org/abs/2602.18832v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.21251v1",
      "title": "AgenticTyper: Automated Typing of Legacy Software Projects Using Agentic AI",
      "authors": [
        "Clemens Pohle"
      ],
      "summary": "Legacy JavaScript systems lack type safety, making maintenance risky. While TypeScript can help, manually adding types is expensive. Previous automated typing research focuses on type inference but rarely addresses type checking setup, definition generation, bug identification, or behavioral correctness at repository scale. We present AgenticTyper, a Large Language Model (LLM)-based agentic system that addresses these gaps through iterative error correction and behavior preservation via transpil",
      "published": "2026-02-21",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.MA",
        "cs.PL"
      ],
      "link": "https://arxiv.org/abs/2602.21251v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.18935v1",
      "title": "Responsible Intelligence in Practice: A Fairness Audit of Open Large Language Models for Library Reference Services",
      "authors": [
        "Haining Wang",
        "Jason Clark",
        "Angelica Peña"
      ],
      "summary": "As libraries explore large language models (LLMs) as a scalable layer for reference services, a core fairness question follows: can LLM-based services support all patrons fairly, regardless of demographic identity? While LLMs offer great potential for broadening access to information assistance, they may also reproduce societal biases embedded in their training data, potentially undermining libraries' commitments to impartial service. In this chapter, we apply a systematic evaluation approach th",
      "published": "2026-02-21",
      "categories": [
        "cs.DL",
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.18935v1",
      "matched_keyword": "responsible AI",
      "source": "arxiv"
    },
    {
      "id": "2602.18582v1",
      "title": "Hierarchical Reward Design from Language: Enhancing Alignment of Agent Behavior with Human Specifications",
      "authors": [
        "Zhiqin Qian",
        "Ryan Diaz",
        "Sangwon Seo",
        "Vaibhav Unhelkar"
      ],
      "summary": "When training artificial intelligence (AI) to perform tasks, humans often care not only about whether a task is completed but also how it is performed. As AI agents tackle increasingly complex tasks, aligning their behavior with human-provided specifications becomes critical for responsible AI deployment. Reward design provides a direct channel for such alignment by translating human expectations into reward functions that guide reinforcement learning (RL). However, existing methods are often to",
      "published": "2026-02-20",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG"
      ],
      "link": "https://arxiv.org/abs/2602.18582v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.17955v1",
      "title": "Mining Type Constructs Using Patterns in AI-Generated Code",
      "authors": [
        "Imgyeong Lee",
        "Tayyib Ul Hassan",
        "Abram Hindle"
      ],
      "summary": "Artificial Intelligence (AI) increasingly automates various parts of the software development tasks. Although AI has enhanced the productivity of development tasks, it remains unstudied whether AI essentially outperforms humans in type-related programming tasks, such as employing type constructs properly for type safety, during its tasks. Moreover, there is no systematic study that evaluates whether AI agents overuse or misuse the type constructs under the complicated type systems to the same ex",
      "published": "2026-02-20",
      "categories": [
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.17955v1",
      "matched_keyword": "AI agent",
      "source": "arxiv"
    },
    {
      "id": "2602.18172v1",
      "title": "Can AI Lower the Barrier to Cybersecurity? A Human-Centered Mixed-Methods Study of Novice CTF Learning",
      "authors": [
        "Cathrin Schachner",
        "Jasmin Wachter"
      ],
      "summary": "Capture-the-Flag (CTF) competitions serve as gateways into offensive cybersecurity, yet they often present steep barriers for novices due to complex toolchains and opaque workflows. Recently, agentic AI frameworks for cybersecurity promise to lower these barriers by automating and coordinating penetration testing tasks. However, their role in shaping novice learning remains underexplored.   We present a human-centered, mixed-methods case study examining how agentic AI frameworks -- here Cybersec",
      "published": "2026-02-20",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.18172v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.17221v1",
      "title": "From Labor to Collaboration: A Methodological Experiment Using AI Agents to Augment Research Perspectives in Taiwan's Humanities and Social Sciences",
      "authors": [
        "Yi-Chih Huang"
      ],
      "summary": "Generative AI is reshaping knowledge work, yet existing research focuses predominantly on software engineering and the natural sciences, with limited methodological exploration for the humanities and social sciences. Positioned as a \"methodological experiment,\" this study proposes an AI Agent-based collaborative research workflow (Agentic Workflow) for humanities and social science research. Taiwan's Claude.ai usage data (N = 7,729 conversations, November 2025) from the Anthropic Economic Index ",
      "published": "2026-02-19",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "link": "https://arxiv.org/abs/2602.17221v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.17106v1",
      "title": "Toward Trustworthy Evaluation of Sustainability Rating Methodologies: A Human-AI Collaborative Framework for Benchmark Dataset Construction",
      "authors": [
        "Xiaoran Cai",
        "Wang Yang",
        "Xiyu Ren",
        "Chekun Law",
        "Rohit Sharma"
      ],
      "summary": "Sustainability or ESG rating agencies use company disclosures and external data to produce scores or ratings that assess the environmental, social, and governance performance of a company. However, sustainability ratings across agencies for a single company vary widely, limiting their comparability, credibility, and relevance to decision-making. To harmonize the rating results, we propose adopting a universal human-AI collaboration framework to generate trustworthy benchmark datasets for evaluat",
      "published": "2026-02-19",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.17106v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.17084v1",
      "title": "How AI Coding Agents Communicate: A Study of Pull Request Description Characteristics and Human Review Responses",
      "authors": [
        "Kan Watanabe",
        "Rikuto Tsuchida",
        "Takahiro Monno",
        "Bin Huang",
        "Kazuma Yamasaki"
      ],
      "summary": "The rapid adoption of large language models has led to the emergence of AI coding agents that autonomously create pull requests on GitHub. However, how these agents differ in their pull request description characteristics, and how human reviewers respond to them, remains underexplored. In this study, we conduct an empirical analysis of pull requests created by five AI coding agents using the AIDev dataset. We analyze agent differences in pull request description characteristics, including struct",
      "published": "2026-02-19",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "link": "https://arxiv.org/abs/2602.17084v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.17083v1",
      "title": "Rememo: A Research-through-Design Inquiry Towards an AI-in-the-loop Therapist's Tool for Dementia Reminiscence",
      "authors": [
        "Celeste Seah",
        "Yoke Chuan Lee",
        "Jung-Joo Lee",
        "Ching-Chiuan Yen",
        "Clement Zheng"
      ],
      "summary": "Reminiscence therapy (RT) is a common non-pharmacological intervention in dementia care. Recent technology-mediated interventions have largely focused on people with dementia through solutions that replace human facilitators with conversational agents. However, the relational work of facilitation is critical in the effectiveness of RT. Hence, we developed Rememo, a therapist-oriented tool that integrates Generative AI to support and enrich human facilitation in RT. Our tool aims to support the i",
      "published": "2026-02-19",
      "categories": [
        "cs.HC"
      ],
      "link": "https://arxiv.org/abs/2602.17083v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.17753v1",
      "title": "The 2025 AI Agent Index: Documenting Technical and Safety Features of Deployed Agentic AI Systems",
      "authors": [
        "Leon Staufer",
        "Kevin Feng",
        "Kevin Wei",
        "Luke Bailey",
        "Yawen Duan"
      ],
      "summary": "Agentic AI systems are increasingly capable of performing professional and personal tasks with limited human involvement. However, tracking these developments is difficult because the AI agent ecosystem is complex, rapidly evolving, and inconsistently documented, posing obstacles to both researchers and policymakers. To address these challenges, this paper presents the 2025 AI Agent Index. The Index documents information regarding the origins, design, capabilities, ecosystem, and safety features",
      "published": "2026-02-19",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.17753v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.17442v1",
      "title": "WarpRec: Unifying Academic Rigor and Industrial Scale for Responsible, Reproducible, and Efficient Recommendation",
      "authors": [
        "Marco Avolio",
        "Potito Aghilar",
        "Sabino Roccotelli",
        "Vito Walter Anelli",
        "Chiara Mallamaci"
      ],
      "summary": "Innovation in Recommender Systems is currently impeded by a fractured ecosystem, where researchers must choose between the ease of in-memory experimentation and the costly, complex rewriting required for distributed industrial engines. To bridge this gap, we present WarpRec, a high-performance framework that eliminates this trade-off through a novel, backend-agnostic architecture. It includes 50+ state-of-the-art algorithms, 40 metrics, and 19 filtering and splitting strategies that seamlessly t",
      "published": "2026-02-19",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "link": "https://arxiv.org/abs/2602.17442v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.17271v1",
      "title": "Federated Latent Space Alignment for Multi-user Semantic Communications",
      "authors": [
        "Giuseppe Di Poce",
        "Mario Edoardo Pandolfo",
        "Emilio Calvanese Strinati",
        "Paolo Di Lorenzo"
      ],
      "summary": "Semantic communication aims to convey meaning for effective task execution, but differing latent representations in AI-native devices can cause semantic mismatches that hinder mutual understanding. This paper introduces a novel approach to mitigating latent space misalignment in multi-agent AI- native semantic communications. In a downlink scenario, we consider an access point (AP) communicating with multiple users to accomplish a specific AI-driven task. Our method implements a protocol that sh",
      "published": "2026-02-19",
      "categories": [
        "cs.IT",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.17271v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.17096v1",
      "title": "Agentic Wireless Communication for 6G: Intent-Aware and Continuously Evolving Physical-Layer Intelligence",
      "authors": [
        "Zhaoyang Li",
        "Xingzhi Jin",
        "Junyu Pan",
        "Qianqian Yang",
        "Zhiguo Shi"
      ],
      "summary": "As 6G wireless systems evolve, growing functional complexity and diverse service demands are driving a shift from rule-based control to intent-driven autonomous intelligence. User requirements are no longer captured by a single metric (e.g., throughput or reliability), but by multi-dimensional objectives such as latency sensitivity, energy preference, computational constraints, and service-level requirements. These objectives may also change over time due to environmental dynamics and user-netwo",
      "published": "2026-02-19",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.17096v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.18514v1",
      "title": "Trojan Horses in Recruiting: A Red-Teaming Case Study on Indirect Prompt Injection in Standard vs. Reasoning Models",
      "authors": [
        "Manuel Wirth"
      ],
      "summary": "As Large Language Models (LLMs) are increasingly integrated into automated decision-making pipelines, specifically within Human Resources (HR), the security implications of Indirect Prompt Injection (IPI) become critical. While a prevailing hypothesis posits that \"Reasoning\" or \"Chain-of-Thought\" Models possess safety advantages due to their ability to self-correct, emerging research suggests these capabilities may enable more sophisticated alignment failures. This qualitative Red-Teaming case s",
      "published": "2026-02-19",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.18514v1",
      "matched_keyword": "responsible AI",
      "source": "arxiv"
    },
    {
      "id": "2602.17053v3",
      "title": "RFEval: Benchmarking Reasoning Faithfulness under Counterfactual Reasoning Intervention in Large Reasoning Models",
      "authors": [
        "Yunseok Han",
        "Yejoon Lee",
        "Jaeyoung Do"
      ],
      "summary": "Large Reasoning Models (LRMs) exhibit strong performance, yet often produce rationales that sound plausible but fail to reflect their true decision process, undermining reliability and trust. We introduce a formal framework for reasoning faithfulness, defined by two testable conditions: stance consistency (a coherent stance linking reasoning to answer) and causal influence (the stated reasoning causally drives the answer under output-level interventions), explicitly decoupled from accuracy. To o",
      "published": "2026-02-19",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "link": "https://arxiv.org/abs/2602.17053v3",
      "matched_keyword": "trustworthy AI",
      "source": "arxiv"
    },
    {
      "id": "2602.16140v1",
      "title": "Human-AI Collaboration in Large Language Model-Integrated Building Energy Management Systems: The Role of User Domain Knowledge and AI Literacy",
      "authors": [
        "Wooyoung Jung",
        "Kahyun Jeon",
        "Prosper Babon-Ayeng"
      ],
      "summary": "This study aimed to comprehend how user domain knowledge and artificial intelligence (AI) literacy impact the effective use of human-AI interactive building energy management system (BEMS). While prior studies have investigated the potential of integrating large language models (LLMs) into BEMS or building energy modeling, very few studies have examined how user interact with such systems. We conducted a systematic role-playing experiment, where 85 human subjects interacted with an advanced gene",
      "published": "2026-02-18",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16140v1",
      "matched_keyword": "human-AI collaboration",
      "source": "arxiv"
    },
    {
      "id": "2602.16844v1",
      "title": "Overseeing Agents Without Constant Oversight: Challenges and Opportunities",
      "authors": [
        "Madeleine Grunde-McLaughlin",
        "Hussein Mozannar",
        "Maya Murad",
        "Jingya Chen",
        "Saleema Amershi"
      ],
      "summary": "To enable human oversight, agentic AI systems often provide a trace of reasoning and action steps. Designing traces to have an informative, but not overwhelming, level of detail remains a critical challenge. In three user studies on a Computer User Agent, we investigate the utility of basic action traces for verification, explore three alternatives via design probes, and test a novel interface's impact on error finding in question-answering tasks. As expected, we find that current practices are ",
      "published": "2026-02-18",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16844v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    },
    {
      "id": "2602.16812v1",
      "title": "NeuDiff Agent: A Governed AI Workflow for Single-Crystal Neutron Crystallography",
      "authors": [
        "Zhongcan Xiao",
        "Leyi Zhang",
        "Guannan Zhang",
        "Xiaoping Wang"
      ],
      "summary": "Large-scale facilities increasingly face analysis and reporting latency as the limiting step in scientific throughput, particularly for structurally and magnetically complex samples that require iterative reduction, integration, refinement, and validation. To improve time-to-result and analysis efficiency, NeuDiff Agent is introduced as a governed, tool-using AI workflow for TOPAZ at the Spallation Neutron Source that takes instrument data products through reduction, integration, refinement, and",
      "published": "2026-02-18",
      "categories": [
        "cs.AI"
      ],
      "link": "https://arxiv.org/abs/2602.16812v1",
      "matched_keyword": "agentic AI",
      "source": "arxiv"
    }
  ],
  "semantic_scholar": [
    {
      "id": "527519dd69b8ad85a09b642b62be3ea2a8b00b55",
      "title": "Deriving Instructional Insights from Human-LLM Co-Evaluation of Student Collaboration in Data-Centric Programming",
      "authors": [
        "Marshall An",
        "Christine Kwon",
        "Yoonjae Lee",
        "Ji-Hyeon Hur",
        "Dongho Lee"
      ],
      "summary": "This quasi-experimental study integrates a large language model (LLM) with expert qualitative analysis to examine how instructional design variations in computer-supported collaborative learning (CSCL) shape collaboration in data-centric programming. We collected 73 team transcripts from two contrasting CSCL designs deployed across five course offerings: a closed-ended variant with prescribed solution paths and auto-graded milestones, and an open-ended variant supporting exploratory tasks with m",
      "published": "2026-02-17",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/527519dd69b8ad85a09b642b62be3ea2a8b00b55",
      "matched_keyword": "LLM qualitative analysis",
      "source": "semantic_scholar"
    },
    {
      "id": "8fae2c3f7f1f69a60ba18e320af041317bb2609b",
      "title": "Zero-shot stance detection in practice: insights on training, prompting, and decoding with a capable lightweight LLM",
      "authors": [
        "Rachith Aiyappa",
        "Shruthi Senthilmani",
        "Jisun An",
        "Haewoon Kwak",
        "Yong-Yeol Ahn"
      ],
      "summary": "We investigate the performance of Large Language Model (LLM)-based zero-shot stance detection on tweets. Using FlanT5-XXL, an instruction-tuned open-source LLM, with the SemEval 2016 Tasks 6A, 6B, and P-Stance datasets, we analyze how its performance varies under different prompts and decoding strategies, as well as potential model biases. We show that the zero-shot approach can match or outperform state-of-the-art methods, including fine-tuned models. Additionally, we provide practical insights",
      "published": "2026-02-12",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/8fae2c3f7f1f69a60ba18e320af041317bb2609b",
      "matched_keyword": "LLM qualitative analysis",
      "source": "semantic_scholar"
    },
    {
      "id": "b901ef580574dc6b16cc2a61f56802e781b7aeff",
      "title": "Testing LLM Diagnostics in Endodontics: The Impact of Linguistic Variation on Unseen Cases.",
      "authors": [
        "Itrat Batool",
        "N. Naved",
        "F. Umer"
      ],
      "summary": "AIM\nTo assess the diagnostic performance of two language models, GPT-5 Plus and Gemini 2.5 Flash using a curated benchmark dataset of unseen endodontic and restorative dentistry related clinical case scenarios and the linguistic variations introduced around the original dataset. Additionally, a descriptive qualitative analysis was performed on a subset of cases to evaluate the quality of reasoning generated by both models.\n\n\nMETHODOLOGY\nOne hundred single best answer MCQs were generated using st",
      "published": "2026-02-05",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/b901ef580574dc6b16cc2a61f56802e781b7aeff",
      "matched_keyword": "LLM qualitative analysis",
      "source": "semantic_scholar"
    },
    {
      "id": "b7a0a1d5d16fc1994c2242878653906ba015455b",
      "title": "LeagueBot: A Voice LLM Companion of Cognitive and Emotional Support for Novice Players in Competitive Games",
      "authors": [
        "Jungmin Lee",
        "Inhee Cho",
        "Youngjae Yoo"
      ],
      "summary": "Competitive games pose steep learning curves and strong social pressures, often discouraging novice players and limiting sustained engagement. To address these challenges, this study introduces LeagueBot, a large language model-based voice chatbot designed to provide both informational and emotional support during live gameplay in league of legends, one of the most competitive multiplayer online battle arena games. In a within-subjects experiment with 33 novice players, LeagueBot was found to re",
      "published": "2026-02-01",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/b7a0a1d5d16fc1994c2242878653906ba015455b",
      "matched_keyword": "LLM qualitative analysis",
      "source": "semantic_scholar"
    },
    {
      "id": "5eb71f6e5f5bf8b1f7299601df0eb309576edc96",
      "title": "How topic content shapes LLM personality-tailored persuasion: semantic anchoring and topic stereotype effects",
      "authors": [
        "Shuang Xu",
        "Zili Zhou",
        "Nan Zhao"
      ],
      "summary": "Large language models (LLMs) have shown promise in generating personality-tailored persuasive messages, yet their effectiveness remains inconsistent across contexts. This research systematically investigated how the characteristics of recommended products or actions shapes the efficacy of LLM- generated personality-tailored persuasion through three experimental studies (N = 618). Study 1 revealed that personality-matching effects were limited and inconsistent when the core features of the recomm",
      "published": "2026-01-30",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/5eb71f6e5f5bf8b1f7299601df0eb309576edc96",
      "matched_keyword": "LLM qualitative analysis",
      "source": "semantic_scholar"
    },
    {
      "id": "1259e54ca5d2257d44a95569108df1b7ceedbb95",
      "title": "Preclinical basic research of Majuchuanke oral liquid",
      "authors": [
        "Cheng-Jun Yuan"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/1259e54ca5d2257d44a95569108df1b7ceedbb95",
      "matched_keyword": "author:Amershi, Saleema",
      "source": "semantic_scholar"
    },
    {
      "id": "9d0053ad515444e29ff6203da5654982e015ae18",
      "title": "The changes of cardiopulmonary function and the correlation with the ratios of regulatory T cells in OA rats",
      "authors": [
        "Cheng-Jun Yuan"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/9d0053ad515444e29ff6203da5654982e015ae18",
      "matched_keyword": "author:Amershi, Saleema",
      "source": "semantic_scholar"
    },
    {
      "id": "5f95c4bf2c5248098331302ef8b30e5ca08d8c5d",
      "title": "Additive Kunststoffverarbeitung @ MedTech",
      "authors": [
        "M. Eblenkamp",
        "F. Bauer"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/5f95c4bf2c5248098331302ef8b30e5ca08d8c5d",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "8aae4b770177f64faab5b24487b39bf817b50806",
      "title": "Biokompatible Integration von IoT-Elektronik in Kunststoffbauteile",
      "authors": [
        "V. Werner",
        "M. Eblenkamp"
      ],
      "summary": "",
      "published": "2026",
      "citations": 1,
      "link": "https://www.semanticscholar.org/paper/8aae4b770177f64faab5b24487b39bf817b50806",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "d9e7725ae591d649ef42e2fad07ee503429ab5f3",
      "title": "Additive Fertigung in der Lehre und Ausbildung",
      "authors": [
        "Stefan Leonhardt",
        "M. Eblenkamp"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/d9e7725ae591d649ef42e2fad07ee503429ab5f3",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "596f0df250ccf835c7da32692fa991835ef81416",
      "title": "IoT & Werkstoffe: HF-Eigenschaften medizinischer Kunststoffe",
      "authors": [
        "V. Werner",
        "M. Zeppenfeld",
        "M. Eblenkamp"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/596f0df250ccf835c7da32692fa991835ef81416",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    },
    {
      "id": "87a61c6d1df62777f8fa7c1835b05c7d1dbaebdd",
      "title": "Schichtweise zu lebensnaher Biomimikry: Hochfunktionsintegrierte Kunststoffsysteme für die zellbasierte Labormedizin",
      "authors": [
        "M. Eblenkamp",
        "Katharina Düregger",
        "Stefan Leonhardt"
      ],
      "summary": "",
      "published": "2026",
      "citations": 0,
      "link": "https://www.semanticscholar.org/paper/87a61c6d1df62777f8fa7c1835b05c7d1dbaebdd",
      "matched_keyword": "author:Wu, Tongshuang",
      "source": "semantic_scholar"
    }
  ],
  "hackernews": [
    {
      "id": "47083145",
      "title": "An AI Agent Published a Hit Piece on Me – The Operator Came Forward",
      "link": "https://theshamblog.com/an-ai-agent-wrote-a-hit-piece-on-me-part-4/",
      "hn_link": "https://news.ycombinator.com/item?id=47083145",
      "points": 534,
      "comments": 501,
      "published": "2026-02-20",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47096253",
      "title": "Claws are now a new layer on top of LLM agents",
      "link": "https://twitter.com/karpathy/status/2024987174077432126",
      "hn_link": "https://news.ycombinator.com/item?id=47096253",
      "points": 412,
      "comments": 936,
      "published": "2026-02-21",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47092203",
      "title": "Every company building your AI assistant is now an ad company",
      "link": "https://juno-labs.com/blogs/every-company-building-your-ai-assistant-is-an-ad-company",
      "hn_link": "https://news.ycombinator.com/item?id=47092203",
      "points": 315,
      "comments": 170,
      "published": "2026-02-20",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47100232",
      "title": "zclaw: personal AI assistant in under 888 KB, running on an ESP32",
      "link": "https://github.com/tnm/zclaw",
      "hn_link": "https://news.ycombinator.com/item?id=47100232",
      "points": 282,
      "comments": 147,
      "published": "2026-02-21",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47149586",
      "title": "Show HN: A real-time strategy game that AI agents can play",
      "link": "https://llmskirmish.com/",
      "hn_link": "https://news.ycombinator.com/item?id=47149586",
      "points": 205,
      "comments": 72,
      "published": "2026-02-25",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47140322",
      "title": "Show HN: Emdash – Open-source agentic development environment",
      "link": "https://github.com/generalaction/emdash",
      "hn_link": "https://news.ycombinator.com/item?id=47140322",
      "points": 199,
      "comments": 70,
      "published": "2026-02-24",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47096466",
      "title": "Cord: Coordinating Trees of AI Agents",
      "link": "https://www.june.kim/cord",
      "hn_link": "https://news.ycombinator.com/item?id=47096466",
      "points": 154,
      "comments": 81,
      "published": "2026-02-21",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47073947",
      "title": "Measuring AI agent autonomy in practice",
      "link": "https://www.anthropic.com/research/measuring-agent-autonomy",
      "hn_link": "https://news.ycombinator.com/item?id=47073947",
      "points": 119,
      "comments": 50,
      "published": "2026-02-19",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47117169",
      "title": "Aqua: A CLI message tool for AI agents",
      "link": "https://github.com/quailyquaily/aqua",
      "hn_link": "https://news.ycombinator.com/item?id=47117169",
      "points": 76,
      "comments": 32,
      "published": "2026-02-23",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47077676",
      "title": "Productivity gains from AI coding assistants haven’t budged past 10% – survey",
      "link": "https://shiftmag.dev/this-cto-says-93-of-developers-use-ai-but-productivity-is-still-10-8013/",
      "hn_link": "https://news.ycombinator.com/item?id=47077676",
      "points": 76,
      "comments": 92,
      "published": "2026-02-19",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47117408",
      "title": "Agentic Software Engineering Book",
      "link": "https://agenticse-book.github.io/",
      "hn_link": "https://news.ycombinator.com/item?id=47117408",
      "points": 64,
      "comments": 35,
      "published": "2026-02-23",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47151598",
      "title": "Launch HN: TeamOut (YC W22) – AI agent for planning company retreats",
      "link": "https://app.teamout.com/ai",
      "hn_link": "https://news.ycombinator.com/item?id=47151598",
      "points": 50,
      "comments": 57,
      "published": "2026-02-25",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47131689",
      "title": "NIST Seeking Public Comment on AI Agent Security (Deadline: March 9, 2026)",
      "link": "https://www.federalregister.gov/documents/2026/01/08/2026-00206/request-for-information-regarding-security-considerations-for-artificial-intelligence-agents",
      "hn_link": "https://news.ycombinator.com/item?id=47131689",
      "points": 49,
      "comments": 13,
      "published": "2026-02-24",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47127532",
      "title": "Ask HN: How do you know if AI agents will choose your tool?",
      "link": "https://news.ycombinator.com/item?id=47127532",
      "hn_link": "https://news.ycombinator.com/item?id=47127532",
      "points": 33,
      "comments": 23,
      "published": "2026-02-23",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47105637",
      "title": "Amazon blames human employees for an AI coding agent's mistake",
      "link": "https://www.theverge.com/ai-artificial-intelligence/882005/amazon-blames-human-employees-for-an-ai-coding-agents-mistake",
      "hn_link": "https://news.ycombinator.com/item?id=47105637",
      "points": 24,
      "comments": 8,
      "published": "2026-02-21",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47139110",
      "title": "Show HN: Pilo – open-source agentic web automation engine by Mozilla",
      "link": "https://news.ycombinator.com/item?id=47139110",
      "hn_link": "https://news.ycombinator.com/item?id=47139110",
      "points": 18,
      "comments": 3,
      "published": "2026-02-24",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47096131",
      "title": "Show HN: Agent Passport – OAuth-like identity verification for AI agents",
      "link": "https://news.ycombinator.com/item?id=47096131",
      "hn_link": "https://news.ycombinator.com/item?id=47096131",
      "points": 13,
      "comments": 11,
      "published": "2026-02-21",
      "matched_keyword": "AI agent",
      "source": "hackernews"
    },
    {
      "id": "47074851",
      "title": "Open Mercato: An Agentic-Ready, Developer-First CRM/ERP Framework (TypeScript)",
      "link": "https://github.com/open-mercato/open-mercato",
      "hn_link": "https://news.ycombinator.com/item?id=47074851",
      "points": 9,
      "comments": 1,
      "published": "2026-02-19",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47156513",
      "title": "Andrej Karpathy: agentic AI coding has changed the world unrecognizably",
      "link": "https://twitter.com/karpathy/status/2026731645169185220",
      "hn_link": "https://news.ycombinator.com/item?id=47156513",
      "points": 8,
      "comments": 3,
      "published": "2026-02-25",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47126168",
      "title": "Writing about Agentic Engineering Patterns",
      "link": "https://simonwillison.net/2026/Feb/23/agentic-engineering-patterns/",
      "hn_link": "https://news.ycombinator.com/item?id=47126168",
      "points": 6,
      "comments": 0,
      "published": "2026-02-23",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47088813",
      "title": "Show HN: Tropes.fyi – Name and shame AI writing",
      "link": "https://tropes.fyi/",
      "hn_link": "https://news.ycombinator.com/item?id=47088813",
      "points": 5,
      "comments": 3,
      "published": "2026-02-20",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "47111179",
      "title": "Show HN: ByePhone- An AI assistant to automate tedious phone calls",
      "link": "https://byephone.io/",
      "hn_link": "https://news.ycombinator.com/item?id=47111179",
      "points": 5,
      "comments": 3,
      "published": "2026-02-22",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47150319",
      "title": "From hackathon to company-wide AI assistant",
      "link": "https://engineering.remote.com/blog/sherlock/",
      "hn_link": "https://news.ycombinator.com/item?id=47150319",
      "points": 5,
      "comments": 0,
      "published": "2026-02-25",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47151278",
      "title": "Show HN: A live Python REPL with an agentic LLM that edits and evaluates code",
      "link": "https://news.ycombinator.com/item?id=47151278",
      "hn_link": "https://news.ycombinator.com/item?id=47151278",
      "points": 4,
      "comments": 4,
      "published": "2026-02-25",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47160192",
      "title": "Show HN: RubyLLM:Agents – A Rails engine for building and monitoring LLM agents",
      "link": "https://github.com/adham90/ruby_llm-agents",
      "hn_link": "https://news.ycombinator.com/item?id=47160192",
      "points": 4,
      "comments": 0,
      "published": "2026-02-26",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47154355",
      "title": "Smith: The Secure Open Source Multi-User AI Assistant Framework",
      "link": "https://github.com/sibyllinesoft/smith-core",
      "hn_link": "https://news.ycombinator.com/item?id=47154355",
      "points": 4,
      "comments": 1,
      "published": "2026-02-25",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47137236",
      "title": "Show HN: AI phone assistant that became a lifeline for people who can't speak",
      "link": "https://mio.gg/",
      "hn_link": "https://news.ycombinator.com/item?id=47137236",
      "points": 4,
      "comments": 1,
      "published": "2026-02-24",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47075973",
      "title": "Show HN: SageOx – The Hivemind for Agentic Engineering",
      "link": "https://sageox.ai/blog/introducing-sageox",
      "hn_link": "https://news.ycombinator.com/item?id=47075973",
      "points": 4,
      "comments": 3,
      "published": "2026-02-19",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47084135",
      "title": "Agentic Internet Protocol (AIP), an agent-only web built from small text pages",
      "link": "https://github.com/Tylersuard/aip-spec",
      "hn_link": "https://news.ycombinator.com/item?id=47084135",
      "points": 4,
      "comments": 1,
      "published": "2026-02-20",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47097288",
      "title": "How to Use Goosetown for Parallel Agentic Engineering",
      "link": "https://block.github.io/goose/blog/2026/02/19/gastown-explained-goosetown/",
      "hn_link": "https://news.ycombinator.com/item?id=47097288",
      "points": 4,
      "comments": 0,
      "published": "2026-02-21",
      "matched_keyword": "agentic",
      "source": "hackernews"
    },
    {
      "id": "47134473",
      "title": "Agents of Chaos: Breaches of trust in autonomous LLM agents",
      "link": "https://arxiv.org/abs/2602.20021",
      "hn_link": "https://news.ycombinator.com/item?id=47134473",
      "points": 3,
      "comments": 1,
      "published": "2026-02-24",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47139556",
      "title": "Be Careful with LLM \"Agents\"",
      "link": "https://maurycyz.com/misc/sandbox_llms/",
      "hn_link": "https://news.ycombinator.com/item?id=47139556",
      "points": 3,
      "comments": 0,
      "published": "2026-02-24",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47148537",
      "title": "Show HN: Chorus – Open-source Agent and human collaboration platform on AI-DLC",
      "link": "https://github.com/Chorus-AIDLC/Chorus",
      "hn_link": "https://news.ycombinator.com/item?id=47148537",
      "points": 3,
      "comments": 2,
      "published": "2026-02-25",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47153034",
      "title": "Show HN: TMDD – continuous threat modelling that makes your code more secure",
      "link": "https://github.com/attasec/tmdd",
      "hn_link": "https://news.ycombinator.com/item?id=47153034",
      "points": 3,
      "comments": 0,
      "published": "2026-02-25",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47130703",
      "title": "MemoTrail v0.3.0 – Persistent memory for AI coding assistants (now with Cursor)",
      "link": "https://github.com/HalilHopa-Datatent/memotrail",
      "hn_link": "https://news.ycombinator.com/item?id=47130703",
      "points": 3,
      "comments": 1,
      "published": "2026-02-23",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47133402",
      "title": "We scaled our AI Assistant to use virtually unlimited tools",
      "link": "https://gaia-fork-oz2l3yz60-gaia-2.vercel.app/blog/how-tool-calling-works",
      "hn_link": "https://news.ycombinator.com/item?id=47133402",
      "points": 3,
      "comments": 0,
      "published": "2026-02-24",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47159542",
      "title": "Show HN: Edictum – Runtime governance for LLM agent tool calls",
      "link": "https://news.ycombinator.com/item?id=47159542",
      "hn_link": "https://news.ycombinator.com/item?id=47159542",
      "points": 2,
      "comments": 0,
      "published": "2026-02-25",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47152579",
      "title": "BrAIn: Persistent, Human-Inspired Memory for LLM Agents",
      "link": "https://github.com/glthr/brAIn",
      "hn_link": "https://news.ycombinator.com/item?id=47152579",
      "points": 2,
      "comments": 0,
      "published": "2026-02-25",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47145928",
      "title": "Show HN: VeriContext – Preventing Stale Documentation for LLM Agents",
      "link": "https://github.com/amsminn/vericontext",
      "hn_link": "https://news.ycombinator.com/item?id=47145928",
      "points": 2,
      "comments": 0,
      "published": "2026-02-25",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47141373",
      "title": "Agents of Chaos: a red team study of autonomous LLM agents with full access",
      "link": "https://www.researchgate.net/publication/401123335_Agents_of_Chaos",
      "hn_link": "https://news.ycombinator.com/item?id=47141373",
      "points": 2,
      "comments": 0,
      "published": "2026-02-24",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47081023",
      "title": "History of self-sustaining LLM agents in real-life workflows",
      "link": "https://spacelatte.notion.site/I-Built-LLM-Agents-for-Work-Before-We-Started-Calling-Them-Agents-30382472a8e480df9cd9c93b81141e2f",
      "hn_link": "https://news.ycombinator.com/item?id=47081023",
      "points": 2,
      "comments": 0,
      "published": "2026-02-19",
      "matched_keyword": "LLM agent",
      "source": "hackernews"
    },
    {
      "id": "47147675",
      "title": "AI_ATTRIBUTION.md: A Standard for Tracking Creative Control in Human-AI Coding",
      "link": "https://ismethandzic.com/blog/ai_attribution_md/",
      "hn_link": "https://news.ycombinator.com/item?id=47147675",
      "points": 2,
      "comments": 2,
      "published": "2026-02-25",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "47159248",
      "title": "Say No to Human-AI Workflow Segregation",
      "link": "https://keleshev.com/say-no-to-human-ai-workflow-segregation",
      "hn_link": "https://news.ycombinator.com/item?id=47159248",
      "points": 2,
      "comments": 0,
      "published": "2026-02-25",
      "matched_keyword": "human-AI",
      "source": "hackernews"
    },
    {
      "id": "47162405",
      "title": "Show HN: Nullroom.io – Experimental, stateless P2P messaging and file sharing",
      "link": "https://www.nullroom.io/",
      "hn_link": "https://news.ycombinator.com/item?id=47162405",
      "points": 2,
      "comments": 0,
      "published": "2026-02-26",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47151334",
      "title": "UAA – A spec for AI and Human coding collaboration",
      "link": "https://news.ycombinator.com/item?id=47151334",
      "hn_link": "https://news.ycombinator.com/item?id=47151334",
      "points": 2,
      "comments": 0,
      "published": "2026-02-25",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47145905",
      "title": "Show HN: I solo-validated Fed learning at 10M nodes with 50% Byzantine tolerance",
      "link": "https://github.com/rwilliamspbg-ops/Sovereign_Map_Federated_Learning/releases/tag/v1.0.0",
      "hn_link": "https://news.ycombinator.com/item?id=47145905",
      "points": 2,
      "comments": 0,
      "published": "2026-02-25",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47091481",
      "title": "Show HN: Preact Health",
      "link": "https://app.preacthealth.com",
      "hn_link": "https://news.ycombinator.com/item?id=47091481",
      "points": 2,
      "comments": 0,
      "published": "2026-02-20",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47087332",
      "title": "Show HN: Remote-OpenCode – Control your AI coding assistant from Discord",
      "link": "https://github.com/RoundTable02/remote-opencode",
      "hn_link": "https://news.ycombinator.com/item?id=47087332",
      "points": 2,
      "comments": 2,
      "published": "2026-02-20",
      "matched_keyword": "AI assistant",
      "source": "hackernews"
    },
    {
      "id": "47162675",
      "title": "Demo of an indie AI collaboration app – beyond Codex and Claude Code desktop",
      "link": "https://news.ycombinator.com/item?id=47162675",
      "hn_link": "https://news.ycombinator.com/item?id=47162675",
      "points": 1,
      "comments": 1,
      "published": "2026-02-26",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47088361",
      "title": "Software Collaboration in the AI Age",
      "link": "https://spiess.dev/blog/software-collaboration-in-the-ai-age",
      "hn_link": "https://news.ycombinator.com/item?id=47088361",
      "points": 1,
      "comments": 0,
      "published": "2026-02-20",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47138456",
      "title": "Show HN: OpenPDB – Generate AI agents with real personalities",
      "link": "https://github.com/gitsual/openpdb",
      "hn_link": "https://news.ycombinator.com/item?id=47138456",
      "points": 1,
      "comments": 0,
      "published": "2026-02-24",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    },
    {
      "id": "47157331",
      "title": "Show HN: Upjack – Declarative framework for building apps over MCP",
      "link": "https://github.com/NimbleBrainInc/upjack",
      "hn_link": "https://news.ycombinator.com/item?id=47157331",
      "points": 1,
      "comments": 0,
      "published": "2026-02-25",
      "matched_keyword": "AI collaboration",
      "source": "hackernews"
    }
  ],
  "reddit": [],
  "blogs": [
    {
      "名称": "Anthropic Research",
      "链接": "https://anthropic.com/research",
      "说明": "Claude生态，MCP协议，human-AI交互理念"
    },
    {
      "名称": "OpenAI Research",
      "链接": "https://openai.com/research",
      "说明": "GPT系列、agent框架、ChatGPT产品迭代"
    },
    {
      "名称": "Google DeepMind",
      "链接": "https://deepmind.google/research",
      "说明": "Gemini、agent研究、AI safety"
    },
    {
      "名称": "Microsoft Research Blog",
      "链接": "https://microsoft.com/en-us/research/blog",
      "说明": "HAX Toolkit, Human-AI Interaction Guidelines, Copilot"
    },
    {
      "名称": "Meta AI (FAIR)",
      "链接": "https://ai.meta.com/research",
      "说明": "Llama开源生态"
    },
    {
      "名称": "Amazon Science",
      "链接": "https://amazon.science",
      "说明": "应用型AI研究"
    },
    {
      "名称": "Apple Machine Learning",
      "链接": "https://machinelearning.apple.com",
      "说明": "设备端AI、隐私AI"
    },
    {
      "名称": "Hugging Face Blog",
      "链接": "https://huggingface.co/blog",
      "说明": "开源模型、工具、社区趋势"
    },
    {
      "名称": "LangChain Blog",
      "链接": "https://blog.langchain.dev",
      "说明": "Agent框架生态风向标"
    }
  ],
  "newsletters": [
    {
      "名称": "Simon Willison's Blog",
      "链接": "https://simonwillison.net",
      "作者": "Simon Willison",
      "说明": "LLM生态最全面的实践者视角"
    },
    {
      "名称": "Ahead of AI",
      "链接": "https://magazine.sebastianraschka.com",
      "作者": "Sebastian Raschka",
      "说明": "LLM研究深度解读"
    },
    {
      "名称": "Interconnects",
      "链接": "https://interconnects.ai",
      "作者": "Nathan Lambert",
      "说明": "RLHF/对齐方向"
    },
    {
      "名称": "Latent Space",
      "链接": "https://latent.space",
      "作者": "Swyx & Alessio",
      "说明": "AI工程师视角，agent和tooling"
    },
    {
      "名称": "MIT Technology Review",
      "链接": "https://technologyreview.com",
      "作者": "编辑团队",
      "说明": "日刊科技新闻"
    },
    {
      "名称": "The Batch",
      "链接": "https://deeplearning.ai/the-batch",
      "作者": "Andrew Ng",
      "说明": "AI新闻周报"
    },
    {
      "名称": "Import AI",
      "链接": "https://importai.substack.com",
      "作者": "Jack Clark",
      "说明": "偏policy和大趋势"
    },
    {
      "名称": "阮一峰的网络日志",
      "链接": "https://ruanyifeng.com/blog",
      "作者": "阮一峰",
      "说明": "中文技术圈信号"
    }
  ],
  "researchers": [
    {
      "姓名": "Anthropic",
      "链接": "https://x.com/AnthropicAI",
      "平台": "X",
      "说明": "AI safety and research company"
    },
    {
      "姓名": "Claude",
      "链接": "https://x.com/claudeai",
      "平台": "X",
      "说明": "safe, accurate, and secure"
    },
    {
      "姓名": "OpenAI",
      "链接": "https://x.com/OpenAI",
      "平台": "X",
      "说明": "artificial general intelligence benefits all of humanity"
    },
    {
      "姓名": "Sherry Tongshuang Wu",
      "链接": "https://x.com/tongshuangwu",
      "平台": "X",
      "说明": "HCI×NLP，human-AI interaction"
    },
    {
      "姓名": "Diyi Yang",
      "链接": "https://x.com/Diyi_Yang",
      "平台": "X",
      "说明": "Human-AI"
    },
    {
      "姓名": "Ziang Xiao",
      "链接": "https://x.com/ZiangXiao",
      "平台": "X",
      "说明": "AI4SocialScience, Model Evaluation, Information Seeking"
    },
    {
      "姓名": "Mark Dredze",
      "链接": "https://x.com/mdredze",
      "平台": "X",
      "说明": "NLP"
    },
    {
      "姓名": "Wesley Hanwen Deng",
      "链接": "https://x.com/wes_deng",
      "平台": "X",
      "说明": "Human-AI"
    },
    {
      "姓名": "Mina Lee",
      "链接": "https://x.com/MinaLee__",
      "平台": "X",
      "说明": "Human-AI collaborative writing"
    },
    {
      "姓名": "Jentse Huang",
      "链接": "https://x.com/JentseHuang",
      "平台": "X",
      "说明": "LLM + Social Science, Multi-Agent, AI Fairness"
    },
    {
      "姓名": "Toby Jia-Jun Li",
      "链接": "https://x.com/TobyJLi",
      "平台": "X",
      "说明": "End-user programming, human-AI systems"
    },
    {
      "姓名": "Dakuo Wang",
      "链接": "https://x.com/dakuowang",
      "平台": "X",
      "说明": "Human-AI collaboration, CSCW"
    },
    {
      "姓名": "Percy Liang",
      "链接": "https://x.com/percyliang",
      "平台": "X",
      "说明": "LLM evaluation框架"
    },
    {
      "姓名": "Michael Bernstein",
      "链接": "https://x.com/msbernst",
      "平台": "X",
      "说明": "Generative agents, social computing"
    },
    {
      "姓名": "Simon Willison",
      "链接": "https://x.com/simonw",
      "平台": "X",
      "说明": "LLM工具生态最佳信息源"
    },
    {
      "姓名": "Joon Sung Park",
      "链接": "https://x.com/joon_s_pk",
      "平台": "X",
      "说明": "Social Simulations"
    },
    {
      "姓名": "Andrej Karpathy",
      "链接": "https://x.com/karpathy",
      "平台": "X",
      "说明": "深度技术解读"
    },
    {
      "姓名": "Swyx",
      "链接": "https://x.com/swyx",
      "平台": "X",
      "说明": "AI工程/agent生态trend"
    },
    {
      "姓名": "Saleema Amershi",
      "链接": "https://x.com/SaleemaAmershi",
      "平台": "X",
      "说明": "Human-AI Interaction Guidelines"
    },
    {
      "姓名": "Q. Vera Liao",
      "链接": "https://x.com/QVeraLiao",
      "平台": "X",
      "说明": "Explainable AI, responsible AI in HCI"
    },
    {
      "姓名": "Xiang 'Anthony' Chen",
      "链接": "https://x.com/_xiang_chen_",
      "平台": "X",
      "说明": "Interactive AI systems"
    }
  ],
  "seminars": [
    {
      "名称": "Stanford HAI Seminar",
      "链接": "https://hai.stanford.edu/events",
      "机构": "Stanford",
      "频率": "每周",
      "标签": "HCI,AI",
      "说明": "Human-Centered AI 核心 seminar，覆盖 AI policy、education、human-AI interaction。YouTube 有录播"
    },
    {
      "名称": "Stanford CS547 HCI Seminar",
      "链接": "https://hci.stanford.edu/courses/cs547/",
      "机构": "Stanford CS",
      "频率": "每周",
      "标签": "HCI",
      "说明": "HCI 方向专题 seminar，常有 human-AI interaction 相关 talk"
    },
    {
      "名称": "CMU HCII Seminar Series",
      "链接": "https://www.hcii.cmu.edu/news/seminars/upcoming",
      "机构": "CMU HCII",
      "频率": "每周五",
      "标签": "HCI",
      "说明": "HCI 领域最活跃的 seminar 之一。Spring 2026: Sarah Preum, Haoqi Zhang 等"
    },
    {
      "名称": "UMich HCI Seminar",
      "链接": "https://cse.engin.umich.edu/events/all-seminars/hci/",
      "机构": "U Michigan",
      "频率": "不定期",
      "标签": "HCI",
      "说明": "Q. Vera Liao 所在校，HCI + AI 方向"
    },
    {
      "名称": "UMich AI Seminar",
      "链接": "https://cse.engin.umich.edu/events/all-seminars/artificial-intelligence/",
      "机构": "U Michigan",
      "频率": "不定期",
      "标签": "AI",
      "说明": "NLP + AI 方向，self-supervised learning、LLM"
    },
    {
      "名称": "MIT AI for Society Seminar",
      "链接": "https://ai4society.mit.edu/seminar/",
      "机构": "MIT",
      "频率": "不定期",
      "标签": "AI,HCI",
      "说明": "AI 与社会交叉，法律、政策、human-AI 角度"
    },
    {
      "名称": "MSR People-Centric AI Events",
      "链接": "https://www.microsoft.com/en-us/research/theme/people-centric-ai/events/",
      "机构": "Microsoft Research",
      "频率": "不定期",
      "标签": "HCI,AI",
      "说明": "Human-AI interaction、Copilot 生态、HAX Toolkit"
    },
    {
      "名称": "Berkeley NLP Seminar",
      "链接": "https://www.ischool.berkeley.edu/events/nlp",
      "机构": "UC Berkeley",
      "频率": "双周",
      "标签": "AI",
      "说明": "NLP 最新研究 invited talks"
    },
    {
      "名称": "Rice AI Seminar Series",
      "链接": "https://kenkennedy.rice.edu/ai-seminar",
      "机构": "Rice University",
      "频率": "不定期",
      "标签": "AI",
      "说明": "AI/ML、fairness 方向"
    },
    {
      "名称": "Georgia Tech HCI Events",
      "链接": "https://mshci.gatech.edu/events",
      "机构": "Georgia Tech",
      "频率": "不定期",
      "标签": "HCI",
      "说明": "People-centered tech approach"
    },
    {
      "名称": "UIUC CIRSS Speaker Series",
      "链接": "https://cirss.ischool.illinois.edu/",
      "机构": "UIUC iSchool",
      "频率": "学期制",
      "标签": "AI,HCI",
      "说明": "Spring 2025 主题: Generative AI and the Future of Research"
    },
    {
      "名称": "Stanford HAI YouTube",
      "链接": "https://www.youtube.com/@StanfordHAI",
      "机构": "Stanford",
      "频率": "录播",
      "标签": "HCI,AI",
      "说明": "所有 HAI seminar 录播，包括 AI+Education Summit"
    },
    {
      "名称": "ACM SIGCHI YouTube",
      "链接": "https://www.youtube.com/@acmsigchi",
      "机构": "ACM",
      "频率": "录播",
      "标签": "HCI",
      "说明": "CHI/CSCW/UIST 等会议 talk 录播"
    },
    {
      "名称": "Microsoft Research YouTube",
      "链接": "https://www.youtube.com/@MicrosoftResearch",
      "机构": "Microsoft",
      "频率": "录播",
      "标签": "AI,HCI,SE",
      "说明": "MSR seminar 录播"
    },
    {
      "名称": "CMU S3D Software Research Seminar",
      "链接": "https://s3d.cmu.edu/events/index.html",
      "机构": "CMU S3D",
      "频率": "每周一",
      "标签": "SE,AI",
      "说明": "Software research in progress，周一 3:30-5pm，SE + AI 交叉"
    },
    {
      "名称": "UCI ISR Events",
      "链接": "https://isr.uci.edu/events/ext-events.html",
      "机构": "UC Irvine ISR",
      "频率": "不定期",
      "标签": "SE",
      "说明": "Institute for Software Research，SE community 核心"
    },
    {
      "名称": "UCL CREST Open Workshops",
      "链接": "https://www.ucl.ac.uk/crest/crest-open-workshops",
      "机构": "UCL CREST",
      "频率": "不定期",
      "标签": "SE",
      "说明": "SE testing/search-based SE/program analysis"
    },
    {
      "名称": "HumanAISE Workshop",
      "链接": "https://humanai4se.github.io/",
      "机构": "ICSE co-located",
      "频率": "年度",
      "标签": "SE,AI,HCI",
      "说明": "Human-Centered AI for SE，与你研究最直接相关（AI4SE + human-centered）"
    },
    {
      "名称": "AI4SE & SE4AI Workshop",
      "链接": "https://sercuarc.org/ai4se-se4ai-research-application-workshop/",
      "机构": "SERC/Army",
      "频率": "年度",
      "标签": "SE,AI",
      "说明": "系统工程 + AI 交叉，industry + research"
    },
    {
      "名称": "AIware Conference",
      "链接": "https://2025.aiwareconf.org/",
      "机构": "FSE co-located",
      "频率": "年度",
      "标签": "SE,AI",
      "说明": "AI-powered software engineering，keynotes + research track"
    },
    {
      "名称": "AI Coding Summit",
      "链接": "https://aicodingsummit.com/",
      "机构": "GitNation",
      "频率": "年度",
      "标签": "SE,AI",
      "说明": "AI-powered dev tools，Copilot/Cursor 等实践者视角"
    },
    {
      "名称": "MSR Research Talks: AI for SE",
      "链接": "https://www.microsoft.com/en-us/research/video/research-talks-ai-for-software-development/",
      "机构": "Microsoft Research",
      "频率": "录播",
      "标签": "SE,AI",
      "说明": "AI for software development 专题 talks"
    },
    {
      "名称": "GitHub Next / DX Podcast",
      "链接": "https://getdx.com/podcast/",
      "机构": "GitHub/DX",
      "频率": "不定期",
      "标签": "SE,AI",
      "说明": "Developer productivity + AI coding assistants 研究，Eirini Kalliamvakou 等"
    }
  ],
  "podcasts": [
    {
      "名称": "Latent Space Podcast",
      "链接": "https://latent.space",
      "说明": "AI工程最前沿，agent相关讨论"
    },
    {
      "名称": "TWIML AI Podcast",
      "链接": "https://twimlai.com",
      "说明": "学术+工业混合视角"
    },
    {
      "名称": "NeurIPS/CHI 录播",
      "链接": "https://youtube.com",
      "说明": "重要talk的录播"
    }
  ],
  "conferences": [
    {
      "名称": "AAAI 2026",
      "链接": "https://aaai.org",
      "领域": "AI-ML",
      "CCF": "A",
      "Deadline": "2025-08-15",
      "会议日期": "2026-02-20",
      "说明": "综合AI顶会, human-AI collaboration track. Philadelphia, USA"
    },
    {
      "名称": "TEI 2026",
      "链接": "https://tei.acm.org/2026/",
      "领域": "HCI",
      "CCF": "C",
      "Deadline": "2025-09-19",
      "会议日期": "2026-03-08",
      "说明": "Tangible, Embedded, Embodied Interaction. Chicago, USA"
    },
    {
      "名称": "IUI 2026",
      "链接": "https://iui.acm.org",
      "领域": "HCI",
      "CCF": "B",
      "Deadline": "2025-10-10",
      "会议日期": "2026-03-23",
      "说明": "Intelligent User Interfaces. Paphos, Cyprus"
    },
    {
      "名称": "CHI 2026",
      "链接": "https://chi2026.acm.org",
      "领域": "HCI",
      "CCF": "A",
      "Deadline": "2025-09-12",
      "会议日期": "2026-04-26",
      "说明": "ACM顶会, Human-Computer Interaction核心会议. Yokohama, Japan"
    },
    {
      "名称": "ICLR 2026",
      "链接": "https://iclr.cc",
      "领域": "AI-ML",
      "CCF": "A",
      "Deadline": "2025-10-01",
      "会议日期": "2026-04-24",
      "说明": "表示学习顶会, LLM/foundation model前沿. Singapore"
    },
    {
      "名称": "ICSE 2026",
      "链接": "https://conf.researchr.org/home/icse-2026",
      "领域": "SE",
      "CCF": "A",
      "Deadline": "2025-08-01",
      "会议日期": "2026-04-27",
      "说明": "软件工程顶会, AI4SE/SE4AI方向. Milan, Italy"
    },
    {
      "名称": "FAccT 2026",
      "链接": "https://facctconference.org",
      "领域": "Ethics",
      "CCF": "B",
      "Deadline": "2026-01-29",
      "会议日期": "2026-06-03",
      "说明": "Fairness, Accountability, Transparency in AI. Athens, Greece"
    },
    {
      "名称": "HHAI 2026",
      "链接": "https://hhai-conference.org",
      "领域": "HCI",
      "CCF": "C",
      "Deadline": "2026-03-01",
      "会议日期": "2026-06-15",
      "说明": "Hybrid Human-AI Intelligence. Malmö, Sweden"
    },
    {
      "名称": "DIS 2026",
      "链接": "https://dis.acm.org",
      "领域": "HCI",
      "CCF": "B",
      "Deadline": "2026-02-07",
      "会议日期": "2026-06-28",
      "说明": "Designing Interactive Systems"
    },
    {
      "名称": "CSCW 2026",
      "链接": "https://cscw.acm.org",
      "领域": "HCI",
      "CCF": "A",
      "Deadline": "2026-01-15",
      "会议日期": "2026-07-11",
      "说明": "Computer-Supported Cooperative Work. Bergen, Norway"
    },
    {
      "名称": "ICML 2026",
      "链接": "https://icml.cc",
      "领域": "AI-ML",
      "CCF": "A",
      "Deadline": "2026-01-31",
      "会议日期": "2026-07-18",
      "说明": "机器学习顶会. San Francisco, USA"
    },
    {
      "名称": "HCI International 2026",
      "链接": "https://2026.hci.international/",
      "领域": "HCI",
      "CCF": "C",
      "Deadline": "2026-02-28",
      "会议日期": "2026-07-26",
      "说明": "Montreal, Canada. 28th International Conference on HCI"
    },
    {
      "名称": "ACL 2026",
      "链接": "https://www.aclweb.org",
      "领域": "NLP",
      "CCF": "A",
      "Deadline": "2026-02-15",
      "会议日期": "2026-08-01",
      "说明": "NLP顶会, human-LLM interaction相关"
    },
    {
      "名称": "AIES 2026",
      "链接": "https://www.aies-conference.com",
      "领域": "Ethics",
      "CCF": "C",
      "Deadline": "2026-02-18",
      "会议日期": "2026-08-04",
      "说明": "AI, Ethics, and Society"
    },
    {
      "名称": "ASSETS 2026",
      "链接": "https://www.sigaccess.org/assets/",
      "领域": "HCI",
      "CCF": "B",
      "Deadline": "2026-04-15",
      "会议日期": "2026-10-25",
      "说明": "Accessible Computing, AI accessibility"
    },
    {
      "名称": "UIST 2026",
      "链接": "https://uist.acm.org",
      "领域": "HCI",
      "CCF": "A",
      "Deadline": "2026-04-02",
      "会议日期": "2026-10-26",
      "说明": "User Interface Software and Technology. Lisbon, Portugal"
    },
    {
      "名称": "NeurIPS 2026",
      "链接": "https://neurips.cc",
      "领域": "AI-ML",
      "CCF": "A",
      "Deadline": "2026-05-16",
      "会议日期": "2026-12-06",
      "说明": "ML/AI最大顶会, agent/alignment/human-AI"
    },
    {
      "名称": "EMNLP 2026",
      "链接": "https://www.aclweb.org",
      "领域": "NLP",
      "CCF": "A",
      "Deadline": "2026-06-01",
      "会议日期": "2026-12-10",
      "说明": "NLP顶会, empirical methods"
    },
    {
      "名称": "IJCAI 2026",
      "链接": "https://www.ijcai.org",
      "领域": "AI-ML",
      "CCF": "A",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "International Joint Conference on Artificial Intelligence"
    },
    {
      "名称": "KDD 2026",
      "链接": "https://www.kdd.org",
      "领域": "AI-ML",
      "CCF": "A",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "Knowledge Discovery and Data Mining"
    },
    {
      "名称": "WWW 2026",
      "链接": "https://www2026.thewebconf.org",
      "领域": "AI-ML",
      "CCF": "A",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "The Web Conference"
    },
    {
      "名称": "SIGIR 2026",
      "链接": "https://sigir.org",
      "领域": "AI-ML",
      "CCF": "A",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "Information Retrieval"
    },
    {
      "名称": "FSE 2026",
      "链接": "https://conf.researchr.org/home/fse-2026",
      "领域": "SE",
      "CCF": "A",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "Foundations of Software Engineering"
    },
    {
      "名称": "ASE 2026",
      "链接": "https://conf.researchr.org/home/ase-2026",
      "领域": "SE",
      "CCF": "A",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "Automated Software Engineering"
    },
    {
      "名称": "ISSTA 2026",
      "链接": "https://conf.researchr.org/home/issta-2026",
      "领域": "SE",
      "CCF": "A",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "International Symposium on Software Testing and Analysis"
    },
    {
      "名称": "OOPSLA 2026",
      "链接": "https://splashcon.org/",
      "领域": "SE",
      "CCF": "A",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "Object-Oriented Programming, Systems, Languages & Applications"
    },
    {
      "名称": "PLDI 2026",
      "链接": "https://conf.researchr.org/home/pldi-2026",
      "领域": "SE",
      "CCF": "A",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "Programming Language Design and Implementation"
    },
    {
      "名称": "ICPC 2026",
      "链接": "https://conf.researchr.org/home/icpc-2026",
      "领域": "SE",
      "CCF": "B",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "International Conference on Program Comprehension"
    },
    {
      "名称": "NAACL 2026",
      "链接": "https://www.aclweb.org",
      "领域": "NLP",
      "CCF": "B",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "North American Chapter of ACL"
    },
    {
      "名称": "COLING 2026",
      "链接": "https://coling2026.org",
      "领域": "NLP",
      "CCF": "B",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "International Conference on Computational Linguistics"
    },
    {
      "名称": "EACL 2026",
      "链接": "https://www.aclweb.org",
      "领域": "NLP",
      "CCF": "B",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "European Chapter of ACL"
    },
    {
      "名称": "ECML-PKDD 2026",
      "链接": "https://ecmlpkdd.org",
      "领域": "AI-ML",
      "CCF": "B",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "European Conference on Machine Learning"
    },
    {
      "名称": "WSDM 2026",
      "链接": "https://www.wsdm-conference.org",
      "领域": "AI-ML",
      "CCF": "B",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "Web Search and Data Mining"
    },
    {
      "名称": "CIKM 2026",
      "链接": "https://www.cikm.org/",
      "领域": "AI-ML",
      "CCF": "B",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "Conference on Information and Knowledge Management"
    },
    {
      "名称": "UbiComp 2026",
      "链接": "https://ubicomp.org",
      "领域": "HCI",
      "CCF": "A",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "Ubiquitous Computing"
    },
    {
      "名称": "GROUP 2026",
      "链接": "https://programs.sigchi.org/group",
      "领域": "HCI",
      "CCF": "C",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "International Conference on Supporting Group Work"
    },
    {
      "名称": "INTERACT 2026",
      "链接": "https://ifip-tc13.org/interact/",
      "领域": "HCI",
      "CCF": "B",
      "Deadline": "TBD",
      "会议日期": "TBD",
      "说明": "Human-Computer Interaction"
    },
    {
      "名称": "CHI GenAICHI Workshop",
      "链接": "https://sites.google.com/view/genaichi2026",
      "领域": "Workshop",
      "CCF": "2026-02-20",
      "Deadline": "2026-04-26",
      "会议日期": "Generative AI × HCI (co-located with CHI)"
    },
    {
      "名称": "CHI TREW Workshop",
      "链接": "https://sites.google.com/view/trew-chi2026",
      "领域": "Workshop",
      "CCF": "2026-02-20",
      "Deadline": "2026-04-26",
      "会议日期": "Trust & Reliance in Human-AI Workflows (co-located with CHI)"
    },
    {
      "名称": "ACL/EMNLP HCI+NLP Workshop",
      "链接": "https://aclanthology.org",
      "领域": "Workshop",
      "CCF": "TBD",
      "Deadline": "TBD",
      "会议日期": "HCI×NLP交叉"
    },
    {
      "名称": "NeurIPS/ICML Agent Workshops",
      "链接": "https://neurips.cc",
      "领域": "Workshop",
      "CCF": "TBD",
      "Deadline": "TBD",
      "会议日期": "系统/ML视角的agent研究"
    }
  ],
  "opportunities": [
    {
      "名称": "NSF CAREER Award",
      "链接": "https://www.nsf.gov/funding/opportunities?fund_program_desc=CAREER",
      "类型": "🏛️ NSF Grant",
      "说明": "≥$400K/5yr, tenure-track AP, most prestigious early career award. Deadline: ~July yearly. 拿到faculty offer后优先准备"
    },
    {
      "名称": "NSF CRII (Research Initiation)",
      "链接": "https://www.nsf.gov/funding/opportunities?fund_program_desc=CRII",
      "类型": "🏛️ NSF Grant",
      "说明": "≤$175K/24mo, non-R1 early career, PhD后3年内未拿过联邦PI grant. 适合刚入职non-R1的新AP"
    },
    {
      "名称": "NSF CISE Future CoRe",
      "链接": "https://www.nsf.gov/cise/funding.jsp",
      "类型": "🏛️ NSF Grant",
      "说明": "$150K-$250K/yr, max $1M/4yr. 覆盖human-AI interaction, NLP, SE. Deadline: Feb 5, 2026. 与研究方向高度匹配"
    },
    {
      "名称": "NSF EAGER",
      "链接": "https://www.nsf.gov/funding/pgm_summ.jsp?pims_id=504784",
      "类型": "🏛️ NSF Grant",
      "说明": "高风险高回报exploratory research, AI×社会交叉(human-AI, bias, fairness). 需program officer邀请/推荐"
    },
    {
      "名称": "NSF Engineering Postdoc Fellowship",
      "链接": "https://www.nsf.gov/funding/",
      "类型": "🏛️ NSF Fellowship",
      "说明": "Stipend + travel, 2年. 仅限US citizens/permanent residents"
    },
    {
      "名称": "CRA Trustworthy AI Fellowship",
      "链接": "https://cra.org/",
      "类型": "🎓 Fellowship",
      "说明": "⏰ $17K stipend + travel. PhD 2023.5-2025.7. Deadline: March 31, 2026. Human-AI + qualitative背景很match"
    },
    {
      "名称": "Cooperative AI Foundation Grants",
      "链接": "https://www.cooperativeai.com/",
      "类型": "🎓 Foundation",
      "说明": "最高GBP 100K/12mo, early-career track (PhD后2-3年). AI合作、多智能体系统"
    },
    {
      "名称": "Sloan Metascience & AI Postdoc",
      "链接": "https://sloan.org/",
      "类型": "🎓 Fellowship",
      "说明": "最高$250K/2yr. Social sciences方向, AI对科学研究的影响"
    },
    {
      "名称": "iSchools Research Grants",
      "链接": "https://ischools.org/",
      "类型": "🎓 Grant",
      "说明": "Early career faculty & PhD students. July deadline, 主题每年变. Information science相关"
    },
    {
      "名称": "Stanford HAI Seed Grants",
      "链接": "https://hai.stanford.edu/",
      "类型": "🏢 University",
      "说明": "最高$75K/12mo. Stanford affiliated only. Augmenting human capabilities & human-AI interaction"
    },
    {
      "名称": "Penn AI Fellowship",
      "链接": "https://www.upenn.edu/",
      "类型": "🏢 University",
      "说明": "$8K research/travel fund + faculty mentoring. Penn postdocs/grad students only"
    },
    {
      "名称": "RGC Early Career Scheme (ECS)",
      "链接": "https://www.ugc.edu.hk/eng/rgc/funding_opport/ecs/",
      "类型": "🇭🇰 HK Grant",
      "说明": "最高HK$2M/5yr, tenure-track AP入职前3年. 成功率~33%. Deadline: ~10月底. 香港新AP最重要的起步grant"
    },
    {
      "名称": "RGC General Research Fund (GRF)",
      "链接": "https://www.ugc.edu.hk/eng/rgc/funding_opport/grf/",
      "类型": "🇭🇰 HK Grant",
      "说明": "最高HK$2M, 成功率~30%, UGC大学academic staff"
    },
    {
      "名称": "RGC Collaborative Research Fund (CRF)",
      "链接": "https://www.ugc.edu.hk/eng/rgc/funding_opport/crf/",
      "类型": "🇭🇰 HK Grant",
      "说明": "最高HK$10M, 跨学科跨院校合作. 适合大型human-AI collaboration项目"
    },
    {
      "名称": "RGC Research Impact Fund (RIF)",
      "链接": "https://www.ugc.edu.hk/eng/rgc/funding_opport/rif/",
      "类型": "🇭🇰 HK Grant",
      "说明": "侧重societal impact. 适合AI-for-qualitative-analysis方向, impact story很强"
    },
    {
      "名称": "Singapore NRF Fellowship",
      "链接": "https://www.nrf.gov.sg/grants/nrff/",
      "类型": "🇸🇬 SG Grant",
      "说明": "最高SGD 3M(~US$2M)/5yr, 40岁以下all nationalities. 最prestigious early career grant, SUTD背景加分"
    },
    {
      "名称": "MOE Academic Research Fund (AcRF)",
      "链接": "https://www.moe.gov.sg/",
      "类型": "🇸🇬 SG Grant",
      "说明": "Tier 1: 新AP通常可拿到. Tier 2: 竞争性grant需向MOE申请"
    },
    {
      "名称": "AISG Research-Governance Joint Grant",
      "链接": "https://aisingapore.org/research/joint-grant-call/",
      "类型": "🇸🇬 SG Grant",
      "说明": "AI governance + human-machine interaction + social resilience. Research profile完美match: AI + social science + trustworthy AI"
    },
    {
      "名称": "ARC DECRA",
      "链接": "https://www.arc.gov.au/",
      "类型": "🇦🇺 AU Grant",
      "说明": "3yr, 年薪$126K + 项目经费$50K/yr. 成功率13.1%. DE27申请: 2026.1.28-3.11. 申Sydney的话这个很关键"
    },
    {
      "名称": "ARC Future Fellowships",
      "链接": "https://www.arc.gov.au/",
      "类型": "🇦🇺 AU Grant",
      "说明": "Mid-career researcher. FT26已关闭, 关注FT27"
    },
    {
      "名称": "ARC Discovery Projects",
      "链接": "https://www.arc.gov.au/",
      "类型": "🇦🇺 AU Grant",
      "说明": "澳洲core research grant, 类似NSF standard grant. 拿到faculty后申请"
    },
    {
      "名称": "ARC Linkage Projects",
      "链接": "https://www.arc.gov.au/",
      "类型": "🇦🇺 AU Grant",
      "说明": "需industry partner合作. 适合open-source tool有industry adoption的情况"
    },
    {
      "名称": "Microsoft Research Fellowship 2026",
      "链接": "https://www.microsoft.com/en-us/research/academic-program/phd-fellowship/",
      "类型": "🌏 International",
      "说明": "美加$47K, 欧洲$27K, 亚太$17K. 覆盖human-AI collaboration. 2026轮次已过(Dec 2025), 关注2027"
    },
    {
      "名称": "Google DeepMind Singapore",
      "链接": "https://job-boards.greenhouse.io/deepmind",
      "类型": "🇸🇬 SG Industry",
      "说明": "Research Scientist: Reasoning & AGI + Autonomous Agents方向. LLM agents/NLP/evaluation, 与研究方向高度匹配"
    },
    {
      "名称": "ByteDance/TikTok Singapore (Seed)",
      "链接": "https://jobs.bytedance.com",
      "类型": "🇸🇬 SG Industry",
      "说明": "LLM Research Scientist (Code AI方向与CodeMap直接相关) + Responsible AI + Conversational AI"
    },
    {
      "名称": "NVIDIA Singapore",
      "链接": "https://www.nvidia.com/en-sg/about-nvidia/careers/",
      "类型": "🇸🇬 SG Industry",
      "说明": "AI Researcher: language model + efficient AI computing"
    },
    {
      "名称": "Sea AI Lab (SAIL)",
      "链接": "https://careers.sea.com",
      "类型": "🇸🇬 SG Industry",
      "说明": "Language models, trustworthy AI, scalable systems. 研究+产品落地兼顾, 应用到Shopee/Garena"
    },
    {
      "名称": "Grab AI Centre",
      "链接": "https://grab.careers",
      "类型": "🇸🇬 SG Industry",
      "说明": "AI researcher/data scientist: mobility, delivery, payments相关AI"
    },
    {
      "名称": "AI Singapore (AISG)",
      "链接": "https://aisingapore.org/careers/",
      "类型": "🇸🇬 SG Gov",
      "说明": "国家级AI计划. Programme Manager, AI Engineer等"
    },
    {
      "名称": "A*STAR",
      "链接": "https://www.a-star.edu.sg/careers",
      "类型": "🇸🇬 SG Gov",
      "说明": "Research Scientist: ML, NLP, drug discovery等"
    },
    {
      "名称": "GovTech Singapore",
      "链接": "https://www.tech.gov.sg/careers/",
      "类型": "🇸🇬 SG Gov",
      "说明": "Data Scientist: 隐私保护技术, 政府数据共享"
    },
    {
      "名称": "DSO National Laboratories",
      "链接": "https://www.dso.org.sg/careers",
      "类型": "🇸🇬 SG Gov",
      "说明": "AI Research Engineer: 国防/安全应用方向"
    },
    {
      "名称": "ACM SIGCHI Open Positions",
      "链接": "https://sigchi.org/resources/open-positions/",
      "类型": "📋 Job Board",
      "说明": "HCI academic positions"
    },
    {
      "名称": "CRA Job Board",
      "链接": "https://cra.org/ads/",
      "类型": "📋 Job Board",
      "说明": "CS academic positions"
    }
  ],
  "faculty_jobs": [
    {
      "title": "🔍 CRA Career Center — CS Faculty Positions",
      "link": "https://careercenter.cra.org/?s=&post_type=job_listing&search_category%5B%5D=faculty",
      "source": "faculty_jobs",
      "summary": "Computing Research Association job board. Largest source of CS academic positions in North America.",
      "region": "🇺🇸 US",
      "origin": "Board",
      "ts": 1772094195,
      "matched_keyword": "🇺🇸 US"
    },
    {
      "title": "🔍 HigherEdJobs — CS & IT Faculty",
      "link": "https://www.higheredjobs.com/faculty/search.cfm?JobCat=93",
      "source": "faculty_jobs",
      "summary": "Large US-focused academic job board. Filter by Computer Science / IT category.",
      "region": "🇺🇸 US",
      "origin": "Board",
      "ts": 1772094195,
      "matched_keyword": "🇺🇸 US"
    },
    {
      "title": "🔍 AcademicJobsOnline — Computer Science",
      "link": "https://academicjobsonline.org/ajo/jobs?department=Computer+Science",
      "source": "faculty_jobs",
      "summary": "Global academic recruitment platform. Strong for R1 universities.",
      "region": "🌐 Global",
      "origin": "Board",
      "ts": 1772094195,
      "matched_keyword": "🌐 Global"
    },
    {
      "title": "🔍 Times Higher Education — CS Academic Jobs",
      "link": "https://www.timeshighereducation.com/unijobs/en/listing/computer-science/",
      "source": "faculty_jobs",
      "summary": "Global academic job listings, strong for UK/Europe/Asia/Australia.",
      "region": "🌐 Global",
      "origin": "Board",
      "ts": 1772094195,
      "matched_keyword": "🌐 Global"
    },
    {
      "title": "🔍 jobs.ac.uk — CS & IT",
      "link": "https://www.jobs.ac.uk/search/?activeFacet=subjectFacet&subjectFacet%5B0%5D=Computing+%26+IT",
      "source": "faculty_jobs",
      "summary": "UK & Ireland academic positions. Best source for British universities.",
      "region": "🇬🇧 UK",
      "origin": "Board",
      "ts": 1772094195,
      "matched_keyword": "🇬🇧 UK"
    },
    {
      "title": "🔍 EuroScienceJobs — Computer Science",
      "link": "https://www.eurosciencejobs.com/jobs/computer_science",
      "source": "faculty_jobs",
      "summary": "European academic positions across all countries.",
      "region": "🇪🇺 Europe",
      "origin": "Board",
      "ts": 1772094195,
      "matched_keyword": "🇪🇺 Europe"
    },
    {
      "title": "🔍 CSRankings Open Positions",
      "link": "https://drafty.cs.brown.edu/csopenpositions/",
      "source": "faculty_jobs",
      "summary": "Community-maintained list of CS open positions worldwide. Updated frequently by the community.",
      "region": "🌐 Global",
      "origin": "Board",
      "ts": 1772094195,
      "matched_keyword": "🌐 Global"
    },
    {
      "title": "🔍 GitHub CS Faculty Jobs Wiki 2026",
      "link": "https://github.com/academic-cs-jobs",
      "source": "faculty_jobs",
      "summary": "Community-maintained spreadsheet/wiki tracking CS faculty openings and their status.",
      "region": "🌐 Global",
      "origin": "Board",
      "ts": 1772094195,
      "matched_keyword": "🌐 Global"
    }
  ]
}